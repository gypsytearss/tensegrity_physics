{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "if not hasattr(sys, 'argv'):\n",
    "    sys.argv  = ['']\n",
    "import numpy as np\n",
    "import GPflow\n",
    "import random\n",
    "import scipy.spatial\n",
    "import errno\n",
    "\n",
    "def mkdir_p(path):\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as exc:  # Python >2.5\n",
    "        if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
    "            pass\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "def normalize(angle, min_, max_):\n",
    "    if angle < min_:\n",
    "        return angle + 2*np.pi\n",
    "    if angle > max_:\n",
    "        return angle - 2*np.pi\n",
    "    return angle\n",
    "\n",
    "    \n",
    "def unit_vector(vector):\n",
    "    return vector / np.linalg.norm(vector)\n",
    "\n",
    "def angle_between(v1, v2):\n",
    "    v1_u = unit_vector(v1)\n",
    "    v2_u = unit_vector(v2)\n",
    "    return normalize(np.arctan2(v1_u[0], v1_u[1]) - np.arctan2(v2_u[0], v2_u[1]), -3.1415, 3.1415)\n",
    "\n",
    "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "# Full GP Regression Class \n",
    "#   used to aggregate data from trials and perform Bayesian optimization\n",
    "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "class GPRegression():\n",
    "    def __init__(self, ctrl_size, num_gaits, bounds_l, bounds_h):\n",
    "        self.train_data = np.asarray([]).reshape((0,0))\n",
    "        self.train_labels = np.asarray([]).reshape((0,0))\n",
    "        self.train_data_cls = np.asarray([]).reshape((0,0))\n",
    "        self.train_labels_cls = np.asarray([]).reshape((0,0))\n",
    "        self.prev_control = []\n",
    "        self.prev_end_state = []\n",
    "        self.model = []\n",
    "        self.iter_count = 0\n",
    "        self.gp_cls = []\n",
    "        self.ctrl_size = ctrl_size\n",
    "        self.num_gaits = num_gaits\n",
    "        self.bounds_l = bounds_l\n",
    "        self.bounds_h = bounds_h\n",
    "        self.maximums = [0] * num_gaits\n",
    "        self.max_heading_changes = [0] * num_gaits\n",
    "        self.max_controls = np.zeros((self.num_gaits, self.ctrl_size))\n",
    "        self.max_box_dims = np.zeros((self.num_gaits, 2))\n",
    "\n",
    "        self.num_samples = 50000\n",
    "        self.ang_rng_upper = 36.0\n",
    "        self.ang_rng_lower = -36.0\n",
    "        samp_locs = [x / 100000.0 for x in range(100000)]\n",
    "        self.ctrl_samples = np.concatenate([np.array(\n",
    "                                random.sample(samp_locs, self.num_samples)).reshape((self.num_samples,1))\n",
    "                                                *(z-y)+y \n",
    "                                for y,z in zip(self.bounds_l,self.bounds_h)], axis=1)\n",
    "\n",
    "    # Return the bin no. of the gait this ang_vel is grouped with\n",
    "    def get_bin_index(ang_vel):\n",
    "        return int(np.floor((ang_vel + (self.ang_rng_upper-self.ang_rng_lower)/2.0) / \n",
    "                            ((self.ang_rng_upper-self.ang_rng_lower) / self.num_gaits*1.0)))\n",
    "        \n",
    "    # Check if new training example's velocity is higher than current maximum\n",
    "    # for the heading direction\n",
    "    def check_max(self, new_data, new_label, box_dims):\n",
    "        idx = self.get_bin_index(new_label[0])\n",
    "        if new_label[0] <= -self.ang_rng_lower:\n",
    "            pass\n",
    "        elif new_label[0] >= self.ang_rng_upper:\n",
    "            pass\n",
    "        elif new_label[1] > self.maximums[idx]:\n",
    "            self.maximums[idx] = new_label[1]\n",
    "            self.max_controls[idx,:] = new_data\n",
    "            self.max_box_dims[idx,:] = box_dims\n",
    "            self.max_heading_changes[idx] = new_label[0]\n",
    "    \n",
    "    # Insert new {X,Y} into GP regression model and optimize hyperparams\n",
    "    def add_and_optimize(self, new_data, new_label, box_dims):\n",
    "        X, Y = [], []\n",
    "        if not self.train_data.shape[0] == 0:\n",
    "            X = np.concatenate((self.train_data, np.asarray(new_data).reshape((1,self.ctrl_size))), axis=0)\n",
    "            Y = np.concatenate((self.train_labels, np.asarray(new_label).reshape((1,2))), axis=0)\n",
    "        else:\n",
    "            X = np.asarray(new_data).reshape((1,self.ctrl_size))\n",
    "            Y = np.asarray(new_label).reshape((1,2))\n",
    "            self.lengthscales=GPflow.param.Param(0.5)\n",
    "            self.variance=GPflow.param.Param(100)\n",
    "        self.kern = GPflow.kernels.RBF(self.ctrl_size, lengthscales=self.lengthscales.value[0], \n",
    "                                          variance=self.variance.value[0])\n",
    "        self.model = GPflow.gpr.GPR(X,Y, self.kern)\n",
    "        \n",
    "        self.train_data = X\n",
    "        self.train_labels = Y\n",
    "        \n",
    "        self.nn_tree = scipy.spatial.cKDTree(self.train_data, leafsize=100, )\n",
    "        \n",
    "        self.check_max(new_data, new_label, box_dims)\n",
    "        self.model.optimize(method='tnc')\n",
    "\n",
    "        if self.kern.lengthscales.value[0] < 0.09 or self.kern.variance.value[0] < 5.0:\n",
    "            self.kern.lengthscales = GPflow.param.Param(0.5)\n",
    "            self.kern.variance = GPflow.param.Param(100)\n",
    "        self.lengthscales = self.kern.lengthscales\n",
    "        self.variance = self.kern.variance  \n",
    "        np.save('gp_opt_train_data.npy', self.train_data)\n",
    "        np.save('gp_opt_train_labels.npy', self.train_labels)        \n",
    "        \n",
    "        print \"OPT Kern params: \", self.kern.get_parameter_dict()\n",
    "        print \"Added POS: \", new_data, new_label\n",
    "        self.add_class_data(new_data, 1.0)\n",
    "        \n",
    "    # Add datapoint to KNN dataset with binary label indicating stability of \n",
    "    # the gait produced at this control point\n",
    "    def add_class_data(self, new_data, bcls):\n",
    "        X, Y = [], []\n",
    "        if not self.train_data_cls.shape[0] == 0:\n",
    "            X = np.concatenate((self.train_data_cls, np.asarray(new_data).reshape((1,self.ctrl_size))), axis=0)\n",
    "            Y = np.concatenate((self.train_labels_cls, np.asarray(bcls).reshape((1,1))), axis=0)\n",
    "        else:\n",
    "            X = np.asarray(new_data).reshape((1,9))\n",
    "            Y = np.asarray(bcls).reshape((1,1))\n",
    "            \n",
    "        self.train_data_cls = X\n",
    "        self.train_labels_cls = Y\n",
    "\n",
    "        if bcls == 0.0: \n",
    "            print \"Added NEG Class: \", new_data\n",
    "        else:\n",
    "            print \"Added POS Class: \", new_data\n",
    "\n",
    "        np.save('gp_class_train_data.npy', self.train_data_cls)\n",
    "        np.save('gp_class_train_labels.npy', self.train_labels_cls)\n",
    "        \n",
    "    # For each input point, return KNN prediction of quality of control point\n",
    "    def get_probabilities(self, test_data):\n",
    "        res = [] \n",
    "        self.near_tree = scipy.spatial.cKDTree(self.train_data_cls, leafsize=100)\n",
    "        for i,item in enumerate(test_data):\n",
    "            k = min(10, self.train_data_cls.shape[0])\n",
    "            idx = self.near_tree.query(item, k=k, distance_upper_bound=14)\n",
    "            res.append((np.sum(self.train_labels_cls[idx[1]])/k)+0.01)\n",
    "        return res\n",
    "        \n",
    "    # Return GP model prediction for input data\n",
    "    def test(self, data):\n",
    "        return self.model.predict_y(data)\n",
    "\n",
    "    # Return GP model prediction for all random samples generated at init\n",
    "    def test_samples(self):\n",
    "        return self.model.predict_y(self.ctrl_samples)\n",
    "    \n",
    "    # Increase iteration count\n",
    "    def add_iter(self):\n",
    "        self.iter_count += 1\n",
    "        \n",
    "    # Choose next sample location by evaluating all remaining sample locations\n",
    "    # and ranking wrt product of local and \"regional\" proportions of: \n",
    "    #       (mean GP sample val / nearest training point val)\n",
    "    def select_max_velocity(self):\n",
    "        pred, pred_var = self.test_samples()\n",
    "        prob = np.asarray(self.get_probabilities(self.ctrl_samples)).reshape((self.ctrl_samples.shape[0],1))\n",
    "        loc_max_prop, reg_max_prop, item_bins, local_disps = [], [], [], []\n",
    "        for idx, item in enumerate(self.ctrl_samples):\n",
    "            try:\n",
    "                res = self.nn_tree.query(item, k=1, distance_upper_bound=14)\n",
    "                local_disps.append(self.train_labels[res[1],1])\n",
    "                loc_max_prop.append((pred[idx,1])/self.train_labels[res[1],1])\n",
    "                item_bins.append(self.get_bin_index(pred[idx,0]))\n",
    "                if item_bins[idx] < 0:\n",
    "                    reg_max_prop.append(0.0)\n",
    "                elif item_bins[idx] > self.num_gaits-1:\n",
    "                    reg_max_prop.append(0.0)                \n",
    "                elif self.maximums[item_bins[idx]] != 0:\n",
    "                    reg_max_prop.append(pred[idx,1] / self.maximums[item_bins[idx]])\n",
    "                else:\n",
    "                    reg_max_prop.append(10.0)\n",
    "            except IndexError as e:\n",
    "                print \"------------ Autopsy Report ----------------\"\n",
    "                print \"idx: \", idx\n",
    "                print \"res: \", res\n",
    "                print \"pred.shape: \", pred.shape\n",
    "                print \"maximums\", self.maximums\n",
    "                print \"item_bins[idx]\", item_bins[idx]\n",
    "                raise e\n",
    "\n",
    "        loc_reg_criteria = [(((np.sign(a)==-1 and np.sign(b)==-1)-0.5)* -2)*a*b for a,b in zip(loc_max_prop,reg_max_prop)]\n",
    "        criteria = [a*b for a,b in zip(loc_reg_criteria, prob)]\n",
    "        try:        \n",
    "            idx = np.argmax(criteria)\n",
    "            max_criteria = self.ctrl_samples[idx]\n",
    "            res = self.nn_tree.query(max_criteria, k=1, distance_upper_bound=14)\n",
    "            print \"...................... Debug ...................................\"\n",
    "            print \"Max Pred: \\n\", max_criteria, pred[idx], loc_max_prop[idx], \\\n",
    "                                    reg_max_prop[idx], prob[idx], criteria[idx]\n",
    "            print \"Nearest: \", res, self.train_data[res[1],:], self.train_labels[res[1],:]\n",
    "            print \"................................................................\"\n",
    "            self.ctrl_samples = np.delete(self.ctrl_samples, idx, 0)\n",
    "        except IndexError as e:\n",
    "            print \"------------ Autopsy Report ----------------\"\n",
    "            print \"ctrl_samples.shape: \", self.ctrl_samples.shape\n",
    "            print \"argmax(criteria): \", np.argmax(criteria)\n",
    "            raise e\n",
    "\n",
    "        print \"Sample\\t\\t\\t p[head] \\t P[disp] \\t L_Prop \\t R_Prop \\t Product\"\n",
    "        print np.concatenate((self.ctrl_samples[100:110], \n",
    "                              pred[100:110],\n",
    "                              np.asarray(loc_max_prop[100:110]).reshape((10,1)), \n",
    "                              np.asarray(reg_max_prop[100:110]).reshape((10,1)), \n",
    "                              np.asarray(criteria[100:110]).reshape((10,1))),axis=1)\n",
    "        print \"Choosing bin: \", item_bins[np.argmax(criteria)]\n",
    "        print \"Maximums: \", np.asarray(self.maximums)\n",
    "        print \"Pos Samples: \", self.train_data.shape[0]\n",
    "        print \"Neg Samples: \", self.train_data_cls.shape[0] - self.train_data.shape[0]\n",
    "        return max_criteria\n",
    "\n",
    "    # Choose next sample location by evaluating all remaining sample locations\n",
    "    # and selecting the control point with the maximium model variance \n",
    "    def select_max_variance(self):\n",
    "        pred, pred_var = self.test_samples()\n",
    "        pred_var = pred_var[:,1] - np.mean(pred_var[:,1])\n",
    "        pred_var = (pred_var / (2*np.max(np.abs(pred_var))))+0.5\n",
    "        \n",
    "        prob = np.asarray(self.get_probabilities(self.ctrl_samples)).reshape((self.ctrl_samples.shape[0],1))\n",
    "        criteria = np.multiply(np.asarray(pred_var).reshape((pred_var.shape[0],1)), prob)\n",
    "        print \"Sample\\t\\t\\t Prob \\t Var \\t Product\"\n",
    "        print np.concatenate((self.ctrl_samples[:10], prob[:10], \n",
    "                              np.asarray(pred_var[:10]).reshape((10,1)),\n",
    "                             np.asarray(criteria[:10]).reshape((10,1))),axis=1)\n",
    "        max_var = self.ctrl_samples[np.argmax(criteria)]\n",
    "        self.ctrl_samples = np.delete(self.ctrl_samples, np.argmax(criteria), 0)\n",
    "\n",
    "        return max_var\n",
    "\n",
    "    # Write out the current best set of gaits to individual files\n",
    "    def save_gaits(self):\n",
    "        output_dir = os.environ[\"PRACSYS_PATH\"] + \"prx_input/maneuvers/stored_maneuvers/opt1_dim9_test/\" + str(self.iter_count) + \"/\"\n",
    "        if not os.path.exists(output_dir):\n",
    "            mkdir_p(output_dir)\n",
    "        summary_path = output_dir + \"summary.txt\"\n",
    "        with open(summary_path, \"w\") as fout:\n",
    "            fout.write(\"Maximums: \")\n",
    "            fout.write(str(np.asarray(self.maximums)))\n",
    "            fout.write(\"Pos Samples: \")\n",
    "            fout.write(str(self.train_data.shape[0]))\n",
    "            fout.write(\"Neg Samples: \")\n",
    "            fout.write(str(self.train_data_cls.shape[0] - self.train_data.shape[0]))\n",
    "            fout.write(\"\\nSum: \")\n",
    "            fout.write(str(np.sum(self.maximums)))\n",
    "        for i in range(0,self.max_controls.shape[0]):\n",
    "            output_path = output_dir + \"maneuver_\" + str(i) + \".txt\"\n",
    "            with open(output_path, \"w\") as fout:\n",
    "                ctrl = []\n",
    "                if (self.max_controls[i,:] > 0.0).any():\n",
    "                    ctrl = self.max_controls[i,:]\n",
    "                else:\n",
    "                    samp_locs = [x / 100000.0 for x in range(100000)]\n",
    "                    ctrl = np.concatenate([np.array(\n",
    "                                            random.sample(samp_locs, 1)).reshape((1,1))*(z-y)+y \n",
    "                                            for y,z in zip(self.bounds_l,self.bounds_h)], axis=1)[0,:]\n",
    "                string = \"\"\n",
    "                for idx, item in enumerate(ctrl):\n",
    "                    string = string + str(item)\n",
    "                    if idx < 8: \n",
    "                        string += \", \"\n",
    "                fout.write(string)\n",
    "                fout.write(\"\\n\")\n",
    "                fout.write(str(self.max_heading_changes[i]))\n",
    "                fout.write(\", \")\n",
    "                fout.write(str(self.maximums[i]))\n",
    "                fout.write(\", \")\n",
    "                fout.write(str(self.max_box_dims[i,0]))\n",
    "                fout.write(\", \")\n",
    "                fout.write(str(self.max_box_dims[i,1]))\n",
    "\n",
    "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "# Cython Interface functions \n",
    "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "def init_gp_model(ctrl_size, num_gaits, bounds_l, bounds_h):\n",
    "    np.random.seed(1013)\n",
    "    random.seed(1013)\n",
    "    \n",
    "    np.set_printoptions(formatter={'float': '{: 0.3f}'.format})\n",
    "\n",
    "    global gp\n",
    "    gp = GPRegression(ctrl_size, num_gaits, bounds_l, bounds_h)\n",
    "\n",
    "def select_next_control():\n",
    "    # If first_iter, then select random control to propagate\n",
    "    if (gp.train_data.shape[0] == 0):\n",
    "        samp_locs = [x / 100000.0 for x in range(100000)]\n",
    "        ctrl = np.concatenate([np.array(\n",
    "                        random.sample(samp_locs, 1)).reshape((1,1))*(z-y)+y \n",
    "                        for y,z in zip(gp.bounds_l,gp.bounds_h)], axis=1)[0,:]\n",
    "        # ctrl = np.concatenate(((np.asarray(random.sample([x / 10000.0 for x in range(10000)],1)).reshape((1,1))*0.8 + 0.2),\n",
    "        #     (np.asarray(random.sample([x / 10000.0 for x in range(10000)],1)).reshape((1,1))*0.8 + 0.2),\n",
    "        #     (np.asarray(random.sample([x / 10000.0 for x in range(10000)],1)).reshape((1,1))*0.8 + 0.2),\n",
    "        #     (np.asarray(random.sample([x / 10000.0 for x in range(10000)],1)).reshape((1,1))*0.8 + 0.2),\n",
    "        #     (np.asarray(random.sample([x / 10000.0 for x in range(10000)],1)).reshape((1,1))*0.8 + 0.2),\n",
    "        #     (np.asarray(random.sample([x / 10000.0 for x in range(10000)],1)).reshape((1,1))*0.8 + 0.2),\n",
    "        #     (np.asarray(random.sample([x / 10000.0 for x in range(10000)],1)).reshape((1,1))),\n",
    "        #     (np.asarray(random.sample([x / 10000.0 for x in range(10000)],1)).reshape((1,1))),\n",
    "        #     (np.asarray(random.sample([x / 10000.0 for x in range(10000)],1)).reshape((1,1)))), axis=1)\n",
    "        # ctrl = ctrl.tolist()[0]\n",
    "    else:\n",
    "        print \"-\"*80\n",
    "        if gp.iter_count % 2 == 0:\n",
    "            ctrl = gp.select_max_variance()\n",
    "            print \"VAR Next: \", ctrl\n",
    "        else:\n",
    "            ctrl = gp.select_max_velocity()\n",
    "            print \"OPT Next: \", ctrl\n",
    "        \n",
    "        if gp.iter_count % 50 == 0:\n",
    "            gp.save_gaits()\n",
    "    return ctrl\n",
    "\n",
    "def add_optimize(data, label, dims):\n",
    "    gp.add_and_optimize(data, label, dims)\n",
    "    gp.add_iter()\n",
    "    \n",
    "def add_negative(data):\n",
    "    gp.add_class_data(data, 0.0)\n",
    "    gp.add_iter()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_bin_index() takes exactly 1 argument (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-8f39c4e54d96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minit_gp_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_next_control\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0madd_optimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m10.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# [0.65648, 0.539264, 0.29277600000000004, 0.744912, 0.406488, 0.622296, 0.92919, 0.63293, 0.00129]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-e74babb060a1>\u001b[0m in \u001b[0;36madd_optimize\u001b[0;34m(data, label, dims)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0madd_optimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m     \u001b[0mgp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_and_optimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m     \u001b[0mgp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-e74babb060a1>\u001b[0m in \u001b[0;36madd_and_optimize\u001b[0;34m(self, new_data, new_label, box_dims)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspatial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcKDTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleafsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tnc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-e74babb060a1>\u001b[0m in \u001b[0;36mcheck_max\u001b[0;34m(self, new_data, new_label, box_dims)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;31m# for the heading direction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_bin_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mang_rng_lower\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: get_bin_index() takes exactly 1 argument (2 given)"
     ]
    }
   ],
   "source": [
    "init_gp_model(9, 10, [0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1], [1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\n",
    "b = select_next_control()\n",
    "add_optimize(b, [0.5,0.5], [10.0,10.0])\n",
    "# [0.65648, 0.539264, 0.29277600000000004, 0.744912, 0.406488, 0.622296, 0.92919, 0.63293, 0.00129]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'ckdtree.cKDTree'>\n"
     ]
    }
   ],
   "source": [
    "import scipy.spatial\n",
    "print scipy.spatial.cKDTree"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
