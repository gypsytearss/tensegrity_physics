{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "\n",
      "Requirements:\n",
      " - Caffe (script to install Caffe and pycaffe on a new Ubuntu 14.04 LTS x64 or Ubuntu 14.10 x64. \n",
      "   CPU only, multi-threaded Caffe. http://stackoverflow.com/a/31396229/395857)\n",
      " - sudo pip install pydot\n",
      " - sudo apt-get install -y graphviz\n",
      "\n",
      "Interesting resources on Caffe:\n",
      " - https://github.com/BVLC/caffe/tree/master/examples\n",
      " - http://nbviewer.ipython.org/github/joyofdata/joyofdata-articles/blob/master/deeplearning-with-caffe/Neural-Networks-with-Caffe-on-the-GPU.ipynb\n",
      "'''\n",
      "\n",
      "import subprocess\n",
      "import platform\n",
      "import copy\n",
      "\n",
      "# from sklearn.datasets import load_iris\n",
      "import sklearn.metrics \n",
      "import numpy as np\n",
      "from sklearn.cross_validation import StratifiedShuffleSplit\n",
      "import matplotlib.pyplot as plt\n",
      "import h5py\n",
      "import caffe\n",
      "import caffe.draw\n",
      "\n",
      "\n",
      "def load_data():\n",
      "    '''\n",
      "    Load Sample for Forward Pass from Toy Car Data set\n",
      "    '''\n",
      "    start_states, controls, durations, end_states = [], [], [], [] \n",
      "    \n",
      "    with open('../data_output_50Hz.txt', 'r') as infile:\n",
      "        data = infile.readlines()\n",
      "        \n",
      "        idx, i = 0, 0\n",
      "        \n",
      "        for line in data:\n",
      "            # Stop at end of file\n",
      "            if line == '':\n",
      "                break\n",
      "                \n",
      "            # Reset and continue at Trajectory break\n",
      "            if len(line) == 1:\n",
      "                start_states.pop()\n",
      "                if idx > 100:\n",
      "                    break\n",
      "                i = 0\n",
      "                continue\n",
      "                \n",
      "            # Split Values in line and append to individual lists\n",
      "            vals = line.split(',')\n",
      "            if i % 3 == 0:\n",
      "                start_states.append([float(val) for val in vals])\n",
      "                if i != 0:\n",
      "                    end_states.append([float(val) for val in vals])\n",
      "                    idx += 1\n",
      "            elif i % 3 == 1:\n",
      "                controls.append([float(val) for val in vals])\n",
      "            elif i % 3 == 2:\n",
      "                durations.append([float(val) for val in vals])\n",
      "                \n",
      "            i += 1\n",
      "            \n",
      "    X = np.concatenate((start_states, controls, durations), axis=1)\n",
      "    y = np.asarray(end_states, dtype=np.float64)\n",
      "    \n",
      "    #Resize\n",
      "    X = np.resize(X, (10,8))\n",
      "    y = np.resize(y, (10,5))\n",
      "                \n",
      "    return X, y\n",
      "\n",
      "def save_data_as_hdf5(hdf5_data_filename, data):\n",
      "    '''\n",
      "    HDF5 is one of the data formats Caffe accepts\n",
      "    '''\n",
      "    with h5py.File(hdf5_data_filename, 'w') as f:\n",
      "        f['data'] = data['input'].astype(np.float32)\n",
      "        f['label'] = data['output'].astype(np.float32)\n",
      "\n",
      "\n",
      "def train(solver_prototxt_filename):\n",
      "    '''\n",
      "    Train the ANN\n",
      "    '''\n",
      "    caffe.set_mode_gpu()\n",
      "    solver = caffe.get_solver(solver_prototxt_filename)\n",
      "    solver.solve()\n",
      "\n",
      "\n",
      "def print_network_parameters(net):\n",
      "    '''\n",
      "    Print the parameters of the network\n",
      "    '''\n",
      "    print(net)\n",
      "    print('net.inputs: {0}'.format(net.inputs))\n",
      "    print('net.outputs: {0}'.format(net.outputs))\n",
      "    print('net.blobs: {0}'.format(net.blobs))\n",
      "    print('net.params: {0}'.format(net.params))    \n",
      "\n",
      "def get_predicted_output(deploy_prototxt_filename, caffemodel_filename, input, net = None):\n",
      "    '''\n",
      "    Get the predicted output, i.e. perform a forward pass\n",
      "    '''\n",
      "    if net is None:\n",
      "        net = caffe.Net(deploy_prototxt_filename,caffemodel_filename, caffe.TEST)\n",
      "\n",
      "    #input = np.array([[ 5.1,  3.5,  1.4,  0.2]])\n",
      "    #input = np.random.random((1, 1, 1))\n",
      "    print(input)\n",
      "    print(input.shape)\n",
      "    out = net.forward(data=input)\n",
      "    #print('out: {0}'.format(out))\n",
      "    return out[net.outputs[0]]\n",
      "\n",
      "\n",
      "import google.protobuf \n",
      "def print_network(prototxt_filename, caffemodel_filename):\n",
      "    '''\n",
      "    Draw the ANN architecture\n",
      "    '''\n",
      "    _net = caffe.proto.caffe_pb2.NetParameter()\n",
      "    f = open(prototxt_filename)\n",
      "    google.protobuf.text_format.Merge(f.read(), _net)\n",
      "    caffe.draw.draw_net_to_file(_net, prototxt_filename + '.png' )\n",
      "    print('Draw ANN done!')\n",
      "\n",
      "\n",
      "def print_network_weights(prototxt_filename, caffemodel_filename):\n",
      "    '''\n",
      "    For each ANN layer, print weight heatmap and weight histogram \n",
      "    '''\n",
      "    net = caffe.Net(prototxt_filename,caffemodel_filename, caffe.TEST)\n",
      "    for layer_name in net.params: \n",
      "        # weights heatmap \n",
      "        arr = net.params[layer_name][0].data\n",
      "        plt.clf()\n",
      "        fig = plt.figure(figsize=(10,10))\n",
      "        ax = fig.add_subplot(111)\n",
      "        cax = ax.matshow(arr, interpolation='none')\n",
      "        fig.colorbar(cax, orientation=\"horizontal\")\n",
      "        plt.savefig('{0}_weights_{1}.png'.format(caffemodel_filename, layer_name), dpi=100, format='png', bbox_inches='tight') # use format='svg' or 'pdf' for vectorial pictures\n",
      "        plt.close()\n",
      "\n",
      "        # weights histogram  \n",
      "        plt.clf()\n",
      "        plt.hist(arr.tolist(), bins=20)\n",
      "        plt.savefig('{0}_weights_hist_{1}.png'.format(caffemodel_filename, layer_name), dpi=100, format='png', bbox_inches='tight') # use format='svg' or 'pdf' for vectorial pictures\n",
      "        plt.close()\n",
      "\n",
      "\n",
      "def get_predicted_outputs(deploy_prototxt_filename, caffemodel_filename, inputs):\n",
      "    '''\n",
      "    Get several predicted outputs\n",
      "    '''\n",
      "    outputs = []\n",
      "    net = caffe.Net(deploy_prototxt_filename,caffemodel_filename, caffe.TEST)\n",
      "    print(input)\n",
      "    outputs.append(copy.deepcopy(get_predicted_output(deploy_prototxt_filename, caffemodel_filename, inputs, net)))\n",
      "    return outputs    \n",
      "\n",
      "\n",
      "def get_accuracy(true_outputs, predicted_outputs):\n",
      "    '''\n",
      "\n",
      "    '''\n",
      "    number_of_samples = true_outputs.shape[0]\n",
      "    number_of_outputs = true_outputs.shape[1]\n",
      "    threshold = 0.0 # 0 if SigmoidCrossEntropyLoss ; 0.5 if EuclideanLoss\n",
      "    for output_number in range(number_of_outputs):\n",
      "        predicted_output_binary = []\n",
      "        for sample_number in range(number_of_samples):\n",
      "            #print(predicted_outputs)\n",
      "            #print(predicted_outputs[sample_number][output_number])            \n",
      "            if predicted_outputs[sample_number][0][output_number] < threshold:\n",
      "                predicted_output = 0\n",
      "            else:\n",
      "                predicted_output = 1\n",
      "            predicted_output_binary.append(predicted_output)\n",
      "\n",
      "        print('accuracy: {0}'.format(sklearn.metrics.accuracy_score(true_outputs[:, output_number], predicted_output_binary)))\n",
      "        print(sklearn.metrics.confusion_matrix(true_outputs[:, output_number], predicted_output_binary))\n",
      "\n",
      "\n",
      "def training():\n",
      "    '''\n",
      "    Performs Training of the specified network\n",
      "    '''\n",
      "    # Set parameters\n",
      "    solver_prototxt_filename = 'toycar_solver.prototxt'\n",
      "    train_test_prototxt_filename = 'toycar_2fc.prototxt'\n",
      "    caffemodel_filename = '2fc_iter_10001.caffemodel' # generated by train()\n",
      "\n",
      "\n",
      "    # Train network\n",
      "    train(solver_prototxt_filename)\n",
      "\n",
      "    # Print network\n",
      "    print_network(train_test_prototxt_filename, caffemodel_filename)\n",
      "    print_network_weights(train_test_prototxt_filename, caffemodel_filename)\n",
      "\n",
      "\n",
      "def testing():\n",
      "    '''\n",
      "    Performs Testing of the specified network\n",
      "    '''    \n",
      "    caffemodel_filename = '2fc_iter_10001.caffemodel' # generated by train()   \n",
      "    deploy_prototxt_filename  = 'toycar_2fc_deploy.prototxt'\n",
      "    \n",
      "    # Prepare sample data\n",
      "    data, labels = load_data()\n",
      "    \n",
      "    # Print the Network\n",
      "    print_network(deploy_prototxt_filename, caffemodel_filename)    \n",
      "    \n",
      "    # Compute performance metrics\n",
      "    inputs = data\n",
      "    outputs = get_predicted_outputs(deploy_prototxt_filename, caffemodel_filename, inputs)\n",
      "    \n",
      "    print 'predictions: '\n",
      "    print outputs\n",
      "    \n",
      "    print 'ground truths: '\n",
      "    print labels\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "training()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Draw ANN done!\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testing()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Draw ANN done!\n",
        "<function <lambda> at 0x7f156bc2cb18>\n",
        "[[  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
        "    0.00000000e+00  -4.99790647e-01   2.39952491e-02   2.00000000e-02]\n",
        " [ -8.32984387e-05   5.99378961e-13  -1.99876682e-08  -9.99581294e-03\n",
        "    4.79904982e-04  -4.99790647e-01   2.39952491e-02   2.00000000e-02]\n",
        " [ -3.66513070e-04   2.72384365e-11  -2.15866803e-07  -1.99916259e-02\n",
        "    9.59809963e-04  -4.99790647e-01   2.39952491e-02   2.00000000e-02]\n",
        " [ -8.49643698e-04   2.38419453e-10  -7.79518923e-07  -2.99874388e-02\n",
        "    1.43971494e-03  -4.99790647e-01   2.39952491e-02   2.00000000e-02]\n",
        " [ -1.53268999e-03   1.07714906e-09  -1.90282538e-06  -3.99832517e-02\n",
        "    1.91961993e-03  -4.99790647e-01   2.39952491e-02   2.00000000e-02]\n",
        " [ -2.41565147e-03   3.42437735e-09  -3.77766726e-06  -4.99790647e-02\n",
        "    2.39952491e-03  -4.99790647e-01   2.39952491e-02   2.00000000e-02]\n",
        " [ -3.49852754e-03   8.75243516e-09  -6.59592532e-06  -5.99748776e-02\n",
        "    2.87942989e-03  -4.99790647e-01   2.39952491e-02   2.00000000e-02]\n",
        " [ -4.78131743e-03   1.92784689e-08  -1.05494799e-05  -6.99706906e-02\n",
        "    3.35933487e-03  -4.99790647e-01   2.39952491e-02   2.00000000e-02]\n",
        " [ -6.26402027e-03   3.81178723e-08  -1.58302107e-05  -7.99665035e-02\n",
        "    3.83923985e-03  -4.99790647e-01   2.39952491e-02   2.00000000e-02]\n",
        " [ -7.94663504e-03   6.94377142e-08  -2.26299969e-05  -8.99623164e-02\n",
        "    4.31914483e-03  -4.99790647e-01   2.39952491e-02   2.00000000e-02]]\n",
        "(10, 8)\n",
        "predictions: \n",
        "[array([[ 1.90996003,  1.90288162,  1.86407399,  1.87990713,  1.95122719],\n",
        "       [ 1.91013265,  1.90305269,  1.86423969,  1.88007188,  1.95140839],\n",
        "       [ 1.91030526,  1.90322328,  1.86440527,  1.88023663,  1.95158958],\n",
        "       [ 1.91047776,  1.90339375,  1.86457086,  1.88040113,  1.9517709 ],\n",
        "       [ 1.91065013,  1.90356445,  1.86473608,  1.88056517,  1.95195174],\n",
        "       [ 1.91082239,  1.90373456,  1.86490142,  1.88072944,  1.95213246],\n",
        "       [ 1.91099429,  1.9039048 ,  1.86506653,  1.88089347,  1.95231295],\n",
        "       [ 1.91116655,  1.90407467,  1.86523139,  1.8810575 ,  1.95249367],\n",
        "       [ 1.91133821,  1.90424466,  1.86539626,  1.88122129,  1.95267344],\n",
        "       [ 1.91150975,  1.90441442,  1.86556089,  1.88138485,  1.95285392]], dtype=float32)]\n",
        "ground truths: \n",
        "[[ -8.32984387e-05   5.99378961e-13  -1.99876682e-08  -9.99581294e-03\n",
        "    4.79904982e-04]\n",
        " [ -3.66513070e-04   2.72384365e-11  -2.15866803e-07  -1.99916259e-02\n",
        "    9.59809963e-04]\n",
        " [ -8.49643698e-04   2.38419453e-10  -7.79518923e-07  -2.99874388e-02\n",
        "    1.43971494e-03]\n",
        " [ -1.53268999e-03   1.07714906e-09  -1.90282538e-06  -3.99832517e-02\n",
        "    1.91961993e-03]\n",
        " [ -2.41565147e-03   3.42437735e-09  -3.77766726e-06  -4.99790647e-02\n",
        "    2.39952491e-03]\n",
        " [ -3.49852754e-03   8.75243516e-09  -6.59592532e-06  -5.99748776e-02\n",
        "    2.87942989e-03]\n",
        " [ -4.78131743e-03   1.92784689e-08  -1.05494799e-05  -6.99706906e-02\n",
        "    3.35933487e-03]\n",
        " [ -6.26402027e-03   3.81178723e-08  -1.58302107e-05  -7.99665035e-02\n",
        "    3.83923985e-03]\n",
        " [ -7.94663504e-03   6.94377142e-08  -2.26299969e-05  -8.99623164e-02\n",
        "    4.31914483e-03]\n",
        " [ -9.82916056e-03   1.18610163e-07  -3.11407171e-05  -9.99581294e-02\n",
        "    4.79904982e-03]]\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}