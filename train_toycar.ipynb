{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Requirements:\n",
    " - Caffe (script to install Caffe and pycaffe on a new Ubuntu 14.04 LTS x64 or Ubuntu 14.10 x64. \n",
    "   CPU only, multi-threaded Caffe. http://stackoverflow.com/a/31396229/395857)\n",
    " - sudo pip install pydot\n",
    " - sudo apt-get install -y graphviz\n",
    "\n",
    "Interesting resources on Caffe:\n",
    " - https://github.com/BVLC/caffe/tree/master/examples\n",
    " - http://nbviewer.ipython.org/github/joyofdata/joyofdata-articles\\\n",
    " /blob/master/deeplearning-with-caffe/\\\n",
    " Neural-Networks-with-Caffe-on-the-GPU.ipynb\n",
    "'''\n",
    "\n",
    "import subprocess\n",
    "import platform\n",
    "import copy\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# from sklearn.datasets import load_iris\n",
    "import sklearn.metrics\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import caffe\n",
    "import caffe.draw\n",
    "import google.protobuf \n",
    "\n",
    "# Globals\n",
    "train_data, train_labels, test_data, test_labels = [], [], [], []\n",
    "\n",
    "def load_data():\n",
    "    '''\n",
    "    Load Sample for Forward Pass from Toy Car Data set\n",
    "    '''\n",
    "    print \"LOADING DATA\"\n",
    "    start_states, controls, durations, end_states = [], [], [], []\n",
    "\n",
    "    with open('/home/colin/Repos/prx_ws/src/prx_learn/external/caffe/examples/toy_car/data_output_50Hz.txt', 'r') as infile:\n",
    "        data = infile.readlines()\n",
    "\n",
    "        idx, i = 0, 0\n",
    "\n",
    "        for line in data:\n",
    "            # Stop at end of file\n",
    "            if line == '':\n",
    "                print \"end\"\n",
    "                break\n",
    "\n",
    "            # Reset and continue at Trajectory break\n",
    "            if len(line) == 1:\n",
    "                start_states.pop()\n",
    "                i = 0\n",
    "                if idx > 1000000:\n",
    "                    print \"done Reading\"\n",
    "                    break\n",
    "#                 print \"reading: \", idx\n",
    "                continue\n",
    "                \n",
    "            # Split Values in line and append to individual lists\n",
    "            vals = line.split(',')\n",
    "            if i % 3 == 0:\n",
    "                start_states.append([float(val) for val in vals])\n",
    "                if i != 0:\n",
    "                    end_states.append([float(val) for val in vals])\n",
    "                    idx += 1\n",
    "            elif i % 3 == 1:\n",
    "                controls.append([float(val) for val in vals])\n",
    "            elif i % 3 == 2:\n",
    "                durations.append([float(val) for val in vals])\n",
    "                \n",
    "            i += 1\n",
    "            \n",
    "    X = np.concatenate((start_states, controls, durations), axis=1)\n",
    "    start_states = np.asarray(start_states, dtype=np.float32)\n",
    "    end_states = np.asarray(end_states, dtype=np.float32)\n",
    "    \n",
    "    X, meanx, minx, maxx = normalize_data(X)\n",
    "    y = normalize_labels(start_states, end_states)\n",
    "\n",
    "    # Shuffle the data around and split 3M training, ~750k validation\n",
    "    indices = np.random.permutation(X.shape[0])\n",
    "    training_idx = indices[:750000]\n",
    "    \n",
    "    train_X = X[training_idx, :]\n",
    "    train_y = y[training_idx, :]\n",
    "\n",
    "    test_X = X[750000:, :]\n",
    "    test_y = y[750000:, :]\n",
    "\n",
    "    return train_X, train_y, test_X, test_y, meanx, minx, maxx\n",
    "\n",
    "\n",
    "def write_binaryproto(data, string):\n",
    "    blob = caffe.proto.caffe_pb2.BlobProto()\n",
    "    blob.channels = data.shape[0]\n",
    "    blob.data.extend(data.astype(float).flat)\n",
    "    binaryproto_file = open('toycar_' + string + '.binaryproto', 'wb')\n",
    "    binaryproto_file.write(blob.SerializeToString())\n",
    "    binaryproto_file.close()\n",
    "\n",
    "\n",
    "def save_binaryproto(data, ftype='mean'):\n",
    "    '''\n",
    "    Take the mean values of the raw data and store them as binaryproto type\n",
    "    In order to use them later for deploy normalization\n",
    "    '''\n",
    "    # Convert to 32bit float\n",
    "    data = np.array(data, dtype=np.float32)\n",
    "\n",
    "    # Set project home dir \n",
    "    PROJECT_HOME = os.path.abspath('.')\n",
    "\n",
    "    # Initialize blob to store serialized means\n",
    "    blob = caffe.proto.caffe_pb2.BlobProto()\n",
    "\n",
    "    # Custom dimensions for blob for this project\n",
    "    blob.num = 1\n",
    "    blob.channels = data.shape[0]\n",
    "    blob.height = 1\n",
    "    blob.width = 1\n",
    "    \n",
    "    # Reshape data and copy into blob\\n\",\n",
    "    blob.data.extend(data.astype(float).flat)\n",
    "    \n",
    "    # Write file\n",
    "    binaryproto_file = open(PROJECT_HOME + '/toycar_' + ftype + '.binaryproto', 'wb')\n",
    "    binaryproto_file.write(blob.SerializeToString())\n",
    "    binaryproto_file.close()\n",
    "\n",
    "\n",
    "\n",
    "def normalize_labels(start_states, end_states):\n",
    "    '''\n",
    "    Normalize end states such that each state variable x_i\n",
    "    is now represented by \\delta x_i\n",
    "    '''\n",
    "    y = end_states\n",
    "    y[:, 0] = end_states[:, 0] - start_states[:, 0]\n",
    "    y[:, 1] = end_states[:, 1] - start_states[:, 1]\n",
    "    y[:, 2] = end_states[:, 2] - start_states[:, 2]\n",
    "    y[:, 3] = end_states[:, 3] - start_states[:, 3]\n",
    "    y[:, 4] = end_states[:, 4] - start_states[:, 4]\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "def unnormalize_data(data, meanx, minx, maxx):\n",
    "    desired_min = -1\n",
    "    desired_max = 1\n",
    "    desired_rng = desired_max - desired_min\n",
    "    \n",
    "    data = data - desired_min\n",
    "    for i in range(0, data.shape[1]):\n",
    "        data[:,i] = data[:,i] * (maxx[:,i] - minx[:,i]) \\\n",
    "                    / desired_rng + minx[:,i] + meanx[:,i]\n",
    "        \n",
    "    return data\n",
    "\n",
    "\n",
    "def normalize_data(data):\n",
    "    '''\n",
    "    Normalize data to zero mean on [-1,1] interval for all dimensions\n",
    "    '''\n",
    "    X_mean = np.mean(data, axis=0)\n",
    "    \n",
    "    # do not substract duration\n",
    "    X_mean[7] = 0\n",
    "    \n",
    "    # Mean Shift\n",
    "    data_t = data - X_mean\n",
    "    \n",
    "    # Find bounds, define desired bounds\n",
    "    X_min = np.min(data_t, axis=0)\n",
    "    X_max = np.max(data_t, axis=0)\n",
    "\n",
    "    # Write 'em Out\n",
    "    save_binaryproto(X_mean, ftype=\"mean\")\n",
    "    save_binaryproto(X_min, ftype=\"min\")\n",
    "    save_binaryproto(X_max, ftype=\"max\")\n",
    "\n",
    "    desiredMin = -1\n",
    "    desiredMax = 1\n",
    "    \n",
    "    # Normalize \n",
    "    for i in range(0, 7):\n",
    "        data_t[:, i] = (data_t[:, i] - X_min[i]) * (desiredMax - desiredMin)\\\n",
    "            / (X_max[i] - X_min[i]) + desiredMin\n",
    "\n",
    "    return data_t, X_mean, X_min, X_max\n",
    "\n",
    "\n",
    "def normalize_test_data(data, meanx, minx, maxx):\n",
    "    '''\n",
    "    Normalize data to zero mean on [-1,1] interval for all dimensions\n",
    "    '''\n",
    "    data_t = data - meanx\n",
    "    desiredMin = -1\n",
    "    desiredMax = 1\n",
    "    \n",
    "    # Normalize \n",
    "    for i in range(0, data.shape[1]):\n",
    "        data_t[:, i] = (data_t[:, i] - minx[:, i]) * (desiredMax - desiredMin)\\\n",
    "            / (maxx[:, i] - minx[:, i]) + desiredMin\n",
    "\n",
    "    return data_t\n",
    "\n",
    "\n",
    "def save_data_as_hdf5(hdf5_data_filename, data, labels):\n",
    "    '''\n",
    "    HDF5 is one of the data formats Caffe accepts\n",
    "    '''\n",
    "    with h5py.File(hdf5_data_filename, 'w') as f:\n",
    "        f['data'] = data.astype(np.float32)\n",
    "        f['label'] = labels.astype(np.float32)\n",
    "\n",
    "\n",
    "def train(solver_prototxt_filename):\n",
    "    '''\n",
    "    Train the ANN\n",
    "    '''\n",
    "\n",
    "\n",
    "\n",
    "def print_network_parameters(net):\n",
    "    '''\n",
    "    Print the parameters of the network\n",
    "    '''\n",
    "    print(net)\n",
    "    print('net.inputs: {0}'.format(net.inputs))\n",
    "    print('net.outputs: {0}'.format(net.outputs))\n",
    "    print('net.blobs: {0}'.format(net.blobs))\n",
    "    print('net.params: {0}'.format(net.params))    \n",
    "\n",
    "\n",
    "def get_predicted_output(deploy_prototxt_filename, \n",
    "                         caffemodel_filename, input, net=None):\n",
    "    '''\n",
    "    Get the predicted output, i.e. perform a forward pass\n",
    "    '''\n",
    "    if net is None:\n",
    "        net = caffe.Net(deploy_prototxt_filename, \n",
    "                        caffemodel_filename, caffe.TEST)\n",
    "    \n",
    "    out = net.forward(data=input)\n",
    "    return out[net.outputs[0]]\n",
    "\n",
    "\n",
    "def print_network(prototxt_filename, caffemodel_filename):\n",
    "    '''\n",
    "    Draw the ANN architecture\n",
    "    '''\n",
    "    _net = caffe.proto.caffe_pb2.NetParameter()\n",
    "    f = open(prototxt_filename)\n",
    "    google.protobuf.text_format.Merge(f.read(), _net)\n",
    "    caffe.draw.draw_net_to_file(_net, prototxt_filename + '.png')\n",
    "    print('Draw ANN done!')\n",
    "\n",
    "\n",
    "def print_network_weights(prototxt_filename, caffemodel_filename):\n",
    "    '''\n",
    "    For each ANN layer, print weight heatmap and weight histogram \n",
    "    '''\n",
    "    net = caffe.Net(prototxt_filename, caffemodel_filename, caffe.TEST)\n",
    "    for layer_name in net.params: \n",
    "        # weights heatmap \n",
    "        arr = net.params[layer_name][0].data\n",
    "        plt.clf()\n",
    "        fig = plt.figure(figsize=(10, 10))\n",
    "        ax = fig.add_subplot(111)\n",
    "        cax = ax.matshow(arr, interpolation='none')\n",
    "        fig.colorbar(cax, orientation=\"horizontal\")\n",
    "        plt.savefig('{0}_weights_{1}.png'.format(caffemodel_filename, \n",
    "                                                 layer_name), \n",
    "                    dpi=100, format='png', bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        # weights histogram  \n",
    "        plt.clf()\n",
    "        plt.hist(arr.tolist(), bins=20)\n",
    "        # savefig: use format='svg' or 'pdf' for vectorial pictures\n",
    "        plt.savefig('{0}_weights_hist_{1}.png'.format(caffemodel_filename, \n",
    "                                                      layer_name), dpi=100, \n",
    "                    format='png', \n",
    "                    bbox_inches='tight')  \n",
    "        plt.close()\n",
    "\n",
    "\n",
    "def get_predicted_outputs(deploy_prototxt_filename, \n",
    "                          caffemodel_filename, inputs):\n",
    "    '''\n",
    "    Get several predicted outputs\n",
    "    '''\n",
    "    outputs = []\n",
    "    net = caffe.Net(deploy_prototxt_filename, caffemodel_filename, caffe.TRAIN)\n",
    "    outputs.append(copy.deepcopy(get_predicted_output(deploy_prototxt_filename, \n",
    "                                                      caffemodel_filename, \n",
    "                                                      inputs, net)))\n",
    "    return outputs    \n",
    "\n",
    "\n",
    "def get_accuracy(true_outputs, predicted_outputs):\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    number_of_samples = true_outputs.shape[0]\n",
    "    number_of_outputs = true_outputs.shape[1]\n",
    "    threshold = 0.0  # 0 if SigmoidCrossEntropyLoss ; 0.5 if EuclideanLoss\n",
    "    for output_number in range(number_of_outputs):\n",
    "        predicted_output_binary = []\n",
    "        for sample_number in range(number_of_samples):\n",
    "            # print(predicted_outputs)\n",
    "            # print(predicted_outputs[sample_number][output_number])            \n",
    "            if predicted_outputs[sample_number][0][output_number] < threshold:\n",
    "                predicted_output = 0\n",
    "            else:\n",
    "                predicted_output = 1\n",
    "            predicted_output_binary.append(predicted_output)\n",
    "\n",
    "        print('accuracy: {0}'.format(sklearn.metrics.accuracy_score(\n",
    "                                     true_outputs[:, output_number], \n",
    "                                     predicted_output_binary)))\n",
    "        print(sklearn.metrics.confusion_matrix(true_outputs[:, output_number], \n",
    "                                               predicted_output_binary))\n",
    "\n",
    "\n",
    "def training(model_iter):\n",
    "    '''\n",
    "    Performs Training of the specified network and outputs PNG images\n",
    "    showing resulting learned weights and histograms of weights\n",
    "    '''\n",
    "    # Set parameters\n",
    "    solver_prototxt_filename = 'toycar_solver.prototxt'\n",
    "    train_test_prototxt_filename = 'toycar_2fc_hdf5.prototxt'\n",
    "    caffemodel_filename = '2fc_iter_' + str(model_iter) + '.caffemodel' \n",
    "\n",
    "    # Train network\n",
    "    caffe.set_mode_gpu()\n",
    "    solver = caffe.get_solver(solver_prototxt_filename)\n",
    "    solver.solve()\n",
    "    \n",
    "    # Print network\n",
    "    print_network(train_test_prototxt_filename, caffemodel_filename)\n",
    "    print_network_weights(train_test_prototxt_filename, caffemodel_filename)\n",
    "\n",
    "\n",
    "def testing(deploy_prototxt_filename, caffemodel_filename, inputs, labels):\n",
    "    '''\n",
    "    Performs Testing of the specified network\n",
    "    '''    \n",
    "    outputs = get_predicted_outputs(deploy_prototxt_filename, \n",
    "                                    caffemodel_filename, inputs)\n",
    "    return outputs[0]\n",
    "    \n",
    "    \n",
    "def euclidean_loss(pred, labels):\n",
    "    '''\n",
    "    Hand Calculate the Euclidean Loss to Compare with Model Output\n",
    "    '''\n",
    "    result = labels-pred\n",
    "    size = pred.shape[0]\n",
    "    \n",
    "    loss = np.sum(np.square(result), axis=1)\n",
    "    loss = np.sum(loss, axis=0) / (2 * size)\n",
    "    \n",
    "    print \"Euclidean Loss: \", loss\n",
    "\n",
    "\n",
    "def main(arg=\"x\"):\n",
    "\n",
    "    if arg.lower() == \"train\":\n",
    "        train_data, train_labels, test_data, test_labels, meanx, minx, maxx = load_data()\n",
    "\n",
    "        print \"writing: train and test\"\n",
    "        save_data_as_hdf5('toycar_hdf5_data_norm11_train.hdf5', \n",
    "                          train_data, train_labels)\n",
    "        save_data_as_hdf5('toycar_hdf5_data_norm11_test.hdf5', \n",
    "                          test_data, test_labels)\n",
    "        \n",
    "        print \"solving....\"\n",
    "        solver_name = \"toycar_solver.prototxt\"\n",
    "        training(100000)\n",
    "\n",
    "    elif arg.lower() == \"test\":\n",
    "        \n",
    "        train_data, train_labels, test_data, test_labels, meanx, minx, maxx = load_data()\n",
    "\n",
    "        pred = testing('toycar_2fc_deploy.prototxt', \n",
    "               '2fc_iter_100000.caffemodel', \n",
    "               test_data[0:1, :], test_labels[0:1, :])\n",
    "        print \"Input: \", test_data[0:1, :]\n",
    "#             pred[0, 0] = pred[0, 0] + test_data[0, 0]\n",
    "#             pred[0, 1] = pred[0, 1] + test_data[0, 1]\n",
    "        print \"Pred: \", pred\n",
    "        print \"Label: \", test_labels[0:1, :]\n",
    "        print \"Loss: \", euclidean_loss(pred, test_labels[0:1, :])\n",
    "\n",
    "\n",
    "        for i in range(1, 100):\n",
    "            unnorm_state = unnormalize_data(test_data[i-1:i,0:2], np.asarray([meanx[0:2]])\n",
    "                                            , np.asarray([minx[0:2]]),np.asarray([maxx[0:2]]))\n",
    "        \n",
    "            pred[0, 0] = pred[0, 0] + unnorm_state[0,0]\n",
    "            pred[0, 1] = pred[0, 1] + unnorm_state[0,1]\n",
    "            \n",
    "            \n",
    "            pred = normalize_test_data(pred, \n",
    "                                       np.asarray([meanx[0:5]]), \n",
    "                                       np.asarray([minx[0:5]]), \n",
    "                                       np.asarray([maxx[0:5]]))\n",
    "            \n",
    "            inpt = np.asarray([np.concatenate((pred[0,:], test_data[i, 5:8]), axis=0)])\n",
    "            \n",
    "            print \"Test Data: \", test_data[i,:]\n",
    "            print \"Input: \", inpt\n",
    "            pred = testing('toycar_2fc_deploy.prototxt', \n",
    "                           '2fc_iter_100000.caffemodel', \n",
    "                           inpt,  test_labels[i:i+1, :])\n",
    "            \n",
    "            print \"Pred: \", pred\n",
    "            print \"Label: \", test_labels[i:i+1, :]\n",
    "            print \"Loss: \", euclidean_loss(pred, test_labels[i:i+1, :])\n",
    "            print \"\\n\"\n",
    "    else:\n",
    "        train_data, train_labels, test_data, test_labels = load_data()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING DATA\n",
      "done Reading\n",
      "writing: train and test\n",
      "solving....\n",
      "Draw ANN done!\n"
     ]
    }
   ],
   "source": [
    "# main()\n",
    "main(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data, train_labels, test_data, test_labels, meanx, minx, maxx = load_data()\n",
    "check = np.asarray([[0, 0, 0.13562027, -0.10375793,  0.09954461]])\n",
    "res = normalize_test_data(check,\n",
    "                          np.asarray([meanx[0:5]]), \n",
    "                           np.asarray([minx[0:5]]), \n",
    "                           np.asarray([maxx[0:5]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.52753878 -0.09802863  0.13742372 -0.54690999  0.16745029 -0.37171077\n",
      "  0.50107972  0.02      ]\n",
      "[-0.52800329 -0.09813368  0.13728903 -0.55064514  0.17081498 -0.37171077\n",
      "  0.50107972  0.02      ]\n",
      "[-0.52850244 -0.09824639  0.13714132 -0.55438028  0.17417968 -0.37171077\n",
      "  0.50107972  0.02      ]\n",
      "[-0.52903622 -0.09836672  0.1369802  -0.55811543  0.17754437 -0.37171077\n",
      "  0.50107972  0.02      ]\n",
      "[-0.52960462 -0.09849463  0.13680525 -0.56185058  0.18090906 -0.37171077\n",
      "  0.50107972  0.02      ]\n",
      "[-0.53020763 -0.09863006  0.13661607 -0.56558573  0.18427376 -0.37171077\n",
      "  0.50107972  0.02      ]\n",
      "[-0.53084522 -0.09877295  0.13641224 -0.56932087  0.18763845 -0.37171077\n",
      "  0.50107972  0.02      ]\n",
      "[-0.5315174  -0.09892324  0.13619336 -0.57305602  0.19100315 -0.37171077\n",
      "  0.50107972  0.02      ]\n",
      "[-0.53222415 -0.09908088  0.13595903 -0.57679117  0.19436784 -0.37171077\n",
      "  0.50107972  0.02      ]\n",
      "[-0.53296544 -0.09924579  0.13570882 -0.58052632  0.19773254 -0.37171077\n",
      "  0.50107972  0.02      ]\n",
      "[-0.53374128 -0.09941789  0.13544235 -0.58426147  0.20109723 -0.37171077\n",
      "  0.50107972  0.02      ]\n",
      "[-0.53455164 -0.09959711  0.13515919 -0.58799661  0.20446192 -0.37171077\n",
      "  0.50107972  0.02      ]\n",
      "[-0.53539652 -0.09978336  0.13485895 -0.59173176  0.20782662 -0.37171077\n",
      "  0.50107972  0.02      ]\n",
      "[-0.53627589 -0.09997656  0.13454121 -0.59546691  0.21119131 -0.37171077\n",
      "  0.50107972  0.02      ]\n",
      "[-0.53718975 -0.1001766   0.13420558 -0.59920206  0.21455601 -0.37171077\n",
      "  0.50107972  0.02      ]\n",
      "[-0.53813808 -0.1003834   0.13385163 -0.60293721  0.2179207  -0.37171077\n",
      "  0.50107972  0.02      ]\n",
      "[-0.53912087 -0.10059684  0.13347897 -0.60667235  0.22128539 -0.37171077\n",
      "  0.50107972  0.02      ]\n",
      "[-0.5401381  -0.10081682  0.13308719 -0.6104075   0.22465009 -0.37171077\n",
      "  0.50107972  0.02      ]\n",
      "[-0.54118976 -0.10104322  0.13267589 -0.61414265  0.22801478 -0.37171077\n",
      "  0.50107972  0.02      ]\n",
      "[-0.54227584 -0.10127591  0.13224465 -0.6178778   0.23137948 -0.37171077\n",
      "  0.50107972  0.02      ]\n",
      "[-0.54339632 -0.10151478  0.13179308 -0.62161295  0.23474417 -0.37171077\n",
      "  0.50107972  0.02      ]\n",
      "[-0.54455119 -0.10175967  0.13132076 -0.62534809  0.23810886 -0.37171077\n",
      "  0.50107972  0.02      ]\n",
      "[-0.54574043 -0.10201046  0.1308273  -0.62908324  0.24147356 -0.37171077\n",
      "  0.50107972  0.02      ]\n",
      "[-0.5264437  -0.09778059  0.13787201 -0.46100159  0.09006232 -0.76268556\n",
      "  0.83141642  0.02      ]\n",
      "[-0.52612357 -0.09770778  0.13792171 -0.46866567  0.09564466 -0.76268556\n",
      "  0.83141642  0.02      ]\n",
      "[-0.52587498 -0.09765122  0.13796274 -0.47632975  0.101227   -0.76268556\n",
      "  0.83141642  0.02      ]\n",
      "[-0.52569792 -0.09761091  0.1379937  -0.48399383  0.10680935 -0.76268556\n",
      "  0.83141642  0.02      ]\n",
      "[-0.52559236 -0.09758687  0.13801318 -0.49165792  0.11239169 -0.76268556\n",
      "  0.83141642  0.02      ]\n",
      "[-0.52555826 -0.09757911  0.13801979 -0.499322    0.11797403 -0.76268556\n",
      "  0.83141642  0.02      ]\n",
      "[-0.52559559 -0.09758761  0.13801213 -0.50698608  0.12355637 -0.76268556\n",
      "  0.83141642  0.02      ]\n",
      "[-0.52570432 -0.09761237  0.13798882 -0.51465016  0.12913871 -0.76268556\n",
      "  0.83141642  0.02      ]\n",
      "[-0.52588442 -0.09765337  0.13794844 -0.52231425  0.13472105 -0.76268556\n",
      "  0.83141642  0.02      ]\n",
      "[-0.52613585 -0.09771057  0.13788961 -0.52997833  0.14030339 -0.76268556\n",
      "  0.83141642  0.02      ]\n",
      "[-0.52645857 -0.09778394  0.13781094 -0.53764241  0.14588573 -0.76268556\n",
      "  0.83141642  0.02      ]\n",
      "[-0.52685255 -0.09787343  0.13771103 -0.54530649  0.15146807 -0.76268556\n",
      "  0.83141642  0.02      ]\n",
      "[-0.52731773 -0.09797896  0.13758848 -0.55297058  0.15705041 -0.76268556\n",
      "  0.83141642  0.02      ]\n",
      "[-0.52785408 -0.09810047  0.13744191 -0.56063466  0.16263275 -0.76268556\n",
      "  0.83141642  0.02      ]\n",
      "[-0.52846156 -0.09823786  0.13726992 -0.56829874  0.1682151  -0.76268556\n",
      "  0.83141642  0.02      ]\n",
      "[-0.52914012 -0.09839102  0.13707113 -0.57596282  0.17379744 -0.76268556\n",
      "  0.83141642  0.02      ]\n",
      "[-0.52988972 -0.09855983  0.13684413 -0.58362691  0.17937978 -0.76268556\n",
      "  0.83141642  0.02      ]\n",
      "[-0.5307103  -0.09874414  0.13658755 -0.59129099  0.18496212 -0.76268556\n",
      "  0.83141642  0.02      ]\n",
      "[-0.53160183 -0.09894381  0.13629999 -0.59895507  0.19054446 -0.76268556\n",
      "  0.83141642  0.02      ]\n",
      "[-0.53256425 -0.09915864  0.13598007 -0.60661915  0.1961268  -0.76268556\n",
      "  0.83141642  0.02      ]\n",
      "[-0.53359751 -0.09938844  0.13562639 -0.61428324  0.20170914 -0.76268556\n",
      "  0.83141642  0.02      ]\n",
      "[-0.53470157 -0.09963299  0.13523758 -0.62194732  0.20729148 -0.76268556\n",
      "  0.83141642  0.02      ]\n",
      "[-0.53587637 -0.09989205  0.13481225 -0.6296114   0.21287382 -0.76268556\n",
      "  0.83141642  0.02      ]\n",
      "[-0.53712185 -0.10016535  0.13434901 -0.63727548  0.21845616 -0.76268556\n",
      "  0.83141642  0.02      ]\n",
      "[-0.53843798 -0.10045262  0.13384648 -0.64493957  0.2240385  -0.76268556\n",
      "  0.83141642  0.02      ]\n",
      "[-0.53982469 -0.10075353  0.13330328 -0.65260365  0.22962085 -0.76268556\n",
      "  0.83141642  0.02      ]\n",
      "[-0.54128193 -0.10106775  0.13271802 -0.66026773  0.23520319 -0.76268556\n",
      "  0.83141642  0.02      ]\n",
      "[-0.54280965 -0.10139492  0.13208934 -0.66793181  0.24078553 -0.76268556\n",
      "  0.83141642  0.02      ]\n",
      "[-0.54440778 -0.10173464  0.13141584 -0.6755959   0.24636787 -0.76268556\n",
      "  0.83141642  0.02      ]\n",
      "[-0.54607629 -0.10208651  0.13069615 -0.68325998  0.25195021 -0.76268556\n",
      "  0.83141642  0.02      ]\n",
      "[-0.5478151  -0.10245006  0.1299289  -0.69092406  0.25753255 -0.76268556\n",
      "  0.83141642  0.02      ]\n",
      "[-0.54962416 -0.10282482  0.12911271 -0.69858814  0.26311489 -0.76268556\n",
      "  0.83141642  0.02      ]\n",
      "[-0.55150341 -0.10321029  0.1282462  -0.70625223  0.26869723 -0.76268556\n",
      "  0.83141642  0.02      ]\n",
      "[-0.5534528  -0.10360593  0.12732801 -0.71391631  0.27427957 -0.76268556\n",
      "  0.83141642  0.02      ]\n",
      "[-0.55547226 -0.10401116  0.12635676 -0.72158039  0.27986191 -0.76268556\n",
      "  0.83141642  0.02      ]\n",
      "[-0.5264437  -0.09778059  0.13787201 -0.46100159  0.09006232 -0.94322159\n",
      "  0.58322994  0.02      ]\n",
      "[-0.52613061 -0.09770939  0.13792024 -0.47047989  0.09397852 -0.94322159\n",
      "  0.58322994  0.02      ]\n",
      "[-0.52590598 -0.09765827  0.13795639 -0.47995819  0.09789471 -0.94322159\n",
      "  0.58322994  0.02      ]\n",
      "[-0.52576979 -0.09762727  0.13797923 -0.48943649  0.1018109  -0.94322159\n",
      "  0.58322994  0.02      ]\n",
      "[-0.52572201 -0.0976164   0.13798756 -0.4989148   0.10572709 -0.94322159\n",
      "  0.58322994  0.02      ]\n",
      "[-0.52576261 -0.09762564  0.13798016 -0.5083931   0.10964329 -0.94322159\n",
      "  0.58322994  0.02      ]\n",
      "[-0.52589158 -0.097655    0.13795583 -0.5178714   0.11355948 -0.94322159\n",
      "  0.58322994  0.02      ]\n",
      "[-0.52610888 -0.09770444  0.13791334 -0.5273497   0.11747567 -0.94322159\n",
      "  0.58322994  0.02      ]\n",
      "[-0.52641449 -0.09777395  0.1378515  -0.53682801  0.12139186 -0.94322159\n",
      "  0.58322994  0.02      ]\n",
      "[-0.52680838 -0.09786346  0.13776909 -0.54630631  0.12530806 -0.94322159\n",
      "  0.58322994  0.02      ]\n",
      "[-0.52729052 -0.09797292  0.13766489 -0.55578461  0.12922425 -0.94322159\n",
      "  0.58322994  0.02      ]\n",
      "[-0.52786089 -0.09810225  0.1375377  -0.56526291  0.13314044 -0.94322159\n",
      "  0.58322994  0.02      ]\n",
      "[-0.52851947 -0.09825137  0.13738631 -0.57474122  0.13705663 -0.94322159\n",
      "  0.58322994  0.02      ]\n",
      "[-0.52926621 -0.09842015  0.13720951 -0.58421952  0.14097283 -0.94322159\n",
      "  0.58322994  0.02      ]\n",
      "[-0.53010111 -0.09860847  0.13700609 -0.59369782  0.14488902 -0.94322159\n",
      "  0.58322994  0.02      ]\n",
      "[-0.53102412 -0.09881618  0.13677484 -0.60317612  0.14880521 -0.94322159\n",
      "  0.58322994  0.02      ]\n",
      "[-0.53203522 -0.09904311  0.13651455 -0.61265443  0.1527214  -0.94322159\n",
      "  0.58322994  0.02      ]\n",
      "[-0.53313438 -0.09928907  0.13622401 -0.62213273  0.1566376  -0.94322159\n",
      "  0.58322994  0.02      ]\n",
      "[-0.53432158 -0.09955385  0.13590202 -0.63161103  0.16055379 -0.94322159\n",
      "  0.58322994  0.02      ]\n",
      "[-0.5355968  -0.09983722  0.13554738 -0.64108933  0.16446998 -0.94322159\n",
      "  0.58322994  0.02      ]\n",
      "[-0.53696    -0.10013891  0.13515886 -0.65056764  0.16838617 -0.94322159\n",
      "  0.58322994  0.02      ]\n",
      "[-0.53841116 -0.10045863  0.13473527 -0.66004594  0.17230237 -0.94322159\n",
      "  0.58322994  0.02      ]\n",
      "[-0.53995025 -0.10079608  0.13427541 -0.66952424  0.17621856 -0.94322159\n",
      "  0.58322994  0.02      ]\n",
      "[-0.54157725 -0.10115092  0.13377805 -0.67900254  0.18013475 -0.94322159\n",
      "  0.58322994  0.02      ]\n",
      "[-0.54329214 -0.10152277  0.13324201 -0.68848085  0.18405094 -0.94322159\n",
      "  0.58322994  0.02      ]\n",
      "[-0.54509489 -0.10191124  0.13266608 -0.69795915  0.18796714 -0.94322159\n",
      "  0.58322994  0.02      ]\n",
      "[-0.54698548 -0.1023159   0.13204905 -0.70743745  0.19188333 -0.94322159\n",
      "  0.58322994  0.02      ]\n",
      "[-0.54896389 -0.1027363   0.13138971 -0.71691575  0.19579952 -0.94322159\n",
      "  0.58322994  0.02      ]\n",
      "[-0.55103009 -0.10317193  0.13068688 -0.72639406  0.19971571 -0.94322159\n",
      "  0.58322994  0.02      ]\n",
      "[-0.55318407 -0.10362228  0.12993934 -0.73587236  0.20363191 -0.94322159\n",
      "  0.58322994  0.02      ]\n",
      "[-0.55542579 -0.10408678  0.12914589 -0.74535066  0.2075481  -0.94322159\n",
      "  0.58322994  0.02      ]\n",
      "[-0.55775525 -0.10456484  0.12830533 -0.75482896  0.21146429 -0.94322159\n",
      "  0.58322994  0.02      ]\n",
      "[-0.56017242 -0.10505583  0.12741647 -0.76430727  0.21538048 -0.94322159\n",
      "  0.58322994  0.02      ]\n",
      "[-0.56267727 -0.10555909  0.12647809 -0.77378557  0.21929668 -0.94322159\n",
      "  0.58322994  0.02      ]\n",
      "[-0.5264437  -0.09778059  0.13787201 -0.46100159  0.09006232 -0.86892124\n",
      "  0.64540666  0.02      ]\n",
      "[-0.52612771 -0.09770873  0.13792078 -0.46973324  0.09439593 -0.86892124\n",
      "  0.64540666  0.02      ]\n",
      "[-0.52589322 -0.09765537  0.13795876 -0.47846489  0.09872953 -0.86892124\n",
      "  0.64540666  0.02      ]\n",
      "[-0.5257402  -0.09762054  0.1379847  -0.48719654  0.10306313 -0.86892124\n",
      "  0.64540666  0.02      ]\n",
      "[-0.52566864 -0.09760424  0.13799736 -0.4959282   0.10739674 -0.86892124\n",
      "  0.64540666  0.02      ]\n",
      "[-0.52567849 -0.09760649  0.13799552 -0.50465985  0.11173034 -0.86892124\n",
      "  0.64540666  0.02      ]\n",
      "[-0.52576974 -0.09762726  0.13797793 -0.5133915   0.11606394 -0.86892124\n",
      "  0.64540666  0.02      ]\n",
      "[-0.52594236 -0.09766655  0.13794337 -0.52212315  0.12039754 -0.86892124\n",
      "  0.64540666  0.02      ]\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for x in test_data:\n",
    "    if i < 100:\n",
    "        print test_data[i,:]\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.95341616  0.86100332  1.85468962 -1.04898425  1.99619798 -0.29372734\n",
      "   3.39019925  1.35962904]]\n",
      "[-0.00196064 -0.00026777  0.13562027 -0.10375793  0.09954461]\n"
     ]
    }
   ],
   "source": [
    "print unnormalize_data(test_data[1:2,:], meanx, minx, maxx)\n",
    "print test_labels[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.29162416  0.00804919  0.03366669  0.27424605  0.00841767  0.05690521\n",
      "  0.00058458  0.        ]\n",
      "[-3.23727242 -2.3730294  -1.54712097 -1.27228815 -0.6063877  -1.05684408\n",
      " -0.20053342  0.02      ] [ 5.20444778  2.72492031  1.35288862  2.70801442  0.58511506  0.94307371\n",
      "  0.19941189  0.02      ]\n",
      "norm_a: [[-0.06520279  0.71244538  2.1127168   1.51138802  8.39648689]]\n",
      "unnorm_a:  [[ 1.  2.  3.  4.  5.]]\n"
     ]
    }
   ],
   "source": [
    "a = np.asarray([[1, 2, 3, 4, 5]])\n",
    "print meanx\n",
    "print minx,maxx\n",
    "norm_a = normalize_test_data(a, np.asarray([meanx[0:5]]), np.asarray([minx]), np.asarray([maxx]))\n",
    "print 'norm_a:', norm_a\n",
    "unnorm_a = unnormalize_data(norm_a, np.asarray([meanx[0:5]]), np.asarray([minx[0:5]]), \n",
    "                            np.asarray([maxx[0:5]]))\n",
    "print 'unnorm_a: ',unnorm_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.29162415862083435, 0.008049188181757927, 0.033666692674160004, 0.27424606680870056, 0.008417674340307713, 0.05690521001815796, 0.0005845790728926659, 0.0]\n",
      "[0.6776861548423767, -0.06710384786128998, -0.05981121584773064, 0.4085806608200073, -0.004740194883197546, 0.04174768552184105, 0.0003070685488637537, 0.0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "blob = caffe.proto.caffe_pb2.BlobProto()\n",
    "data = open( \"toycar_mean.binaryproto\" , 'rb' ).read()\n",
    "blob.ParseFromString(data)\n",
    "# arr = np.array( caffe.io.blobproto_to_array(blob) )\n",
    "# out = arr[0]\n",
    "print blob.data\n",
    "\n",
    "data = open( \"../prx_ws/src/prx_learn/data/toy_car/toy_car_mean.binaryproto\" , 'rb' ).read()\n",
    "blob.ParseFromString(data)\n",
    "print blob.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
