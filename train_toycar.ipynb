{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Requirements:\n",
    " - Caffe (script to install Caffe and pycaffe on a new Ubuntu 14.04 LTS x64 or Ubuntu 14.10 x64. \n",
    "   CPU only, multi-threaded Caffe. http://stackoverflow.com/a/31396229/395857)\n",
    " - sudo pip install pydot\n",
    " - sudo apt-get install -y graphviz\n",
    "\n",
    "Interesting resources on Caffe:\n",
    " - https://github.com/BVLC/caffe/tree/master/examples\n",
    " - http://nbviewer.ipython.org/github/joyofdata/joyofdata-articles\\\n",
    " /blob/master/deeplearning-with-caffe/\\\n",
    " Neural-Networks-with-Caffe-on-the-GPU.ipynb\n",
    "'''\n",
    "\n",
    "import subprocess\n",
    "import platform\n",
    "import copy\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# from sklearn.datasets import load_iris\n",
    "import sklearn.metrics\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import caffe\n",
    "import caffe.draw\n",
    "import google.protobuf \n",
    "\n",
    "# Globals\n",
    "train_data, train_labels, test_data, test_labels = [], [], [], []\n",
    "\n",
    "def load_data():\n",
    "    '''\n",
    "    Load Sample for Forward Pass from Toy Car Data set\n",
    "    '''\n",
    "    start_states, controls, durations, end_states = [], [], [], []\n",
    "\n",
    "    with open('data_output_50Hz.txt', 'r') as infile:\n",
    "        data = infile.readlines()\n",
    "\n",
    "        idx, i = 0, 0\n",
    "\n",
    "        for line in data:\n",
    "            # Stop at end of file\n",
    "            if line == '':\n",
    "                break\n",
    "\n",
    "            # Reset and continue at Trajectory break\n",
    "            if len(line) == 1:\n",
    "                start_states.pop()\n",
    "                i = 0\n",
    "                if idx > 1000000:\n",
    "                    break\n",
    "                continue\n",
    "                \n",
    "            # Split Values in line and append to individual lists\n",
    "            vals = line.split(',')\n",
    "            if i % 3 == 0:\n",
    "                start_states.append([float(val) for val in vals])\n",
    "                if i != 0:\n",
    "                    end_states.append([float(val) for val in vals])\n",
    "                    idx += 1\n",
    "            elif i % 3 == 1:\n",
    "                controls.append([float(val) for val in vals])\n",
    "            elif i % 3 == 2:\n",
    "                durations.append([float(val) for val in vals])\n",
    "                \n",
    "            i += 1\n",
    "            \n",
    "    X = np.concatenate((start_states, controls, durations), axis=1)\n",
    "    start_states = np.asarray(start_states, dtype=np.float32)\n",
    "    end_states = np.asarray(end_states, dtype=np.float32)\n",
    "    \n",
    "    X = normalize_data(X)\n",
    "    y = normalize_labels(start_states, end_states)\n",
    "\n",
    "    # Shuffle the data around and split 3M training, ~750k validation\n",
    "    indices = np.random.permutation(X.shape[0])\n",
    "    training_idx = indices[:900000]\n",
    "    \n",
    "    train_X = X[training_idx, :]\n",
    "    train_y = y[training_idx, :]\n",
    "\n",
    "    test_X = X[900000:1000000, :]\n",
    "    test_y = y[900000:1000000, :]\n",
    "\n",
    "    return train_X, train_y, test_X, test_y\n",
    "\n",
    "\n",
    "def write_binaryproto(data, string):\n",
    "    blob = caffe.proto.caffe_pb2.BlobProto()\n",
    "    blob.channels = data.shape[0]\n",
    "    blob.data.extend(data.astype(float).flat)\n",
    "    binaryproto_file = open('toycar_' + string + '.binaryproto', 'wb')\n",
    "    binaryproto_file.write(blob.SerializeToString())\n",
    "    binaryproto_file.close()\n",
    "\n",
    "\n",
    "def save_binaryproto(data, ftype='mean'):\n",
    "    '''\n",
    "    Take the mean values of the raw data and store them as binaryproto type\n",
    "    In order to use them later for deploy normalization\n",
    "    '''\n",
    "    # Convert to 32bit float\n",
    "    data = np.array(data, dtype=np.float32)\n",
    "\n",
    "    # Set project home dir \n",
    "    PROJECT_HOME = os.path.abspath('.')\n",
    "\n",
    "    # Initialize blob to store serialized means\n",
    "    blob = caffe.proto.caffe_pb2.BlobProto()\n",
    "\n",
    "    # Custom dimensions for blob for this project\n",
    "    blob.num = 1\n",
    "    blob.channels = data.shape[0]\n",
    "    blob.height = 1\n",
    "    blob.width = 1\n",
    "    \n",
    "    # Reshape data and copy into blob\\n\",\n",
    "    blob.data.extend(data.astype(float).flat)\n",
    "    \n",
    "    # Write file\n",
    "    binaryproto_file = open(PROJECT_HOME + '/toycar_' + ftype + '.binaryproto', 'wb')\n",
    "    binaryproto_file.write(blob.SerializeToString())\n",
    "    binaryproto_file.close()\n",
    "\n",
    "\n",
    "\n",
    "def normalize_labels(start_states, end_states):\n",
    "    '''\n",
    "    Normalize end states such that positional coordinates e.g. (x,y)\n",
    "    are now represented by delta_(x,y)\n",
    "    '''\n",
    "    y = end_states\n",
    "    y[:, 0] = end_states[:, 0] - start_states[:, 0]\n",
    "    y[:, 1] = end_states[:, 1] - start_states[:, 1]\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "def unnormalize_data(data, meanx, minx, maxx):\n",
    "    desired_min = -1\n",
    "    desired_max = 1\n",
    "    desired_rng = desired_max - desired_min\n",
    "    \n",
    "    data = data - desired_min\n",
    "    for i in range(0, 7):\n",
    "        data[:, i] = data[:, i] * (maxx[i] - minx[i]) \\\n",
    "                    / desired_rng + minx[i] + meanx[i]\n",
    "        \n",
    "    return data\n",
    "\n",
    "\n",
    "def normalize_data(data):\n",
    "    '''\n",
    "    Normalize data to zero mean on [-1,1] interval for all dimensions\n",
    "    '''\n",
    "    X_mean = np.mean(data, axis=0)\n",
    "    \n",
    "    # do not substract duration\n",
    "    X_mean[7] = 0\n",
    "    \n",
    "    # Mean Shift\n",
    "    data_t = data - X_mean\n",
    "    \n",
    "    # Find bounds, define desired bounds\n",
    "    X_min = np.min(data_t, axis=0)\n",
    "    X_max = np.max(data_t, axis=0)\n",
    "\n",
    "    # Write 'em Out\n",
    "    save_binaryproto(X_mean, ftype=\"mean\")\n",
    "    save_binaryproto(X_min, ftype=\"min\")\n",
    "    save_binaryproto(X_max, ftype=\"max\")\n",
    "\n",
    "    desiredMin = -1\n",
    "    desiredMax = 1\n",
    "    \n",
    "    # Normalize \n",
    "    for i in range(0, 7):\n",
    "        data_t[:, i] = (data_t[:, i] - X_min[i]) * (desiredMax - desiredMin)\\\n",
    "            / (X_max[i] - X_min[i]) + desiredMin\n",
    "\n",
    "    return data_t\n",
    "\n",
    "\n",
    "def save_data_as_hdf5(hdf5_data_filename, data, labels):\n",
    "    '''\n",
    "    HDF5 is one of the data formats Caffe accepts\n",
    "    '''\n",
    "    with h5py.File(hdf5_data_filename, 'w') as f:\n",
    "        f['data'] = data.astype(np.float32)\n",
    "        f['label'] = labels.astype(np.float32)\n",
    "\n",
    "\n",
    "def train(solver_prototxt_filename):\n",
    "    '''\n",
    "    Train the ANN\n",
    "    '''\n",
    "    # caffe.set_mode_gpu()\n",
    "    solver = caffe.get_solver(solver_prototxt_filename)\n",
    "    solver.solve()\n",
    "\n",
    "\n",
    "def print_network_parameters(net):\n",
    "    '''\n",
    "    Print the parameters of the network\n",
    "    '''\n",
    "    print(net)\n",
    "    print('net.inputs: {0}'.format(net.inputs))\n",
    "    print('net.outputs: {0}'.format(net.outputs))\n",
    "    print('net.blobs: {0}'.format(net.blobs))\n",
    "    print('net.params: {0}'.format(net.params))    \n",
    "\n",
    "\n",
    "def get_predicted_output(deploy_prototxt_filename, \n",
    "                         caffemodel_filename, input, net=None):\n",
    "    '''\n",
    "    Get the predicted output, i.e. perform a forward pass\n",
    "    '''\n",
    "    if net is None:\n",
    "        net = caffe.Net(deploy_prototxt_filename, \n",
    "                        caffemodel_filename, caffe.TEST)\n",
    "    \n",
    "#     print \"Input: \"\n",
    "#     print input \n",
    "    out = net.forward(data=input)\n",
    "    return out[net.outputs[0]]\n",
    "\n",
    "\n",
    "def print_network(prototxt_filename, caffemodel_filename):\n",
    "    '''\n",
    "    Draw the ANN architecture\n",
    "    '''\n",
    "    _net = caffe.proto.caffe_pb2.NetParameter()\n",
    "    f = open(prototxt_filename)\n",
    "    google.protobuf.text_format.Merge(f.read(), _net)\n",
    "    caffe.draw.draw_net_to_file(_net, prototxt_filename + '.png')\n",
    "    print('Draw ANN done!')\n",
    "\n",
    "\n",
    "def print_network_weights(prototxt_filename, caffemodel_filename):\n",
    "    '''\n",
    "    For each ANN layer, print weight heatmap and weight histogram \n",
    "    '''\n",
    "    net = caffe.Net(prototxt_filename, caffemodel_filename, caffe.TEST)\n",
    "    for layer_name in net.params: \n",
    "        # weights heatmap \n",
    "        arr = net.params[layer_name][0].data\n",
    "        plt.clf()\n",
    "        fig = plt.figure(figsize=(10, 10))\n",
    "        ax = fig.add_subplot(111)\n",
    "        cax = ax.matshow(arr, interpolation='none')\n",
    "        fig.colorbar(cax, orientation=\"horizontal\")\n",
    "        plt.savefig('{0}_weights_{1}.png'.format(caffemodel_filename, \n",
    "                                                 layer_name), \n",
    "                    dpi=100, format='png', bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        # weights histogram  \n",
    "        plt.clf()\n",
    "        plt.hist(arr.tolist(), bins=20)\n",
    "        # savefig: use format='svg' or 'pdf' for vectorial pictures\n",
    "        plt.savefig('{0}_weights_hist_{1}.png'.format(caffemodel_filename, \n",
    "                                                      layer_name), dpi=100, \n",
    "                    format='png', \n",
    "                    bbox_inches='tight')  \n",
    "        plt.close()\n",
    "\n",
    "\n",
    "def get_predicted_outputs(deploy_prototxt_filename, \n",
    "                          caffemodel_filename, inputs):\n",
    "    '''\n",
    "    Get several predicted outputs\n",
    "    '''\n",
    "    outputs = []\n",
    "    net = caffe.Net(deploy_prototxt_filename, caffemodel_filename, caffe.TRAIN)\n",
    "    outputs.append(copy.deepcopy(get_predicted_output(deploy_prototxt_filename, \n",
    "                                                      caffemodel_filename, \n",
    "                                                      inputs, net)))\n",
    "    return outputs    \n",
    "\n",
    "\n",
    "def get_accuracy(true_outputs, predicted_outputs):\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    number_of_samples = true_outputs.shape[0]\n",
    "    number_of_outputs = true_outputs.shape[1]\n",
    "    threshold = 0.0  # 0 if SigmoidCrossEntropyLoss ; 0.5 if EuclideanLoss\n",
    "    for output_number in range(number_of_outputs):\n",
    "        predicted_output_binary = []\n",
    "        for sample_number in range(number_of_samples):\n",
    "            # print(predicted_outputs)\n",
    "            # print(predicted_outputs[sample_number][output_number])            \n",
    "            if predicted_outputs[sample_number][0][output_number] < threshold:\n",
    "                predicted_output = 0\n",
    "            else:\n",
    "                predicted_output = 1\n",
    "            predicted_output_binary.append(predicted_output)\n",
    "\n",
    "        print('accuracy: {0}'.format(sklearn.metrics.accuracy_score(\n",
    "                                     true_outputs[:, output_number], \n",
    "                                     predicted_output_binary)))\n",
    "        print(sklearn.metrics.confusion_matrix(true_outputs[:, output_number], \n",
    "                                               predicted_output_binary))\n",
    "\n",
    "\n",
    "def training(model_iter):\n",
    "    '''\n",
    "    Performs Training of the specified network and outputs PNG images\n",
    "    showing resulting learned weights and histograms of weights\n",
    "    '''\n",
    "    # Set parameters\n",
    "    solver_prototxt_filename = 'toycar_solver.prototxt'\n",
    "    train_test_prototxt_filename = 'toycar_2fc_hdf5.prototxt'\n",
    "    caffemodel_filename = '2fc_iter_' + str(model_iter) + '.caffemodel' \n",
    "\n",
    "    # Train network\n",
    "    train(solver_prototxt_filename)\n",
    "\n",
    "    # Print network\n",
    "    print_network(train_test_prototxt_filename, caffemodel_filename)\n",
    "    print_network_weights(train_test_prototxt_filename, caffemodel_filename)\n",
    "\n",
    "\n",
    "def testing(deploy_prototxt_filename, caffemodel_filename, inputs, labels):\n",
    "    '''\n",
    "    Performs Testing of the specified network\n",
    "    '''    \n",
    "    # Compute performance metrics\n",
    "    outputs = get_predicted_outputs(deploy_prototxt_filename, \n",
    "                                    caffemodel_filename, inputs)\n",
    "    \n",
    "#     print 'predictions: '\n",
    "#     print outputs[0]\n",
    "    \n",
    "#     print 'ground truths: '\n",
    "#     print labels\n",
    "    \n",
    "    return outputs[0]\n",
    "    \n",
    "    \n",
    "def euclidean_loss(pred, labels):\n",
    "    '''\n",
    "    Hand Calculate the Euclidean Loss to Compare with Model Output\n",
    "    '''\n",
    "    result = labels-pred\n",
    "    size = pred.shape[0]\n",
    "    \n",
    "    loss = np.sum(np.square(result), axis=1)\n",
    "    loss = np.sum(loss, axis=0) / (2 * size)\n",
    "    \n",
    "    print \"Euclidean Loss: \", loss\n",
    "\n",
    "\n",
    "def main(arg=\"x\"):\n",
    "\n",
    "    if arg.lower() == \"train\":\n",
    "        train_data, train_labels, test_data, test_labels = load_data()\n",
    "\n",
    "        # save_data_as_hdf5('toycar_hdf5_data_random_norm11_train.hdf5', \n",
    "        #                   train_data, train_labels)\n",
    "        # save_data_as_hdf5('toycar_hdf5_data_random_norm11_test.hdf5', \n",
    "        #                   test_data, test_labels)\n",
    "        \n",
    "        solver_name = \"toycar_solver.prototxt\"\n",
    "        training(20000)\n",
    "\n",
    "    elif arg.lower() == \"test\":\n",
    "        \n",
    "        train_data, train_labels, test_data, test_labels = load_data()\n",
    "\n",
    "        pred = testing('toycar_2fc_deploy.prototxt', \n",
    "               '2fc_iter_100000.caffemodel', \n",
    "               test_data[0:1, :], test_labels[0:1, :])\n",
    "        print \"Input: \", test_data[0:1, :]\n",
    "#             pred[0, 0] = pred[0, 0] + test_data[0, 0]\n",
    "#             pred[0, 1] = pred[0, 1] + test_data[0, 1]\n",
    "        print \"Pred: \", pred\n",
    "        print \"Label: \", test_labels[0:1, :]\n",
    "        print \"Loss: \", euclidean_loss(pred, test_labels[0:1, :])\n",
    "\n",
    "\n",
    "        for i in range(1, 100):\n",
    "            \n",
    "#             print pred.shape\n",
    "#             print test_data[i:i+1,5:8].shape\n",
    "            inpt = np.asarray([np.concatenate((pred[0,:], test_data[i, 5:8]), axis=0)])\n",
    "            inpt[0, 0] = inpt[0, 0] + test_data[i-1, 0]\n",
    "            inpt[0, 1] = inpt[0, 1] + test_data[i-1, 1]\n",
    "            print \"Input: \", inpt\n",
    "            pred = testing('toycar_2fc_deploy.prototxt', \n",
    "                           '2fc_iter_100000.caffemodel', \n",
    "                           inpt,  test_labels[i:i+1, :])\n",
    "            \n",
    "            print \"Pred: \", pred\n",
    "            print \"Label: \", test_labels[i:i+1, :]\n",
    "            print \"Loss: \", euclidean_loss(pred, test_labels[i:i+1, :])\n",
    "    else:\n",
    "        train_data, train_labels, test_data, test_labels = load_data()\n",
    "\n",
    "\n",
    "    # result = pred - test_labels[:1000, :]\n",
    "    # print np.sqrt(np.sum(np.square(result), axis=1)).shape\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  [[-0.52753878 -0.09802863  0.13742372 -0.54690999  0.16745029 -0.37171077\n",
      "   0.50107972  0.02      ]]\n",
      "Pred:  [[-0.00133245 -0.0015051   0.1356848  -0.09937215  0.09792732]]\n",
      "Label:  [[-0.00196064 -0.00026777  0.13562027 -0.10375793  0.09954461]]\n",
      "Loss:  Euclidean Loss:  1.18902516988e-05\n",
      "None\n",
      "Input:  [[-0.52887122 -0.09953372  0.1356848  -0.09937215  0.09792732 -0.37171077\n",
      "   0.50107972  0.02      ]]\n",
      "Pred:  [[ 0.01502542  0.00126004  0.12019791  0.78664249  0.05610812]]\n",
      "Label:  [[-0.00210685 -0.00028731  0.13540609 -0.11119144  0.10154913]]\n",
      "Loss:  Euclidean Loss:  0.404348939657\n",
      "None\n",
      "Input:  [[-0.51297786 -0.09687363  0.12019791  0.78664249  0.05610812 -0.37171077\n",
      "   0.50107972  0.02      ]]\n",
      "Pred:  [[  4.88878787e-02  -1.76408421e-03   8.45824257e-02   2.60937858e+00\n",
      "    1.70599855e-02]]\n",
      "Label:  [[-0.002253   -0.00030673  0.13517247 -0.11862496  0.10355365]]\n",
      "Loss:  Euclidean Loss:  3.72733068466\n",
      "None\n",
      "Input:  [[-0.47961456 -0.10001047  0.08458243  2.60937858  0.01705999 -0.37171077\n",
      "   0.50107972  0.02      ]]\n",
      "Pred:  [[ 0.12328307  0.01121805  0.06225712  6.33966351 -0.06708111]]\n",
      "Label:  [[-0.00239915 -0.00032603  0.13491879 -0.12605846  0.10555818]]\n",
      "Loss:  Euclidean Loss:  20.9282875061\n",
      "None\n",
      "Input:  [[-0.40575315 -0.08714868  0.06225712  6.33966351 -0.06708111 -0.37171077\n",
      "   0.50107972  0.02      ]]\n",
      "Pred:  [[  0.26024759   0.0261823    0.2199263   13.94607925  -0.28700891]]\n",
      "Label:  [[-0.00254524 -0.0003452   0.13464448 -0.13349198  0.1075627 ]]\n",
      "Loss:  Euclidean Loss:  99.2335205078\n",
      "None\n",
      "Input:  [[ -0.26935703  -0.07231233   0.2199263   13.94607925  -0.28700891\n",
      "   -0.37171077   0.50107972   0.02      ]]\n",
      "Pred:  [[  0.54706728   0.07890432   0.69861847  29.57315063  -0.74779373]]\n",
      "Label:  [[-0.00269121 -0.00036423  0.13434893 -0.14092548  0.10956722]]\n",
      "Loss:  Euclidean Loss:  442.144165039\n",
      "None\n",
      "Input:  [[  1.68596589e-02  -1.97257419e-02   6.98618472e-01   2.95731506e+01\n",
      "   -7.47793734e-01  -3.71710775e-01   5.01079724e-01   2.00000000e-02]]\n",
      "Pred:  [[  1.13006318   0.19607276   1.83033884  61.72912979  -1.66944826]]\n",
      "Label:  [[-0.00283718 -0.0003831   0.13403155 -0.14835899  0.11157174]]\n",
      "Loss:  Euclidean Loss:  1918.09753418\n",
      "None\n",
      "Input:  [[  5.99217952e-01   9.72998080e-02   1.83033884e+00   6.17291298e+01\n",
      "   -1.66944826e+00  -3.71710775e-01   5.01079724e-01   2.00000000e-02]]\n",
      "Pred:  [[   2.3270638     0.44679701    4.31395102  127.95830536   -3.51960397]]\n",
      "Label:  [[-0.00298303 -0.0004018   0.13369176 -0.1557925   0.11357626]]\n",
      "Loss:  Euclidean Loss:  8224.76367188\n",
      "None\n",
      "Input:  [[  1.79554640e+00   3.47873768e-01   4.31395102e+00   1.27958305e+02\n",
      "   -3.51960397e+00  -3.71710775e-01   5.01079724e-01   2.00000000e-02]]\n",
      "Pred:  [[   4.79013634    0.97090214    9.7439127   264.33526611   -7.34949541]]\n",
      "Label:  [[-0.00312895 -0.00042034  0.13332896 -0.16322601  0.11558078]]\n",
      "Loss:  Euclidean Loss:  35065.734375\n",
      "None\n",
      "Input:  [[  4.25791219e+00   8.71821265e-01   9.74391270e+00   2.64335266e+02\n",
      "   -7.34949541e+00  -3.71710775e-01   5.01079724e-01   2.00000000e-02]]\n",
      "Pred:  [[   9.87200832    2.0643487    21.37353325  545.21942139  -15.29162693]]\n",
      "Label:  [[-0.00327468 -0.00043868  0.13294257 -0.17065951  0.1175853 ]]\n",
      "Loss:  Euclidean Loss:  149120.359375\n",
      "None\n",
      "Input:  [[  9.33904288e+00   1.96510291e+00   2.13735332e+01   5.45219421e+02\n",
      "   -1.52916269e+01  -3.71710775e-01   5.01079724e-01   2.00000000e-02]]\n",
      "Pred:  [[   20.34148788     4.33863258    45.87036133  1123.85778809\n",
      "    -31.67696381]]\n",
      "Label:  [[-0.00342041 -0.00045682  0.132532   -0.17809303  0.11958983]]\n",
      "Loss:  Euclidean Loss:  633496.1875\n",
      "None\n",
      "Input:  [[  1.98077466e+01   4.23921470e+00   4.58703613e+01   1.12385779e+03\n",
      "   -3.16769638e+01  -3.71710775e-01   5.01079724e-01   2.00000000e-02]]\n",
      "Pred:  [[   41.9119606      9.05230618    97.04033661  2316.03295898\n",
      "    -65.45178986]]\n",
      "Label:  [[-0.00356609 -0.00047476  0.13209665 -0.18552653  0.12159435]]\n",
      "Loss:  Euclidean Loss:  2690199.0\n",
      "None\n",
      "Input:  [[  4.13774090e+01   8.95270907e+00   9.70403366e+01   2.31603296e+03\n",
      "   -6.54517899e+01  -3.71710775e-01   5.01079724e-01   2.00000000e-02]]\n",
      "Pred:  [[   86.35704803    18.80089378   203.38264465  4772.47167969\n",
      "   -135.05511475]]\n",
      "Label:  [[-0.0037117  -0.00049245  0.13163593 -0.19296005  0.12359887]]\n",
      "Loss:  Euclidean Loss:  11422861.0\n",
      "None\n",
      "Input:  [[  8.58216515e+01   1.87011104e+01   2.03382645e+02   4.77247168e+03\n",
      "   -1.35055115e+02  -3.71710775e-01   5.01079724e-01   2.00000000e-02]]\n",
      "Pred:  [[  177.93861389    38.93555069   423.68814087  9834.12597656\n",
      "   -278.48657227]]\n",
      "Label:  [[-0.00385731 -0.00050991  0.13114925 -0.20039356  0.12560339]]\n",
      "Loss:  Euclidean Loss:  48502088.0\n",
      "None\n",
      "Input:  [[  1.77402338e+02   3.88355741e+01   4.23688141e+02   9.83412598e+03\n",
      "   -2.78486572e+02  -3.71710775e-01   5.01079724e-01   2.00000000e-02]]\n",
      "Pred:  [[   366.64260864     80.48555756    879.1965332   20264.34179688\n",
      "    -574.07794189]]\n",
      "Label:  [[-0.00400275 -0.00052712  0.13063602 -0.20782706  0.12760791]]\n",
      "Loss:  Euclidean Loss:  205947664.0\n",
      "None\n",
      "Input:  [[  3.66105419e+02   8.03853810e+01   8.79196533e+02   2.02643418e+04\n",
      "   -5.74077942e+02  -3.71710775e-01   5.01079724e-01   2.00000000e-02]]\n",
      "Pred:  [[   755.49536133    166.1854248    1819.84960938  41757.60546875\n",
      "   -1183.22644043]]\n",
      "Label:  [[-0.00414819 -0.00054406  0.13009568 -0.21526058  0.12961243]]\n",
      "Loss:  Euclidean Loss:  874512832.0\n",
      "None\n",
      "Input:  [[  7.54957223e+02   1.66085041e+02   1.81984961e+03   4.17576055e+04\n",
      "   -1.18322644e+03  -3.71710775e-01   5.01079724e-01   2.00000000e-02]]\n",
      "Pred:  [[  1556.79785156    342.8899231    3760.85083008  86048.7578125\n",
      "   -2438.53369141]]\n",
      "Label:  [[-0.00429356 -0.00056072  0.12952758 -0.22269408  0.13161695]]\n",
      "Loss:  Euclidean Loss:  3713529344.0\n",
      "None\n",
      "Input:  [[  1.55625873e+03   3.42789326e+02   3.76085083e+03   8.60487578e+04\n",
      "   -2.43853369e+03  -3.71710775e-01   5.01079724e-01   2.00000000e-02]]\n",
      "Pred:  [[   3208.04589844     707.16107178    7764.07470703  177320.1875\n",
      "    -5025.40039062]]\n",
      "Label:  [[-0.004439   -0.00057708  0.12893119 -0.23012759  0.13362147]]\n",
      "Loss:  Euclidean Loss:  15769428992.0\n",
      "None\n",
      "Input:  [[  3.20750576e+03   7.07060255e+02   7.76407471e+03   1.77320188e+05\n",
      "   -5.02540039e+03  -3.71710775e-01   5.01079724e-01   2.00000000e-02]]\n",
      "Pred:  [[   6610.80322266    1457.99719238   16018.02441406  365405.53125\n",
      "   -10356.2734375 ]]\n",
      "Label:  [[-0.00458419 -0.00059313  0.1283059  -0.23756111  0.13562599]]\n",
      "Loss:  Euclidean Loss:  66965520384.0\n",
      "None\n",
      "Input:  [[  6.61026203e+03   1.45789615e+03   1.60180244e+04   3.65405531e+05\n",
      "   -1.03562734e+04  -3.71710775e-01   5.01079724e-01   2.00000000e-02]]\n",
      "Pred:  [[  13622.95898438    3005.49609375   33032.8984375   752998.875\n",
      "   -21341.83398438]]\n",
      "Label:  [[-0.00472939 -0.00060885  0.12765111 -0.24499461  0.13763052]]\n",
      "Loss:  Euclidean Loss:  284374466560.0\n",
      "None\n",
      "Input:  [[  1.36224167e+04   3.00539482e+03   3.30328984e+04   7.52998875e+05\n",
      "   -2.13418340e+04  -3.71710775e-01   5.01079724e-01   2.00000000e-02]]\n",
      "Pred:  [[   28073.13867188     6194.77294922    68103.5390625   1551726.125\n",
      "    -43980.23046875]]\n",
      "Label:  [[-0.00487447 -0.00062423  0.12696625 -0.25242811  0.13963504]]\n",
      "Loss:  Euclidean Loss:  1.20762689126e+12\n",
      "None\n",
      "Input:  [[  2.80725953e+04   6.19467143e+03   6.81035391e+04   1.55172612e+06\n",
      "   -4.39802305e+04  -3.71710775e-01   5.01079724e-01   2.00000000e-02]]\n",
      "Pred:  [[   57851.1484375    12767.421875    140384.5        3197693.25\n",
      "    -90632.2578125]]\n",
      "Label:  [[-0.00501966 -0.00063925  0.12625073 -0.25986162  0.14163956]]\n",
      "Loss:  Euclidean Loss:  5.12833775206e+12\n",
      "None\n",
      "Input:  [[  5.78506039e+04   1.27673201e+04   1.40384500e+05   3.19769325e+06\n",
      "   -9.06322578e+04  -3.71710775e-01   5.01079724e-01   2.00000000e-02]]\n",
      "Pred:  [[  119215.8359375     26312.43945312   289349.15625     6589602.\n",
      "   -186769.875     ]]\n",
      "Label:  [[-0.00516462 -0.0006539   0.12550396 -0.26729515  0.14364408]]\n",
      "Loss:  Euclidean Loss:  2.17781874196e+13\n",
      "None\n",
      "Input:  [[  1.19215290e+05   2.63123374e+04   2.89349156e+05   6.58960200e+06\n",
      "   -1.86769875e+05  -7.62685563e-01   8.31416416e-01   2.00000000e-02]]\n",
      "Pred:  [[   245672.4375         54225.84765625    596343.875       13579446.\n",
      "    -384884.75      ]]\n",
      "Label:  [[ 0.00135124  0.00018559  0.13653767  0.05939361  0.05476179]]\n",
      "Loss:  Euclidean Loss:  9.2484210262e+13\n",
      "None\n",
      "Input:  [[  2.45671911e+05   5.42257499e+04   5.96343875e+05   1.35794460e+07\n",
      "   -3.84884750e+05  -7.62685563e-01   8.31416416e-01   2.00000000e-02]]\n",
      "Pred:  [[   506266.6875       111749.0234375   1229001.         27983702.\n",
      "    -793149.0625   ]]\n",
      "Label:  [[ 0.00104922  0.00014418  0.13659716  0.04414092  0.05808748]]\n",
      "Loss:  Euclidean Loss:  3.92747949228e+14\n",
      "None\n",
      "Input:  [[  5.06266161e+05   1.11748926e+05   1.22900100e+06   2.79837020e+07\n",
      "   -7.93149062e+05  -7.62685563e-01   8.31416416e-01   2.00000000e-02]]\n",
      "Pred:  [[  1043283.875      230290.53125   2532770.5      57667144.       -1634475.625  ]]\n",
      "Label:  [[  7.47382641e-04   1.02743506e-04   1.36642039e-01   2.88882405e-02\n",
      "    6.14131689e-02]]\n",
      "Loss:  Euclidean Loss:  1.66786371053e+15\n",
      "None\n",
      "Input:  [[  1.04328335e+06   2.30290434e+05   2.53277050e+06   5.76671440e+07\n",
      "   -1.63447562e+06  -7.62685563e-01   8.31416416e-01   2.00000000e-02]]\n",
      "Pred:  [[  2.14993775e+06   4.74575156e+05   5.21954000e+06   1.18837056e+08\n",
      "   -3.36823150e+06]]\n",
      "Label:  [[  4.45544720e-04   6.12661242e-05   1.36670291e-01   1.36355562e-02\n",
      "    6.47388548e-02]]\n",
      "Loss:  Euclidean Loss:  7.08284076838e+15\n",
      "None\n",
      "Input:  [[  2.14993722e+06   4.74575059e+05   5.21954000e+06   1.18837056e+08\n",
      "   -3.36823150e+06  -7.62685563e-01   8.31416416e-01   2.00000000e-02]]\n",
      "Pred:  [[  4.43046500e+06   9.77984250e+05   1.07563320e+07   2.44892448e+08\n",
      "   -6.94105500e+06]]\n",
      "Label:  [[  1.43945217e-04   1.97961926e-05   1.36679873e-01  -1.61712745e-03\n",
      "    6.80645406e-02]]\n",
      "Loss:  Euclidean Loss:  3.00783861183e+16\n",
      "None\n",
      "Input:  [[  4.43046447e+06   9.77984152e+05   1.07563320e+07   2.44892448e+08\n",
      "   -6.94105500e+06  -7.62685563e-01   8.31416416e-01   2.00000000e-02]]\n",
      "Pred:  [[  9.13004400e+06   2.01538375e+06   2.21662720e+07   5.04660064e+08\n",
      "   -1.43037280e+07]]\n",
      "Label:  [[ -1.57594681e-04  -2.16662884e-05   1.36668772e-01  -1.68698113e-02\n",
      "    7.13902265e-02]]\n",
      "Loss:  Euclidean Loss:  1.27732567901e+17\n",
      "None\n",
      "Input:  [[  9.13004347e+06   2.01538365e+06   2.21662720e+07   5.04660064e+08\n",
      "   -1.43037280e+07  -7.62685563e-01   8.31416416e-01   2.00000000e-02]]\n",
      "Pred:  [[  1.88146620e+07   4.15320050e+06   4.56793120e+07   1.03997414e+09\n",
      "   -2.94762640e+07]]\n",
      "Label:  [[ -4.58955765e-04  -6.31138682e-05   1.36634961e-01  -3.21224965e-02\n",
      "    7.47159198e-02]]\n",
      "Loss:  Euclidean Loss:  5.42436433701e+17\n",
      "None\n",
      "Input:  [[  1.88146615e+07   4.15320040e+06   4.56793120e+07   1.03997414e+09\n",
      "   -2.94762640e+07  -7.62685563e-01   8.31416416e-01   2.00000000e-02]]\n",
      "Pred:  [[  3.87721640e+07   8.55869700e+06   9.41337280e+07   2.14311834e+09\n",
      "   -6.07430240e+07]]\n",
      "Label:  [[ -7.60138035e-04  -1.04501843e-04   1.36576414e-01  -4.73751798e-02\n",
      "    7.80416057e-02]]\n",
      "Loss:  Euclidean Loss:  2.30354173138e+18\n",
      "None\n",
      "Input:  [[  3.87721635e+07   8.55869690e+06   9.41337280e+07   2.14311834e+09\n",
      "   -6.07430240e+07  -7.62685563e-01   8.31416416e-01   2.00000000e-02]]\n",
      "Pred:  [[  7.98994240e+07   1.76372720e+07   1.93985984e+08   4.41641370e+09\n",
      "   -1.25175696e+08]]\n",
      "Label:  [[-0.00106126 -0.00014581  0.13649112 -0.06262786  0.08136729]]\n",
      "Loss:  Euclidean Loss:  9.78235165379e+18\n",
      "None\n",
      "Input:  [[  7.98994235e+07   1.76372719e+07   1.93985984e+08   4.41641370e+09\n",
      "   -1.25175696e+08  -7.62685563e-01   8.31416416e-01   2.00000000e-02]]\n",
      "Pred:  [[  1.64652080e+08   3.63459200e+07   3.99755712e+08   9.10108877e+09\n",
      "   -2.57954880e+08]]\n",
      "Label:  [[-0.00136214 -0.00018702  0.13637705 -0.07788055  0.08469298]]\n",
      "Loss:  Euclidean Loss:  4.15422980764e+19\n",
      "None\n",
      "Input:  [[  1.64652079e+08   3.63459199e+07   3.99755712e+08   9.10108877e+09\n",
      "   -2.57954880e+08  -7.62685563e-01   8.31416416e-01   2.00000000e-02]]\n",
      "Pred:  [[  3.39305440e+08   7.48995680e+07   8.23793792e+08   1.87549983e+10\n",
      "   -5.31578560e+08]]\n",
      "Label:  [[-0.00166291 -0.0002281   0.13623217 -0.09313323  0.08801866]]\n",
      "Loss:  Euclidean Loss:  1.76415954581e+20\n",
      "None\n",
      "Input:  [[  3.39305439e+08   7.48995679e+07   8.23793792e+08   1.87549983e+10\n",
      "   -5.31578560e+08  -7.62685563e-01   8.31416416e-01   2.00000000e-02]]\n",
      "Pred:  [[  6.99220992e+08   1.54348800e+08   1.69762714e+09   3.86492129e+10\n",
      "   -1.09544602e+09]]\n",
      "Label:  [[-0.0019635  -0.000269    0.13605449 -0.10838591  0.09134436]]\n",
      "Loss:  Euclidean Loss:  7.49178231244e+20\n",
      "None\n",
      "Input:  [[  6.99220991e+08   1.54348800e+08   1.69762714e+09   3.86492129e+10\n",
      "   -1.09544602e+09  -7.62685563e-01   8.31416416e-01   2.00000000e-02]]\n",
      "Pred:  [[  1.44091430e+09   3.18072896e+08   3.49837619e+09   7.96460564e+10\n",
      "   -2.25743053e+09]]\n",
      "Label:  [[-0.00226384 -0.00030973  0.13584195 -0.1236386   0.09467004]]\n",
      "Loss:  Euclidean Loss:  3.18150293604e+21\n",
      "None\n",
      "Input:  [[  1.44091430e+09   3.18072896e+08   3.49837619e+09   7.96460564e+10\n",
      "   -2.25743053e+09  -7.62685563e-01   8.31416416e-01   2.00000000e-02]]\n",
      "Pred:  [[  2.96935270e+09   6.55466624e+08   7.20924979e+09   1.64129980e+11\n",
      "   -4.65198746e+09]]\n",
      "Label:  [[-0.00256407 -0.0003502   0.13559256 -0.13889128  0.09799573]]\n",
      "Loss:  Euclidean Loss:  1.35107560979e+22\n",
      "None\n",
      "Input:  [[  2.96935270e+09   6.55466624e+08   7.20924979e+09   1.64129980e+11\n",
      "   -4.65198746e+09  -7.62685563e-01   8.31416416e-01   2.00000000e-02]]\n",
      "Pred:  [[  6.11907021e+09   1.35074765e+09   1.48564029e+10   3.38229559e+11\n",
      "   -9.58654464e+09]]\n",
      "Label:  [[-0.00286412 -0.0003904   0.13530432 -0.15414396  0.10132141]]\n",
      "Loss:  Euclidean Loss:  5.73755575115e+22\n",
      "None\n",
      "Input:  [[  6.11907021e+09   1.35074765e+09   1.48564029e+10   3.38229559e+11\n",
      "   -9.58654464e+09  -7.62685563e-01   8.31416416e-01   2.00000000e-02]]\n",
      "Pred:  [[  1.26098237e+10   2.78354202e+09   3.06152120e+10   6.97003868e+11\n",
      "   -1.97553889e+10]]\n",
      "Label:  [[-0.00316393 -0.00043029  0.13497517 -0.16939665  0.1046471 ]]\n",
      "Loss:  Euclidean Loss:  2.43654341515e+23\n",
      "None\n",
      "Input:  [[  1.26098237e+10   2.78354202e+09   3.06152120e+10   6.97003868e+11\n",
      "   -1.97553889e+10  -7.62685563e-01   8.31416416e-01   2.00000000e-02]]\n",
      "Pred:  [[  2.59855974e+10   5.73616282e+09   6.30900818e+10   1.43634517e+12\n",
      "   -4.07107707e+10]]\n",
      "Label:  [[-0.00346363 -0.00046981  0.13460311 -0.18464933  0.10797279]]\n",
      "Loss:  Euclidean Loss:  1.03471664208e+24\n",
      "None\n",
      "Input:  [[  2.59855974e+10   5.73616282e+09   6.30900818e+10   1.43634517e+12\n",
      "   -4.07107707e+10  -7.62685563e-01   8.31416416e-01   2.00000000e-02]]\n",
      "Pred:  [[  5.35496131e+10   1.18207529e+10   1.30012365e+11   2.95993685e+12\n",
      "   -8.38943375e+10]]\n",
      "Label:  [[-0.00376296 -0.00050893  0.13418616 -0.19990201  0.11129848]]\n",
      "Loss:  Euclidean Loss:  4.39408736064e+24\n",
      "None\n",
      "Input:  [[  5.35496131e+10   1.18207529e+10   1.30012365e+11   2.95993685e+12\n",
      "   -8.38943375e+10  -7.62685563e-01   8.31416416e-01   2.00000000e-02]]\n",
      "Pred:  [[  1.10351917e+11   2.43595223e+10   2.67921981e+11   6.09966621e+12\n",
      "   -1.72884525e+11]]\n",
      "Label:  [[-0.00406224 -0.0005476   0.13372226 -0.21515469  0.11462416]]\n",
      "Loss:  Euclidean Loss:  1.86601844319e+25\n",
      "None\n",
      "Input:  [[  1.10351917e+11   2.43595223e+10   2.67921981e+11   6.09966621e+12\n",
      "   -1.72884525e+11  -7.62685563e-01   8.31416416e-01   2.00000000e-02]]\n",
      "Pred:  [[  2.27406873e+11   5.01987082e+10   5.52118256e+11   1.25698384e+13\n",
      "   -3.56270539e+11]]\n",
      "Label:  [[-0.00436127 -0.00058575  0.13320944 -0.23040739  0.11794985]]\n",
      "Loss:  Euclidean Loss:  7.92434125114e+25\n",
      "None\n",
      "Input:  [[  2.27406873e+11   5.01987082e+10   5.52118256e+11   1.25698384e+13\n",
      "   -3.56270539e+11  -7.62685563e-01   8.31416416e-01   2.00000000e-02]]\n",
      "Pred:  [[  4.68626833e+11   1.03446561e+11   1.13777312e+12   2.59031910e+13\n",
      "   -7.34181655e+11]]\n",
      "Label:  [[-0.00466007 -0.00062336  0.13264565 -0.24566007  0.12127554]]\n",
      "Loss:  Euclidean Loss:  3.36519561812e+26\n",
      "None\n",
      "Input:  [[  4.68626833e+11   1.03446561e+11   1.13777312e+12   2.59031910e+13\n",
      "   -7.34181655e+11  -7.62685563e-01   8.31416416e-01   2.00000000e-02]]\n",
      "Pred:  [[  9.65718966e+11   2.13176697e+11   2.34465867e+12   5.33797913e+13\n",
      "   -1.51296069e+12]]\n",
      "Label:  [[-0.00495863 -0.00066034  0.13202892 -0.26091275  0.12460123]]\n",
      "Loss:  Euclidean Loss:  1.42908343049e+27\n",
      "None\n",
      "Input:  [[  9.65718966e+11   2.13176697e+11   2.34465867e+12   5.33797913e+13\n",
      "   -1.51296069e+12  -7.62685563e-01   8.31416416e-01   2.00000000e-02]]\n",
      "Pred:  [[  1.99009790e+12   4.39302128e+11   4.83173702e+12   1.10001989e+14\n",
      "   -3.11781963e+12]]\n",
      "Label:  [[-0.00525707 -0.00069665  0.13135722 -0.27616543  0.12792692]]\n",
      "Loss:  Euclidean Loss:  6.06882886511e+27\n",
      "None\n",
      "Input:  [[  1.99009790e+12   4.39302128e+11   4.83173702e+12   1.10001989e+14\n",
      "   -3.11781963e+12  -7.62685563e-01   8.31416416e-01   2.00000000e-02]]\n",
      "Pred:  [[  4.10107799e+12   9.05288155e+11   9.95696207e+12   2.26685706e+14\n",
      "   -6.42502047e+12]]\n",
      "Label:  [[-0.00555515 -0.00073223  0.13062856 -0.29141811  0.1312526 ]]\n",
      "Loss:  Euclidean Loss:  2.57722348e+28\n",
      "None\n",
      "Input:  [[  4.10107799e+12   9.05288155e+11   9.95696207e+12   2.26685706e+14\n",
      "   -6.42502047e+12  -7.62685563e-01   8.31416416e-01   2.00000000e-02]]\n",
      "Pred:  [[  8.45126304e+12   1.86556442e+12   2.05187155e+13   4.67140742e+14\n",
      "   -1.32402999e+13]]\n",
      "Label:  [[-0.00585318 -0.00076702  0.12984091 -0.30667081  0.13457829]]\n",
      "Loss:  Euclidean Loss:  1.09445858394e+29\n",
      "None\n",
      "Input:  [[  8.45126304e+12   1.86556442e+12   2.05187155e+13   4.67140742e+14\n",
      "   -1.32402999e+13  -7.62685563e-01   8.31416416e-01   2.00000000e-02]]\n",
      "Pred:  [[  1.74158722e+13   3.84444950e+12   4.22837936e+13   9.62656521e+14\n",
      "   -2.72848493e+13]]\n",
      "Label:  [[-0.00615072 -0.00080094  0.12899229 -0.32192349  0.13790397]]\n",
      "Loss:  Euclidean Loss:  4.64779049358e+29\n",
      "None\n",
      "Input:  [[  1.74158722e+13   3.84444950e+12   4.22837936e+13   9.62656521e+14\n",
      "   -2.72848493e+13  -7.62685563e-01   8.31416416e-01   2.00000000e-02]]\n",
      "Pred:  [[  3.58896191e+13   7.92241530e+12   8.71359777e+13   1.98378661e+15\n",
      "   -5.62270359e+13]]\n",
      "Label:  [[-0.00644827 -0.00083394  0.1280807  -0.33717617  0.14122966]]\n",
      "Loss:  Euclidean Loss:  1.97375712175e+30\n",
      "None\n",
      "Input:  [[  3.58896191e+13   7.92241530e+12   8.71359777e+13   1.98378661e+15\n",
      "   -5.62270359e+13  -7.62685563e-01   8.31416416e-01   2.00000000e-02]]\n",
      "Pred:  [[  7.39592530e+13   1.63260536e+13   1.79564832e+14   4.08807228e+15\n",
      "   -1.15869527e+14]]\n",
      "Label:  [[-0.00674558 -0.00086595  0.12710412 -0.35242885  0.14455535]]\n",
      "Loss:  Euclidean Loss:  8.38187016811e+30\n",
      "None\n",
      "Input:  [[  7.39592530e+13   1.63260536e+13   1.79564832e+14   4.08807228e+15\n",
      "   -1.15869527e+14  -7.62685563e-01   8.31416416e-01   2.00000000e-02]]\n",
      "Pred:  [[  1.52410924e+14   3.36437916e+13   3.70036598e+14   8.42446131e+15\n",
      "   -2.38777096e+14]]\n",
      "Label:  [[-0.00704253 -0.00089689  0.12606058 -0.36768153  0.14788103]]\n",
      "Loss:  Euclidean Loss:  3.55949251629e+31\n",
      "None\n",
      "Input:  [[  1.52410924e+14   3.36437916e+13   3.70036598e+14   8.42446131e+15\n",
      "   -2.38777096e+14  -7.62685563e-01   8.31416416e-01   2.00000000e-02]]\n",
      "Pred:  [[  3.14079550e+14   6.93311656e+13   7.62549969e+14   1.73606401e+16\n",
      "   -4.92057626e+14]]\n",
      "Label:  [[-0.00733924 -0.00092668  0.12494805 -0.38293421  0.15120673]]\n",
      "Loss:  Euclidean Loss:  1.51159432538e+32\n",
      "None\n",
      "Input:  [[  3.14079550e+14   6.93311656e+13   7.62549969e+14   1.73606401e+16\n",
      "   -4.92057626e+14  -7.62685563e-01   8.31416416e-01   2.00000000e-02]]\n",
      "Pred:  [[  6.47236808e+14   1.42873631e+14   1.57141874e+15   3.57757998e+16\n",
      "   -1.01400326e+15]]\n",
      "Label:  [[-0.00763583 -0.00095526  0.12376457 -0.39818689  0.15453242]]\n",
      "Loss:  Euclidean Loss:  6.41922356426e+32\n",
      "None\n",
      "Input:  [[  6.47236808e+14   1.42873631e+14   1.57141874e+15   3.57757998e+16\n",
      "   -1.01400326e+15  -7.62685563e-01   8.31416416e-01   2.00000000e-02]]\n",
      "Pred:  [[  1.33378827e+15   2.94425712e+14   3.23828991e+15   7.37246856e+16\n",
      "   -2.08959876e+15]]\n",
      "Label:  [[-0.00793207 -0.00098255  0.12250813 -0.4134396   0.1578581 ]]\n",
      "Loss:  Euclidean Loss:  2.72602381364e+33\n",
      "None\n",
      "Input:  [[  1.33378827e+15   2.94425712e+14   3.23828991e+15   7.37246856e+16\n",
      "   -2.08959876e+15  -7.62685563e-01   8.31416416e-01   2.00000000e-02]]\n",
      "Pred:  [[  2.74859278e+15   6.06735266e+14   6.67327859e+15   1.51927562e+17\n",
      "   -4.30612562e+15]]\n",
      "Label:  [[-0.00822806 -0.00100847  0.12117674 -0.42869228  0.16118379]]\n",
      "Loss:  Euclidean Loss:  1.15764910525e+34\n",
      "None\n",
      "Input:  [[  2.74859278e+15   6.06735266e+14   6.67327859e+15   1.51927562e+17\n",
      "   -4.30612562e+15  -7.62685563e-01   8.31416416e-01   2.00000000e-02]]\n",
      "Pred:  [[  5.66414113e+15   1.25032471e+15   1.37519012e+16   3.13083531e+17\n",
      "   -8.87381153e+15]]\n",
      "Label:  [[-0.00852382 -0.00103292  0.11976843 -0.44394496  0.16450948]]\n",
      "Loss:  Euclidean Loss:  4.91614016563e+34\n",
      "None\n",
      "Input:  [[  5.66414113e+15   1.25032471e+15   1.37519012e+16   3.13083531e+17\n",
      "   -8.87381153e+15  -7.62685563e-01   8.31416416e-01   2.00000000e-02]]\n",
      "Pred:  [[  1.16723349e+16   2.57659759e+15   2.83391133e+16   6.45184421e+17\n",
      "   -1.82866586e+16]]\n",
      "Label:  [[-0.00881946 -0.00105584  0.11828118 -0.45919764  0.16783516]]\n",
      "Loss:  Euclidean Loss:  2.08771655161e+35\n",
      "None\n",
      "Input:  [[  1.16723349e+16   2.57659759e+15   2.83391133e+16   6.45184421e+17\n",
      "   -1.82866586e+16  -9.43221595e-01   5.83229941e-01   2.00000000e-02]]\n",
      "Pred:  [[  2.40536723e+16   5.30970379e+15   5.83996152e+16   1.32955860e+18\n",
      "   -3.76840860e+16]]\n",
      "Label:  [[ 0.00132149  0.00018151  0.13653553  0.05578303  0.05376918]]\n",
      "Loss:  Euclidean Loss:  8.86581757153e+35\n",
      "None\n",
      "Input:  [[  2.40536723e+16   5.30970379e+15   5.83996152e+16   1.32955860e+18\n",
      "   -3.76840860e+16  -9.43221595e-01   5.83229941e-01   2.00000000e-02]]\n",
      "Pred:  [[  4.95684151e+16   1.09419274e+16   1.20346530e+17   2.73987715e+18\n",
      "   -7.76572350e+16]]\n",
      "Label:  [[  9.48131084e-04   1.30280852e-04   1.36587948e-01   3.69197801e-02\n",
      "    5.61022609e-02]]\n",
      "Loss:  Euclidean Loss:  3.76500879983e+36\n",
      "None\n",
      "Input:  [[  4.95684151e+16   1.09419274e+16   1.20346530e+17   2.73987715e+18\n",
      "   -7.76572350e+16  -9.43221595e-01   5.83229941e-01   2.00000000e-02]]\n",
      "Pred:  [[  1.02147697e+17   2.25484838e+16   2.48003163e+17   5.64617968e+18\n",
      "   -1.60031478e+17]]\n",
      "Label:  [[  5.74827194e-04   7.90208578e-05   1.36621058e-01   1.80565231e-02\n",
      "    5.84353358e-02]]\n",
      "Loss:  Euclidean Loss:  1.59887008172e+37\n",
      "None\n",
      "Input:  [[  1.02147697e+17   2.25484838e+16   2.48003163e+17   5.64617968e+18\n",
      "   -1.60031478e+17  -9.43221595e-01   5.83229941e-01   2.00000000e-02]]\n",
      "Pred:  [[  2.10500058e+17   4.64665940e+16   5.11070597e+17   1.16353190e+19\n",
      "   -3.29783257e+17]]\n",
      "Label:  [[  2.01702118e-04   2.77236104e-05   1.36633143e-01  -8.06732511e-04\n",
      "    6.07684143e-02]]\n",
      "Loss:  Euclidean Loss:  6.78985352747e+37\n",
      "None\n",
      "Input:  [[  2.10500058e+17   4.64665940e+16   5.11070597e+17   1.16353190e+19\n",
      "   -3.29783257e+17  -9.43221595e-01   5.83229941e-01   2.00000000e-02]]\n",
      "Pred:  [[  4.33786268e+17   9.57556946e+16   1.05318480e+18   2.39773909e+19\n",
      "   -6.79598173e+17]]\n",
      "Label:  [[ -1.71363354e-04  -2.35587358e-05   1.36622414e-01  -1.96699891e-02\n",
      "    6.31014928e-02]]\n",
      "Loss:  Euclidean Loss:  inf\n",
      "None\n",
      "Input:  [[  4.33786268e+17   9.57556946e+16   1.05318480e+18   2.39773909e+19\n",
      "   -6.79598173e+17  -9.43221595e-01   5.83229941e-01   2.00000000e-02]]\n",
      "Pred:  [[  8.93921576e+17   1.97327771e+17   2.17034194e+18   4.94112125e+19\n",
      "   -1.40047723e+18]]\n",
      "Label:  [[ -5.44369221e-04  -7.48261809e-05   1.36587128e-01  -3.85332443e-02\n",
      "    6.54345676e-02]]\n",
      "Loss:  Euclidean Loss:  inf\n",
      "None\n",
      "Input:  [[  8.93921576e+17   1.97327771e+17   2.17034194e+18   4.94112125e+19\n",
      "   -1.40047723e+18  -9.43221595e-01   5.83229941e-01   2.00000000e-02]]\n",
      "Pred:  [[  1.84214157e+18   4.06641731e+17   4.47251314e+18   1.01823758e+20\n",
      "   -2.88602011e+18]]\n",
      "Label:  [[ -9.17196274e-04  -1.26041472e-04   1.36525527e-01  -5.73965013e-02\n",
      "    6.77676424e-02]]\n",
      "Loss:  Euclidean Loss:  inf\n",
      "None\n",
      "Input:  [[  1.84214157e+18   4.06641731e+17   4.47251314e+18   1.01823758e+20\n",
      "   -2.88602011e+18  -9.43221595e-01   5.83229941e-01   2.00000000e-02]]\n",
      "Pred:  [[  3.79617824e+18   8.37983235e+17   9.21669800e+18   2.09832505e+20\n",
      "   -5.94734306e+18]]\n",
      "Label:  [[-0.0012899  -0.00017716  0.13643585 -0.07625975  0.07010072]]\n",
      "Loss:  Euclidean Loss:  inf\n",
      "None\n",
      "Input:  [[  3.79617824e+18   8.37983235e+17   9.21669800e+18   2.09832505e+20\n",
      "   -5.94734306e+18  -9.43221595e-01   5.83229941e-01   2.00000000e-02]]\n",
      "Pred:  [[  7.82294442e+18   1.72686822e+18   1.89932321e+19   4.32410691e+20\n",
      "   -1.22559373e+19]]\n",
      "Label:  [[-0.00166255 -0.00022817  0.13631636 -0.09512302  0.0724338 ]]\n",
      "Loss:  Euclidean Loss:  inf\n",
      "None\n",
      "Input:  [[  7.82294442e+18   1.72686822e+18   1.89932321e+19   4.32410691e+20\n",
      "   -1.22559373e+19  -9.43221595e-01   5.83229941e-01   2.00000000e-02]]\n",
      "Pred:  [[  1.61210736e+19   3.55862876e+18   3.91401642e+19   8.91086796e+20\n",
      "   -2.52563362e+19]]\n",
      "Label:  [[-0.00203508 -0.00027902  0.13616528 -0.11398627  0.07476687]]\n",
      "Loss:  Euclidean Loss:  inf\n",
      "None\n",
      "Input:  [[  1.61210736e+19   3.55862876e+18   3.91401642e+19   8.91086796e+20\n",
      "   -2.52563362e+19  -9.43221595e-01   5.83229941e-01   2.00000000e-02]]\n",
      "Pred:  [[  3.32213634e+19   7.33341765e+18   8.06577629e+19   1.83629996e+21\n",
      "   -5.20467727e+19]]\n",
      "Label:  [[-0.00240749 -0.00032967  0.13598084 -0.13284953  0.07709996]]\n",
      "Loss:  Euclidean Loss:  inf\n",
      "None\n",
      "Input:  [[  3.32213634e+19   7.33341765e+18   8.06577629e+19   1.83629996e+21\n",
      "   -5.20467727e+19  -9.43221595e-01   5.83229941e-01   2.00000000e-02]]\n",
      "Pred:  [[  6.84606561e+19   1.51122728e+19   1.66214862e+20   3.78414058e+21\n",
      "   -1.07254914e+20]]\n",
      "Label:  [[-0.00277972 -0.00038008  0.13576134 -0.15171278  0.07943303]]\n",
      "Loss:  Euclidean Loss:  inf\n",
      "None\n",
      "Input:  [[  6.84606561e+19   1.51122728e+19   1.66214862e+20   3.78414058e+21\n",
      "   -1.07254914e+20  -9.43221595e-01   5.83229941e-01   2.00000000e-02]]\n",
      "Pred:  [[  1.41079771e+20   3.11425256e+19   3.42525844e+20   7.79813700e+21\n",
      "   -2.21024883e+20]]\n",
      "Label:  [[-0.00315189 -0.00043022  0.13550496 -0.17057604  0.08176611]]\n",
      "Loss:  Euclidean Loss:  inf\n",
      "None\n",
      "Input:  [[  1.41079771e+20   3.11425256e+19   3.42525844e+20   7.79813700e+21\n",
      "   -2.21024883e+20  -9.43221595e-01   5.83229941e-01   2.00000000e-02]]\n",
      "Pred:  [[  2.90729012e+20   6.41766377e+19   7.05857192e+20   1.60699491e+22\n",
      "   -4.55475067e+20]]\n",
      "Label:  [[-0.00352401 -0.00048002  0.13521001 -0.1894393   0.08409919]]\n",
      "Loss:  Euclidean Loss:  inf\n",
      "None\n",
      "Input:  [[  2.90729012e+20   6.41766377e+19   7.05857192e+20   1.60699491e+22\n",
      "   -4.55475067e+20  -9.43221595e-01   5.83229941e-01   2.00000000e-02]]\n",
      "Pred:  [[  5.99117447e+20   1.32251502e+20   1.45459006e+21   3.31160219e+22\n",
      "   -9.38617294e+20]]\n",
      "Label:  [[-0.00389588 -0.00052945  0.13487469 -0.20830254  0.08643226]]\n",
      "Loss:  Euclidean Loss:  inf\n",
      "None\n",
      "Input:  [[  5.99117447e+20   1.32251502e+20   1.45459006e+21   3.31160219e+22\n",
      "   -9.38617294e+20  -9.43221595e-01   5.83229941e-01   2.00000000e-02]]\n",
      "Pred:  [[  1.23462665e+21   2.72536457e+20   2.99753455e+21   6.82435766e+22\n",
      "   -1.93424861e+21]]\n",
      "Label:  [[-0.00426769 -0.00057844  0.13449727 -0.2271658   0.08876534]]\n",
      "Loss:  Euclidean Loss:  inf\n",
      "None\n",
      "Input:  [[  1.23462665e+21   2.72536457e+20   2.99753455e+21   6.82435766e+22\n",
      "   -1.93424861e+21  -9.43221595e-01   5.83229941e-01   2.00000000e-02]]\n",
      "Pred:  [[  2.54424668e+21   5.61627373e+20   6.17714175e+21   1.40632392e+23\n",
      "   -3.98598629e+21]]\n",
      "Label:  [[-0.00463945 -0.00062696  0.13407598 -0.24602906  0.09109842]]\n",
      "Loss:  Euclidean Loss:  inf\n",
      "None\n",
      "Input:  [[  2.54424668e+21   5.61627373e+20   6.17714175e+21   1.40632392e+23\n",
      "   -3.98598629e+21  -9.43221595e-01   5.83229941e-01   2.00000000e-02]]\n",
      "Pred:  [[  5.24303664e+21   1.15736867e+21   1.27294987e+22   2.89807068e+23\n",
      "   -8.21409284e+21]]\n",
      "Label:  [[-0.00501102 -0.00067493  0.1336091  -0.26489231  0.0934315 ]]\n",
      "Loss:  Euclidean Loss:  inf\n",
      "None\n",
      "Input:  [[  5.24303664e+21   1.15736867e+21   1.27294987e+22   2.89807068e+23\n",
      "   -8.21409284e+21  -9.43221595e-01   5.83229941e-01   2.00000000e-02]]\n",
      "Pred:  [[  1.08045442e+22   2.38503825e+21   2.62322113e+22   5.97217591e+23\n",
      "   -1.69271102e+22]]\n",
      "Label:  [[-0.00538248 -0.00072229  0.13309486 -0.28375557  0.09576457]]\n",
      "Loss:  Euclidean Loss:  inf\n",
      "None\n",
      "Input:  [[  1.08045442e+22   2.38503825e+21   2.62322113e+22   5.97217591e+23\n",
      "   -1.69271102e+22  -9.43221595e-01   5.83229941e-01   2.00000000e-02]]\n",
      "Pred:  [[  2.22653777e+22   4.91494716e+21   5.40578683e+22   1.23071142e+24\n",
      "   -3.48824192e+22]]\n",
      "Label:  [[-0.00575387 -0.000769    0.13253152 -0.30261883  0.09809764]]\n",
      "Loss:  Euclidean Loss:  inf\n",
      "None\n",
      "Input:  [[  2.22653777e+22   4.91494716e+21   5.40578683e+22   1.23071142e+24\n",
      "   -3.48824192e+22  -9.43221595e-01   5.83229941e-01   2.00000000e-02]]\n",
      "Pred:  [[  4.58832044e+22   1.01284402e+22   1.11399311e+23   2.53617857e+24\n",
      "   -7.18837101e+22]]\n",
      "Label:  [[-0.00612515 -0.00081497  0.13191731 -0.32148209  0.10043073]]\n",
      "Loss:  Euclidean Loss:  inf\n",
      "None\n",
      "Input:  [[  4.58832044e+22   1.01284402e+22   1.11399311e+23   2.53617857e+24\n",
      "   -7.18837101e+22  -9.43221595e-01   5.83229941e-01   2.00000000e-02]]\n",
      "Pred:  [[  9.45534345e+22   2.08720991e+22   2.29565118e+23   5.22640993e+24\n",
      "   -1.48133822e+23]]\n",
      "Label:  [[-0.00649625 -0.00086015  0.1312505  -0.34034535  0.1027638 ]]\n",
      "Loss:  Euclidean Loss:  inf\n",
      "None\n",
      "Input:  [[  9.45534345e+22   2.08720991e+22   2.29565118e+23   5.22640993e+24\n",
      "   -1.48133822e+23  -9.43221595e-01   5.83229941e-01   2.00000000e-02]]\n",
      "Pred:  [[  1.94850255e+23   4.30119885e+22   4.73074462e+23   1.07702814e+25\n",
      "   -3.05265044e+23]]\n",
      "Label:  [[-0.00686741 -0.00090446  0.13052934 -0.35920858  0.10509688]]\n",
      "Loss:  Euclidean Loss:  inf\n",
      "None\n",
      "Input:  [[  1.94850255e+23   4.30119885e+22   4.73074462e+23   1.07702814e+25\n",
      "   -3.05265044e+23  -9.43221595e-01   5.83229941e-01   2.00000000e-02]]\n",
      "Pred:  [[  4.01536043e+23   8.86365963e+22   9.74883763e+23   2.21947697e+25\n",
      "   -6.29072524e+23]]\n",
      "Label:  [[-0.00723827 -0.00094784  0.12975208 -0.37807184  0.10742996]]\n",
      "Loss:  Euclidean Loss:  inf\n",
      "None\n",
      "Input:  [[  4.01536043e+23   8.86365963e+22   9.74883763e+23   2.21947697e+25\n",
      "   -6.29072524e+23  -9.43221595e-01   5.83229941e-01   2.00000000e-02]]\n",
      "Pred:  [[  8.27462068e+23   1.82657282e+23   2.00898417e+24   4.57376966e+25\n",
      "   -1.29635719e+24]]\n",
      "Label:  [[-0.00760913 -0.0009902   0.12891696 -0.39693511  0.10976303]]\n",
      "Loss:  Euclidean Loss:  inf\n",
      "None\n",
      "Input:  [[  8.27462068e+23   1.82657282e+23   2.00898417e+24   4.57376966e+25\n",
      "   -1.29635719e+24  -9.43221595e-01   5.83229941e-01   2.00000000e-02]]\n",
      "Pred:  [[  1.70518604e+24   3.76409524e+23   4.13999758e+24   9.42535835e+25\n",
      "   -2.67145748e+24]]\n",
      "Label:  [[-0.00797999 -0.00103147  0.12802227 -0.41579837  0.11209611]]\n",
      "Loss:  Euclidean Loss:  inf\n",
      "None\n",
      "Input:  [[  1.70518604e+24   3.76409524e+23   4.13999758e+24   9.42535835e+25\n",
      "   -2.67145748e+24  -9.43221595e-01   5.83229941e-01   2.00000000e-02]]\n",
      "Pred:  [[  3.51394853e+24   7.75682562e+23   8.53146810e+24   1.94232317e+26\n",
      "   -5.50518635e+24]]\n",
      "Label:  [[-0.00835061 -0.00107157  0.12706624 -0.43466163  0.11442919]]\n",
      "Loss:  Euclidean Loss:  inf\n",
      "None\n",
      "Input:  [[  3.51394853e+24   7.75682562e+23   8.53146810e+24   1.94232317e+26\n",
      "   -5.50518635e+24  -9.43221595e-01   5.83229941e-01   2.00000000e-02]]\n",
      "Pred:  [[  7.24134087e+24   1.59848128e+24   1.75811606e+25   4.00262692e+26\n",
      "   -1.13447603e+25]]\n",
      "Label:  [[-0.00872111 -0.00111042  0.12604712 -0.45352489  0.11676227]]\n",
      "Loss:  Euclidean Loss:  inf\n",
      "None\n",
      "Input:  [[  7.24134087e+24   1.59848128e+24   1.75811606e+25   4.00262692e+26\n",
      "   -1.13447603e+25  -9.43221595e-01   5.83229941e-01   2.00000000e-02]]\n",
      "Pred:  [[  1.49225351e+25   3.29405930e+24   3.62302493e+25   8.24838118e+26\n",
      "   -2.33786171e+25]]\n",
      "Label:  [[-0.00909162 -0.00114793  0.12496318 -0.47238812  0.11909534]]\n",
      "Loss:  Euclidean Loss:  inf\n",
      "None\n",
      "Input:  [[  1.49225351e+25   3.29405930e+24   3.62302493e+25   8.24838118e+26\n",
      "   -2.33786171e+25  -9.43221595e-01   5.83229941e-01   2.00000000e-02]]\n",
      "Pred:  [[  3.07514902e+25   6.78820582e+24   7.46612321e+25   1.69977863e+27\n",
      "   -4.81773338e+25]]\n",
      "Label:  [[-0.009462   -0.001184    0.12381268 -0.49125138  0.12142842]]\n",
      "Loss:  Euclidean Loss:  inf\n",
      "None\n",
      "Input:  [[  3.07514902e+25   6.78820582e+24   7.46612321e+25   1.69977863e+27\n",
      "   -4.81773338e+25  -9.43221595e-01   5.83229941e-01   2.00000000e-02]]\n",
      "Pred:  [[  6.33708931e+25   1.39887448e+25   1.53857449e+26   3.50280501e+27\n",
      "   -9.92810222e+25]]\n",
      "Label:  [[-0.00983226 -0.00121857  0.12259386 -0.51011467  0.1237615 ]]\n",
      "Loss:  Euclidean Loss:  inf\n",
      "None\n",
      "Input:  [[  6.33708931e+25   1.39887448e+25   1.53857449e+26   3.50280501e+27\n",
      "   -9.92810222e+25  -9.43221595e-01   5.83229941e-01   2.00000000e-02]]\n",
      "Pred:  [[  1.30591087e+26   2.88271927e+25   3.17060534e+26   7.21837742e+27\n",
      "   -2.04592580e+26]]\n",
      "Label:  [[-0.01020253 -0.00125153  0.121305   -0.52897787  0.12609458]]\n",
      "Loss:  Euclidean Loss:  inf\n",
      "None\n",
      "Input:  [[  1.30591087e+26   2.88271927e+25   3.17060534e+26   7.21837742e+27\n",
      "   -2.04592580e+26  -9.43221595e-01   5.83229941e-01   2.00000000e-02]]\n",
      "Pred:  [[  2.69114532e+26   5.94053919e+25   6.53380060e+26   1.48752136e+28\n",
      "   -4.21612511e+26]]\n",
      "Label:  [[-0.01057267 -0.00128278  0.11994436 -0.54784113  0.12842765]]\n",
      "Loss:  Euclidean Loss:  inf\n",
      "None\n",
      "Input:  [[  2.69114532e+26   5.94053919e+25   6.53380060e+26   1.48752136e+28\n",
      "   -4.21612511e+26  -9.43221595e-01   5.83229941e-01   2.00000000e-02]]\n",
      "Pred:  [[  5.54575535e+26   1.22419244e+26   1.34644762e+27   3.06539788e+28\n",
      "   -8.68834710e+26]]\n",
      "Label:  [[-0.0109427  -0.00131223  0.11851019 -0.56670439  0.13076073]]\n",
      "Loss:  Euclidean Loss:  inf\n",
      "None\n",
      "Input:  [[  5.54575535e+26   1.22419244e+26   1.34644762e+27   3.06539788e+28\n",
      "   -8.68834710e+26  -8.68921238e-01   6.45406665e-01   2.00000000e-02]]\n",
      "Pred:  [[  1.14283711e+27   2.52274370e+26   2.77468132e+27   6.31699395e+28\n",
      "   -1.79044305e+27]]\n",
      "Label:  [[ 0.00133371  0.00018319  0.13653632  0.05726898  0.05401786]]\n",
      "Loss:  Euclidean Loss:  inf\n",
      "None\n",
      "Input:  [[  1.14283711e+27   2.52274370e+26   2.77468132e+27   6.31699395e+28\n",
      "   -1.79044305e+27  -8.68921238e-01   6.45406665e-01   2.00000000e-02]]\n",
      "Pred:  [[  2.35509242e+27   5.19872413e+26   5.71789801e+27   1.30176943e+29\n",
      "   -3.68964190e+27]]\n",
      "Label:  [[  9.89794731e-04   1.36010349e-04   1.36591390e-01   3.98916714e-02\n",
      "    5.65996058e-02]]\n",
      "Loss:  Euclidean Loss:  inf\n",
      "None\n",
      "Input:  [[  2.35509242e+27   5.19872413e+26   5.71789801e+27   1.30176943e+29\n",
      "   -3.68964190e+27  -8.68921238e-01   6.45406665e-01   2.00000000e-02]]\n",
      "Pred:  [[  4.85323743e+27   1.07132292e+27   1.17831119e+28   2.68261093e+29\n",
      "   -7.60340790e+27]]\n",
      "Label:  [[  6.45875931e-04   8.87811184e-05   1.36629000e-01   2.25143619e-02\n",
      "    5.91813549e-02]]\n",
      "Loss:  Euclidean Loss:  inf\n",
      "None\n",
      "Input:  [[  4.85323743e+27   1.07132292e+27   1.17831119e+28   2.68261093e+29\n",
      "   -7.60340790e+27  -8.68921238e-01   6.45406665e-01   2.00000000e-02]]\n",
      "Pred:  [[  1.00012709e+28   2.20771932e+27   2.42819646e+28   5.52816919e+29\n",
      "   -1.56686502e+28]]\n",
      "Label:  [[  3.02076340e-04   4.15369868e-05   1.36647359e-01   5.13705146e-03\n",
      "    6.17631078e-02]]\n",
      "Loss:  Euclidean Loss:  inf\n",
      "None\n",
      "Input:  [[  1.00012709e+28   2.20771932e+27   2.42819646e+28   5.52816919e+29\n",
      "   -1.56686502e+28  -8.68921238e-01   6.45406665e-01   2.00000000e-02]]\n",
      "Pred:  [[  2.06100389e+28   4.54954027e+27   5.00388280e+28   1.13921296e+30\n",
      "   -3.22890297e+28]]\n",
      "Label:  [[ -4.16040421e-05  -5.72204590e-06   1.36644691e-01  -1.22402580e-02\n",
      "    6.43448532e-02]]\n",
      "Loss:  Euclidean Loss:  inf\n",
      "None\n",
      "Input:  [[  2.06100389e+28   4.54954027e+27   5.00388280e+28   1.13921296e+30\n",
      "   -3.22890297e+28  -8.68921238e-01   6.45406665e-01   2.00000000e-02]]\n",
      "Pred:  [[  4.24719724e+28   9.37543401e+27   1.03117236e+29   2.34762393e+30\n",
      "   -6.65393857e+28]]\n",
      "Label:  [[ -3.85165215e-04  -5.29512763e-05   1.36619180e-01  -2.96175685e-02\n",
      "    6.69266060e-02]]\n",
      "Loss:  Euclidean Loss:  inf\n",
      "None\n",
      "Input:  [[  4.24719724e+28   9.37543401e+27   1.03117236e+29   2.34762393e+30\n",
      "   -6.65393857e+28  -8.68921238e-01   6.45406665e-01   2.00000000e-02]]\n",
      "Pred:  [[  8.75237643e+28   1.93203441e+28   2.12498029e+29   4.83784701e+30\n",
      "   -1.37120503e+29]]\n",
      "Label:  [[ -7.28607178e-04  -1.00150704e-04   1.36569068e-01  -4.69948761e-02\n",
      "    6.95083588e-02]]\n",
      "Loss:  Euclidean Loss:  inf\n",
      "None\n",
      "Input:  [[  8.75237643e+28   1.93203441e+28   2.12498029e+29   4.83784701e+30\n",
      "   -1.37120503e+29  -8.68921238e-01   6.45406665e-01   2.00000000e-02]]\n",
      "Pred:  [[  1.80363874e+29   3.98142576e+28   4.37903457e+29   9.96955486e+30\n",
      "   -2.82570279e+29]]\n",
      "Label:  [[-0.00107193 -0.00014728  0.13649254 -0.06437219  0.0720901 ]]\n",
      "Loss:  Euclidean Loss:  inf\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/colin/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:352: RuntimeWarning: overflow encountered in square\n"
     ]
    }
   ],
   "source": [
    "# main()\n",
    "main(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 7)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.asarray([1, 1, 1, 1, 1])\n",
    "b = np.asarray([2, 2, 2, 2, 2, 2, 2])\n",
    "b[0]\n",
    "np.asarray([np.concatenate((a, b[5:8]), axis=0)]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.29162415862083435, 0.008049188181757927, 0.033666692674160004, 0.27424606680870056, 0.008417674340307713, 0.05690521001815796, 0.0005845790728926659, 0.0]\n",
      "[0.6776861548423767, -0.06710384786128998, -0.05981121584773064, 0.4085806608200073, -0.004740194883197546, 0.04174768552184105, 0.0003070685488637537, 0.0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "blob = caffe.proto.caffe_pb2.BlobProto()\n",
    "data = open( \"toycar_mean.binaryproto\" , 'rb' ).read()\n",
    "blob.ParseFromString(data)\n",
    "# arr = np.array( caffe.io.blobproto_to_array(blob) )\n",
    "# out = arr[0]\n",
    "print blob.data\n",
    "\n",
    "data = open( \"../prx_ws/src/prx_learn/data/toy_car/toy_car_mean.binaryproto\" , 'rb' ).read()\n",
    "blob.ParseFromString(data)\n",
    "print blob.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
