{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Trimming:  (1383, 4)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "if not hasattr(sys, 'argv'):\n",
    "    sys.argv  = ['']\n",
    "import numpy as np\n",
    "import GPflow\n",
    "import GPy\n",
    "import random\n",
    "import scipy\n",
    "import errno\n",
    "from mp_learning import snake_data\n",
    "\n",
    "def mkdir_p(path):\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as exc:  # Python >2.5\n",
    "        if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
    "            pass\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "def normalize(angle, min_, max_):\n",
    "    if angle < min_:\n",
    "        return angle + 2*np.pi\n",
    "    if angle > max_:\n",
    "        return angle - 2*np.pi\n",
    "    return angle\n",
    "\n",
    "    \n",
    "def unit_vector(vector):\n",
    "    return vector / np.linalg.norm(vector)\n",
    "\n",
    "def angle_between(v1, v2):\n",
    "    v1_u = unit_vector(v1)\n",
    "    v2_u = unit_vector(v2)\n",
    "    return normalize(np.arctan2(v1_u[0], v1_u[1]) - np.arctan2(v2_u[0], v2_u[1]), -3.1415, 3.1415)\n",
    "\n",
    "class Model:\n",
    "    '''\n",
    "    Data containers and Visualization functions for models\n",
    "    '''\n",
    "    def __init__(self, datapath, prefix ):\n",
    "        self.datapath = datapath\n",
    "        self.prefix = prefix\n",
    "        self.load_data()\n",
    "\n",
    "    # 1 - Calculate slope of points, input: 1x91 snake state array\n",
    "    def slope (self, idx1, idx2, m=\"no_debug\" ):\n",
    "        X, Y = [], []\n",
    "        x_mid = self.states[idx1,idx2,39]\n",
    "        y_mid = self.states[idx1,idx2,40]\n",
    "        for i in [0,6]:\n",
    "            X.append(self.states[idx1,idx2,i*13] )\n",
    "            Y.append(self.states[idx1,idx2,(i*13)+1] )\n",
    "        s_x = np.std(X)\n",
    "        s_y = np.std(Y)\n",
    "        corr_x_y = np.corrcoef(X,Y)\n",
    "        slope = corr_x_y[0,1]*(s_y / s_x)\n",
    "        quadrant = 0\n",
    "        point = []\n",
    "        if (X[0] > X[-1]) and (slope >= 0.0):\n",
    "            quadrant = 1\n",
    "            point = [1, slope]\n",
    "        elif (X[0] < X[-1]) and (slope < 0.0):\n",
    "            quadrant = 2\n",
    "            point = [-1, -slope]\n",
    "        elif (X[0] < X[-1]) and (slope >= 0.0):\n",
    "            quadrant = 3\n",
    "            point = [-1, -slope]\n",
    "        elif (X[0] > X[-1]) and (slope < 0.0):\n",
    "            quadrant = 4\n",
    "            point = [1, slope]\n",
    "        else:\n",
    "            raise ValueError(\"Invalid slope/quadrant computation\")\n",
    "        if (m == \"debug\"):\n",
    "            print \"X: \",X\n",
    "            print \"Y: \",Y\n",
    "            print \"quad: \", quadrant\n",
    "            print \"slope: \", slope\n",
    "            print \"point: \", point\n",
    "            point1 = [10, 10*slope]\n",
    "            point2 = [-10, -10*slope]\n",
    "            plot_snake_state_pts(X,Y, point1, point2)\n",
    "        return point, quadrant\n",
    "\n",
    "    def plot2d(self, x, y, c='r'):\n",
    "        c = plt.scatter(x, y, c=c)\n",
    "        plt.colorbar(c)\n",
    "        plt.show()\n",
    "\n",
    "    def plot3d(self, x, y, z, sz=2):\n",
    "        fig = plt.figure()\n",
    "        ax = plt.subplot(111, projection='3d')\n",
    "        ax.plot(x, y, z, 'o', ms=sz)\n",
    "        plt.show()\n",
    "\n",
    "    def load_data(self):\n",
    "        '''\n",
    "        Load Data into class for training and testing\n",
    "        '''\n",
    "        self.states = []\n",
    "        self.controls = []\n",
    "        self.durations = []\n",
    "        self.disp_angles = []\n",
    "        self.disp = []\n",
    "        self.disp_along_heading = []\n",
    "        self.heading_change_norm = []\n",
    "        self.heading_change = []\n",
    "\n",
    "        with open(self.datapath, 'r') as infile:\n",
    "            data = infile.readlines()\n",
    "            idx, i = 0, 0\n",
    "            state_seq = []\n",
    "\n",
    "            # Stop at end of file\n",
    "            for line in data:\n",
    "                if line == '':\n",
    "                    print \"end\"\n",
    "                    break\n",
    "                # Reset and continue at Trajectory break\n",
    "                if len(line) == 1:\n",
    "                    i = 0\n",
    "                    seq = np.asarray(state_seq, dtype=np.float32)[:, 0:91]\n",
    "                    self.states.append(seq)\n",
    "                    state_seq = []\n",
    "                    idx += 1\n",
    "                    continue\n",
    "                # Split Values in line and append to individual lists\n",
    "                vals = line.split(',')\n",
    "                if i == 0:\n",
    "                    self.controls.append([float(val) for val in vals])\n",
    "                elif i == 1:\n",
    "                    self.durations.append([float(val) for val in vals])\n",
    "                elif i >= 2:\n",
    "                    state_seq.append([float(val) for val in vals])\n",
    "\n",
    "                i += 1\n",
    "\n",
    "        self.controls = np.asarray(self.controls, dtype=np.float32)\n",
    "        self.durations = np.asarray(self.durations, dtype=np.float32)\n",
    "        self.states = np.asarray(self.states, dtype=np.float32)\n",
    "\n",
    "        # 2 - Remove displacement(sqrt(dx^2+dy^2) middle link) < 3.0\n",
    "        disp_thresh = []\n",
    "        for i,st in enumerate(self.states):\n",
    "            disp_10 = np.sqrt(np.square(self.states[i,20,39] - self.states[i,10,39]) + \n",
    "                              np.square(self.states[i,20,40] - self.states[i,10,40]))\n",
    "            if disp_10 > 5.0:\n",
    "                disp_thresh.append(i)\n",
    "        self.states = self.states[disp_thresh]\n",
    "        self.controls = self.controls[disp_thresh]\n",
    "        self.durations = self.durations[disp_thresh]\n",
    "\n",
    "        # FILTER: Keep only stable gaits (>5 consecutive cycles within +/- 5 deg displacement)\n",
    "        # COMPUTE: (1) disp: total diplacement (2) disp_angles: angle of disp of center link (3) disp_along_heading\n",
    "        stable_idxs = []\n",
    "        for i in range(0,self.states.shape[0]):\n",
    "            cons_cycs = 0\n",
    "            stable_val = 0.0\n",
    "            for j in range(self.states.shape[1]-1,1,-1):\n",
    "                start_disp = np.asarray(self.states[i,j-1,39:41])\n",
    "                end_disp = np.asarray(self.states[i,j,39:41])\n",
    "                \n",
    "                start_slope, quadrant = self.slope(i,j-1)\n",
    "                end_slope, quadrant = self.slope(i,j)\n",
    "                \n",
    "                start_vec = np.asarray(start_slope)\n",
    "                end_vec = np.asarray((end_disp - start_disp)[0:2])\n",
    "                \n",
    "                disp_total = np.sqrt(np.sum(np.square(start_disp - end_disp)))\n",
    "                disp_angle = angle_between(start_vec, end_vec)*180/np.pi\n",
    "                \n",
    "                slope_unit = unit_vector(np.asarray(end_slope))\n",
    "                disp_along_heading = np.dot(end_vec,slope_unit)\n",
    "                \n",
    "                head_chg = angle_between(start_slope, end_slope)*180/np.pi\n",
    "                \n",
    "                if j == self.states.shape[1]-1:\n",
    "                    stable_val = disp_angle\n",
    "                    self.disp_along_heading.append(disp_along_heading * 1000.0 / self.durations[i])\n",
    "                    self.disp_angles.append(disp_angle * 1000.0 / self.durations[i])\n",
    "                    self.disp.append(disp_total * 1000.0 / self.durations[i])\n",
    "                    self.heading_change.append(head_chg)\n",
    "                    self.heading_change_norm.append(head_chg * 1000.0 / self.durations[i])\n",
    "                elif ((disp_angle < stable_val + 5.0) and (disp_angle > stable_val - 5.0)):\n",
    "                    cons_cycs += 1\n",
    "                else:\n",
    "                    break\n",
    "            if cons_cycs >= 5:\n",
    "                stable_idxs.append(i)\n",
    "        self.disp_along_heading = np.asarray(self.disp_along_heading)\n",
    "        self.disp_angles = np.asarray(self.disp_angles)\n",
    "        self.disp = np.asarray(self.disp)\n",
    "        self.heading_change_norm = np.asarray(self.heading_change_norm)\n",
    "        self.heading_change = np.asarray(self.heading_change)\n",
    "\n",
    "        self.disp = self.disp[stable_idxs]\n",
    "        self.disp_angles = self.disp_angles[stable_idxs]\n",
    "        self.disp_along_heading = self.disp_along_heading[stable_idxs]\n",
    "        self.states = self.states[stable_idxs]\n",
    "        self.controls = self.controls[stable_idxs]\n",
    "        self.durations = self.durations[stable_idxs]\n",
    "        self.heading_change = self.heading_change[stable_idxs]\n",
    "        self.heading_change_norm = self.heading_change_norm[stable_idxs]\n",
    "\n",
    "        # Create Training/Test data and split\n",
    "        indices = np.linspace(self.controls.shape[0]-1,0,self.controls.shape[0]-1)\n",
    "        training_idx = indices[:self.controls.shape[0]*0.9].astype(int)\n",
    "        testing_idx = indices[self.controls.shape[0]*0.9:].astype(int)\n",
    "\n",
    "        self.train_data = self.controls[training_idx, :]\n",
    "        self.train_labels = np.concatenate((self.heading_change_norm[training_idx, :], self.disp_along_heading[training_idx, :]), axis=1) \n",
    "\n",
    "        self.test_data = self.controls[testing_idx, :]\n",
    "        self.test_labels = np.concatenate((self.heading_change_norm[testing_idx, :], self.disp_along_heading[testing_idx, :]), axis=1)\n",
    "\n",
    "class GPRegression():\n",
    "    def __init__(self):\n",
    "        self.train_data = np.asarray([]).reshape((0,0))\n",
    "        self.train_labels = np.asarray([]).reshape((0,0))\n",
    "        self.train_data_cls = np.asarray([]).reshape((0,0))\n",
    "        self.train_labels_cls = np.asarray([]).reshape((0,0))\n",
    "        self.prev_control = []\n",
    "        self.prev_end_state = []\n",
    "        self.model = []\n",
    "        self.iter_count = 0\n",
    "        self.gp_cls = []\n",
    "        self.num_bins = 10\n",
    "        self.maximums = [0]*10\n",
    "        self.max_controls = np.zeros((self.num_bins, 9))\n",
    "        self.max_heading_changes = [0] * 10\n",
    "        self.max_box_dims = np.zeros((self.num_bins, 2))\n",
    "        self.ctrl_samples = np.concatenate(((np.asarray(random.sample([x / 100000.0 for x in range(100000)],50000)).reshape((50000,1))*0.8 + 0.2),\n",
    "            (np.asarray(random.sample([x / 100000.0 for x in range(100000)],50000)).reshape((50000,1))*0.8 + 0.2),\n",
    "            (np.asarray(random.sample([x / 100000.0 for x in range(100000)],50000)).reshape((50000,1))*0.8 + 0.2),\n",
    "            (np.asarray(random.sample([x / 100000.0 for x in range(100000)],50000)).reshape((50000,1))*0.8 + 0.2),                                            \n",
    "            (np.asarray(random.sample([x / 100000.0 for x in range(100000)],50000)).reshape((50000,1))*0.8 + 0.2),\n",
    "            (np.asarray(random.sample([x / 100000.0 for x in range(100000)],50000)).reshape((50000,1))*0.8 + 0.2),\n",
    "            (np.asarray(random.sample([x / 100000.0 for x in range(100000)],50000)).reshape((50000,1))),\n",
    "            (np.asarray(random.sample([x / 100000.0 for x in range(100000)],50000)).reshape((50000,1))),\n",
    "            (np.asarray(random.sample([x / 100000.0 for x in range(100000)],50000)).reshape((50000,1)))), axis=1)\n",
    "        \n",
    "    def check_max(self, new_data, new_label, box_dims):\n",
    "#         print new_label\n",
    "#         print int(np.floor((new_label[0] + 45) / (90 / self.num_bins)))\n",
    "#         print self.maximums[int(np.floor((new_label[0] + 45) / (90 / self.num_bins)))]\n",
    "        idx = int(np.floor((new_label[0] + 36) / (72 / self.num_bins)))\n",
    "        if new_label[0] <= -36.0:\n",
    "            pass\n",
    "        elif new_label[0] >= 36.0:\n",
    "            pass\n",
    "        elif new_label[1] > self.maximums[idx]:\n",
    "            self.maximums[idx] = new_label[1]\n",
    "            self.max_controls[idx,:] = new_data\n",
    "            self.max_box_dims[idx,:] = box_dims\n",
    "            self.max_heading_changes[idx] = new_label[0]\n",
    "    \n",
    "    def add_and_optimize(self, new_data, new_label, box_dims):\n",
    "        X, Y = [], []\n",
    "#         print \"called add_and_optimize with \", new_data, \"; \", new_label\n",
    "        if not self.train_data.shape[0] == 0:\n",
    "            X = np.concatenate((self.train_data, np.asarray(new_data).reshape((1,9))), axis=0)\n",
    "            Y = np.concatenate((self.train_labels, np.asarray(new_label).reshape((1,2))), axis=0)\n",
    "        else:\n",
    "            X = np.asarray(new_data).reshape((1,9))\n",
    "            Y = np.asarray(new_label).reshape((1,2))\n",
    "            self.lengthscales=GPflow.param.Param(0.5)\n",
    "            self.variance=GPflow.param.Param(100)\n",
    "        self.kern = GPflow.kernels.RBF(9, lengthscales=self.lengthscales.value[0], \n",
    "                                          variance=self.variance.value[0])\n",
    "        self.model = GPflow.gpr.GPR(X,Y, self.kern)\n",
    "        \n",
    "#         print \"OPT var: \", self.kern.variance\n",
    "#         print \"OPT lengthscale: \", self.kern.lengthscales            \n",
    "        self.train_data = X\n",
    "        self.train_labels = Y\n",
    "        \n",
    "#         if self.train_data.shape[0] == 1:\n",
    "        self.nn_tree = scipy.spatial.cKDTree(self.train_data, leafsize=100, )\n",
    "        \n",
    "        self.check_max(new_data, new_label, box_dims)\n",
    "\n",
    "#         self.model.set_XY(X, Y)\n",
    "#         self.model.X.set_data(X)\n",
    "#         self.model.Y.set_data(Y)\n",
    "        self.model.optimize(method='tnc')\n",
    "\n",
    "        if self.kern.lengthscales.value[0] < 0.09 or self.kern.variance.value[0] < 5.0:\n",
    "#             print \"OPT ALTERING PARAMS\"\n",
    "            self.kern.lengthscales = GPflow.param.Param(0.5)\n",
    "            self.kern.variance = GPflow.param.Param(100)\n",
    "        self.lengthscales = self.kern.lengthscales\n",
    "        self.variance = self.kern.variance  \n",
    "#         np.save('gp_opt_model.npy', self.model.param_array)\n",
    "        np.save('gp_opt_train_data.npy', self.train_data)\n",
    "        np.save('gp_opt_train_labels.npy', self.train_labels)        \n",
    "        \n",
    "        print \"OPT Kern params: \", self.kern.get_parameter_dict()\n",
    "        print \"Added POS: \", new_data, new_label\n",
    "        self.add_class_data(new_data, 1.0)\n",
    "\n",
    "#     def add_class_data(self, new_data, bcls):\n",
    "#         X, Y = [], []\n",
    "#         print \"called add_class_data with \", new_data, \"; \", bcls\n",
    "#         if not self.train_data_cls.shape[0] == 0:\n",
    "#             X = np.concatenate((self.train_data_cls, np.asarray(new_data).reshape((1,4))), axis=0)\n",
    "#             Y = np.concatenate((self.train_labels_cls, np.asarray(bcls).reshape((1,1))), axis=0)\n",
    "#         else:\n",
    "#             X = np.asarray(new_data).reshape((1,4))\n",
    "#             Y = np.asarray(bcls).reshape((1,1))\n",
    "#             self.cls_lengthscale=1.0\n",
    "#             self.cls_variance=50\n",
    "#         self.cls_kern = GPy.kern.RBF(1, \n",
    "#                                          lengthscale=self.cls_lengthscale,\n",
    "#                                          variance=self.cls_variance)\n",
    "#         self.cls_kern.lengthscale.unconstrain()\n",
    "#         self.cls_kern.variance.unconstrain()\n",
    "#         self.cls_kern.lengthscale.constrain_bounded(1e-4,1e4)\n",
    "#         self.cls_kern.variance.constrain_bounded(1e-4,1e4)\n",
    "        \n",
    "#         self.gp_cls = GPy.models.GPClassification(X, Y, kernel=self.cls_kern)\n",
    "        \n",
    "#         print \"CLASS var: \", self.cls_kern.variance\n",
    "#         print \"CLASS lengthscale: \", self.cls_kern.lengthscale\n",
    "#         self.train_data_cls = X\n",
    "#         self.train_labels_cls = Y\n",
    "\n",
    "#         self.gp_cls.optimize()\n",
    "        \n",
    "#         if bcls == 0.0: \n",
    "#             print \"Added NEG Class: \", new_data\n",
    "#         else:\n",
    "#             print \"Added POS Class: \", new_data\n",
    "        \n",
    "# #         if self.gp_cls.kern.lengthscale.values[0] < 0.0001 or self.gp_cls.kern.variance.values[0] < 5.0:\n",
    "# #             self.cls_kern = GPy.kern.RBF(1, \n",
    "# #                                              lengthscale=1.0,\n",
    "# #                                              variance=50)\n",
    "# #             self.gp_cls = GPy.models.GPClassification(X,Y,kernel=self.cls_kern)\n",
    "#         self.cls_lengthscale = self.gp_cls.kern.lengthscale.values[0]\n",
    "#         self.cls_variance = self.gp_cls.kern.variance.values[0]\n",
    "        \n",
    "    def add_class_data(self, new_data, bcls):\n",
    "        X, Y = [], []\n",
    "#         print \"called add_class_data with \", new_data, \"; \", bcls\n",
    "        if not self.train_data_cls.shape[0] == 0:\n",
    "            X = np.concatenate((self.train_data_cls, np.asarray(new_data).reshape((1,9))), axis=0)\n",
    "            Y = np.concatenate((self.train_labels_cls, np.asarray(bcls).reshape((1,1))), axis=0)\n",
    "        else:\n",
    "            X = np.asarray(new_data).reshape((1,9))\n",
    "            Y = np.asarray(bcls).reshape((1,1))\n",
    "            \n",
    "        self.train_data_cls = X\n",
    "        self.train_labels_cls = Y\n",
    "\n",
    "        if bcls == 0.0: \n",
    "            print \"Added NEG Class: \", new_data\n",
    "        else:\n",
    "            print \"Added POS Class: \", new_data\n",
    "\n",
    "        np.save('gp_class_train_data.npy', self.train_data_cls)\n",
    "        np.save('gp_class_train_labels.npy', self.train_labels_cls)\n",
    "        \n",
    "    def get_probabilities(self, test_data):\n",
    "        res = [] \n",
    "        self.near_tree = scipy.spatial.cKDTree(self.train_data_cls, leafsize=100)\n",
    "        for i,item in enumerate(test_data):\n",
    "            k = min(10, self.train_data_cls.shape[0])\n",
    "            idx = self.near_tree.query(item, k=k, distance_upper_bound=14)\n",
    "            res.append((np.sum(self.train_labels_cls[idx[1]])/k)+0.01)\n",
    "        return res\n",
    "        \n",
    "    def test(self, data):\n",
    "        return self.model.predict_y(data)\n",
    "\n",
    "    def test_samples(self):\n",
    "        return self.model.predict_y(self.ctrl_samples)\n",
    "    \n",
    "    def add_iter(self):\n",
    "        self.iter_count += 1\n",
    "        \n",
    "    def optimize_disp(self):\n",
    "        pred, pred_var = self.test_samples()\n",
    "        prob = np.asarray(self.get_probabilities(self.ctrl_samples)).reshape((self.ctrl_samples.shape[0],1))\n",
    "        loc_max_prop, reg_max_prop, item_bins, local_disps = [], [], [], []\n",
    "        for idx, item in enumerate(self.ctrl_samples):\n",
    "            try:\n",
    "                res = self.nn_tree.query(item, k=1, distance_upper_bound=14)\n",
    "                local_disps.append(self.train_labels[res[1],1])\n",
    "#                 +np.sqrt(pred_var[idx,1])\n",
    "                loc_max_prop.append((pred[idx,1])/self.train_labels[res[1],1])\n",
    "                item_bins.append(int(np.floor((pred[idx, 0]+36) / (72 / self.num_bins))))\n",
    "                if item_bins[idx] < 0:\n",
    "                    reg_max_prop.append(0.0)\n",
    "                elif item_bins[idx] > 9:\n",
    "                    reg_max_prop.append(0.0)                \n",
    "                elif self.maximums[item_bins[idx]] != 0:\n",
    "                    reg_max_prop.append(pred[idx,1] / self.maximums[item_bins[idx]])\n",
    "                else:\n",
    "                    reg_max_prop.append(10.0)\n",
    "            except IndexError as e:\n",
    "                print \"------------ Autopsy Report ----------------\"\n",
    "                print \"idx: \", idx\n",
    "                print \"res: \", res\n",
    "                print \"pred.shape: \", pred.shape\n",
    "                print \"maximums\", self.maximums\n",
    "                print \"item_bins[idx]\", item_bins[idx]\n",
    "                raise e\n",
    "\n",
    "        loc_reg_criteria = [(((np.sign(a)==-1 and np.sign(b)==-1)-0.5)* -2)*a*b for a,b in zip(loc_max_prop,reg_max_prop)]\n",
    "        criteria = [a*b for a,b in zip(loc_reg_criteria, prob)]\n",
    "        try:        \n",
    "            idx = np.argmax(criteria)\n",
    "            max_criteria = self.ctrl_samples[idx]\n",
    "            res = self.nn_tree.query(max_criteria, k=1, distance_upper_bound=14)\n",
    "            print \"...................... Debug ...................................\"\n",
    "            print \"Max Pred: \\n\", max_criteria, pred[idx], loc_max_prop[idx], \\\n",
    "                                    reg_max_prop[idx], prob[idx], criteria[idx]\n",
    "            print \"Nearest: \", res, self.train_data[res[1],:], self.train_labels[res[1],:]\n",
    "            print \"................................................................\"\n",
    "            self.ctrl_samples = np.delete(self.ctrl_samples, idx, 0)\n",
    "        except IndexError as e:\n",
    "            print \"ctrl_samples.shape: \", self.ctrl_samples.shape\n",
    "            print \"argmax(criteria): \", np.argmax(criteria)\n",
    "            raise e\n",
    "\n",
    "        print \"Sample\\t\\t\\t p[head] \\t P[disp] \\t L_Prop \\t R_Prop \\t Product\"\n",
    "        print np.concatenate((self.ctrl_samples[100:110], \n",
    "                              pred[100:110],\n",
    "                              np.asarray(loc_max_prop[100:110]).reshape((10,1)), \n",
    "                              np.asarray(reg_max_prop[100:110]).reshape((10,1)), \n",
    "                              np.asarray(criteria[100:110]).reshape((10,1))),axis=1)\n",
    "        print \"Choosing bin: \", item_bins[np.argmax(criteria)]\n",
    "        print \"Maximums: \", np.asarray(self.maximums)\n",
    "        print \"Pos Samples: \", self.train_data.shape[0]\n",
    "        print \"Neg Samples: \", self.train_data_cls.shape[0] - self.train_data.shape[0]\n",
    "        return max_criteria\n",
    "            \n",
    "    def get_max_variance(self):\n",
    "        pred, pred_var = self.test_samples()\n",
    "        pred_var = pred_var[:,1] - np.mean(pred_var[:,1])\n",
    "        pred_var = (pred_var / (2*np.max(np.abs(pred_var))))+0.5\n",
    "        \n",
    "        prob = np.asarray(self.get_probabilities(self.ctrl_samples)).reshape((self.ctrl_samples.shape[0],1))\n",
    "        criteria = np.multiply(np.asarray(pred_var).reshape((pred_var.shape[0],1)), prob)\n",
    "        print \"Sample\\t\\t\\t Prob \\t Var \\t Product\"\n",
    "        print np.concatenate((self.ctrl_samples[:10], prob[:10], \n",
    "                              np.asarray(pred_var[:10]).reshape((10,1)),\n",
    "                             np.asarray(criteria[:10]).reshape((10,1))),axis=1)\n",
    "        max_var = self.ctrl_samples[np.argmax(criteria)]\n",
    "        self.ctrl_samples = np.delete(self.ctrl_samples, np.argmax(criteria), 0)\n",
    "\n",
    "        return max_var\n",
    "    \n",
    "    def save_maneuvers(self):\n",
    "        output_dir = os.environ[\"PRACSYS_PATH\"] + \"prx_input/maneuvers/stored_maneuvers/opt1_dim9_50k_long/\" + str(self.iter_count) + \"/\"\n",
    "        if not os.path.exists(output_dir):\n",
    "            mkdir_p(output_dir)\n",
    "        summary_path = output_dir + \"summary.txt\"\n",
    "        with open(summary_path, \"w\") as fout:\n",
    "            fout.write(\"Maximums: \")\n",
    "            fout.write(str(np.asarray(self.maximums)))\n",
    "            fout.write(\"Pos Samples: \")\n",
    "            fout.write(str(self.train_data.shape[0]))\n",
    "            fout.write(\"Neg Samples: \")\n",
    "            fout.write(str(self.train_data_cls.shape[0] - self.train_data.shape[0]))\n",
    "            fout.write(\"\\nSum: \")\n",
    "            fout.write(str(np.sum(self.maximums)))\n",
    "        for i in range(0,self.max_controls.shape[0]):\n",
    "            output_path = output_dir + \"maneuver_\" + str(i) + \".txt\"\n",
    "            with open(output_path, \"w\") as fout:\n",
    "                ctrl = []\n",
    "                if (self.max_controls[i,:] > 0.0).any():\n",
    "                    ctrl = self.max_controls[i,:]\n",
    "                else:\n",
    "                    ctrl = np.concatenate(((np.asarray(random.sample([x / 10000.0 for x in range(10000)],1)).reshape((1,1))*0.8 + 0.2),\n",
    "                        (np.asarray(random.sample([x / 10000.0 for x in range(10000)],1)).reshape((1,1))*0.8 + 0.2),\n",
    "                        (np.asarray(random.sample([x / 10000.0 for x in range(10000)],1)).reshape((1,1))*0.8 + 0.2),\n",
    "                        (np.asarray(random.sample([x / 10000.0 for x in range(10000)],1)).reshape((1,1))*0.8 + 0.2),\n",
    "                        (np.asarray(random.sample([x / 10000.0 for x in range(10000)],1)).reshape((1,1))*0.8 + 0.2),\n",
    "                        (np.asarray(random.sample([x / 10000.0 for x in range(10000)],1)).reshape((1,1))*0.8 + 0.2),\n",
    "                        (np.asarray(random.sample([x / 10000.0 for x in range(10000)],1)).reshape((1,1))),\n",
    "                        (np.asarray(random.sample([x / 10000.0 for x in range(10000)],1)).reshape((1,1))),\n",
    "                        (np.asarray(random.sample([x / 10000.0 for x in range(10000)],1)).reshape((1,1)))), axis=1)[0,:]\n",
    "                string = \"\"\n",
    "                for idx, item in enumerate(ctrl):\n",
    "                    string = string + str(item)\n",
    "                    if idx < 8: \n",
    "                        string += \", \"\n",
    "                fout.write(string)\n",
    "                fout.write(\"\\n\")\n",
    "                fout.write(str(self.max_heading_changes[i]))\n",
    "                fout.write(\", \")\n",
    "                fout.write(str(self.maximums[i]))\n",
    "                fout.write(\", \")\n",
    "                fout.write(str(self.max_box_dims[i,0]))\n",
    "                fout.write(\", \")\n",
    "                fout.write(str(self.max_box_dims[i,1]))\n",
    "                \n",
    "def init_gp_model():\n",
    "    gp = GPRegression()\n",
    "    return gp\n",
    "\n",
    "def select_next_control():\n",
    "    # If first_iter, then select random control to propagate\n",
    "    if (gp.train_data.shape[0] == 0):\n",
    "        ctrl = np.concatenate(((np.asarray(random.sample([x / 10000.0 for x in range(10000)],1)).reshape((1,1))*0.8 + 0.2),\n",
    "            (np.asarray(random.sample([x / 10000.0 for x in range(10000)],1)).reshape((1,1))*0.8 + 0.2),\n",
    "            (np.asarray(random.sample([x / 10000.0 for x in range(10000)],1)).reshape((1,1))*0.8 + 0.2),\n",
    "            (np.asarray(random.sample([x / 10000.0 for x in range(10000)],1)).reshape((1,1))*0.8 + 0.2),\n",
    "            (np.asarray(random.sample([x / 10000.0 for x in range(10000)],1)).reshape((1,1))*0.8 + 0.2),\n",
    "            (np.asarray(random.sample([x / 10000.0 for x in range(10000)],1)).reshape((1,1))*0.8 + 0.2),\n",
    "            (np.asarray(random.sample([x / 10000.0 for x in range(10000)],1)).reshape((1,1))),\n",
    "            (np.asarray(random.sample([x / 10000.0 for x in range(10000)],1)).reshape((1,1))),\n",
    "            (np.asarray(random.sample([x / 10000.0 for x in range(10000)],1)).reshape((1,1)))), axis=1)\n",
    "        ctrl = ctrl.tolist()[0]\n",
    "    else:\n",
    "        print \"-\"*80\n",
    "        if gp.iter_count % 2 == 0:\n",
    "            ctrl = gp.get_max_variance()\n",
    "            print \"VAR Next: \", ctrl\n",
    "        else:\n",
    "            ctrl = gp.optimize_disp()\n",
    "            print \"OPT Next: \", ctrl\n",
    "        \n",
    "        if gp.iter_count % 50 == 0:\n",
    "            gp.save_maneuvers()\n",
    "    return ctrl\n",
    "\n",
    "def add_optimize(data, label):\n",
    "    gp.add_and_optimize(data, label)\n",
    "    gp.add_iter()\n",
    "    \n",
    "def add_negative(data):\n",
    "    gp.add_class_data(data, 0.0)\n",
    "    gp.add_iter()\n",
    "\n",
    "FILEHOME = os.path.abspath(os.path.curdir)\n",
    "datapath = '/home/colin/Repos/prx_ws/src/prx_output/cpg_output_snake_multistates.txt'\n",
    "np.set_printoptions(formatter={'float': '{: 0.3f}'.format})\n",
    "\n",
    "np.random.seed(1)\n",
    "random.seed(1013)\n",
    "model = snake_data.Model(datapath, 'snake')\n",
    "gp = init_gp_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added NEG Class:  [0.9938400000000001, 0.91672, 0.27896, 0.9012, 0.60456, 0.52888, 0.0549, 0.3495, 0.5231]\n",
      "OPT Kern params:  {'model.kern.lengthscales': array([ 0.500]), 'model.kern.variance': array([ 100.000])}\n",
      "Added POS:  [0.40144, 0.82392, 0.7736799999999999, 0.8477600000000001, 0.23984, 0.59648, 0.9022, 0.9189, 0.1534] [ 0.098  0.421]\n",
      "Added POS Class:  [0.40144, 0.82392, 0.7736799999999999, 0.8477600000000001, 0.23984, 0.59648, 0.9022, 0.9189, 0.1534]\n",
      "--------------------------------------------------------------------------------\n",
      "Sample\t\t\t Prob \t Var \t Product\n",
      "[[ 0.791  0.766  0.580  0.743  0.732  0.754  0.405  0.427  0.275  0.510\n",
      "   0.501  0.256]\n",
      " [ 0.567  0.835  0.729  0.524  0.565  0.809  0.909  0.390  0.789  0.510\n",
      "   0.501  0.256]\n",
      " [ 0.738  0.647  0.527  0.243  0.971  0.772  0.722  0.923  0.749  0.510\n",
      "   0.514  0.262]\n",
      " [ 0.720  0.605  0.559  0.666  0.829  0.986  0.061  0.602  0.361  0.510\n",
      "   0.514  0.262]\n",
      " [ 0.227  0.994  0.811  0.213  0.429  0.547  0.742  0.533  0.685  0.510\n",
      "   0.501  0.255]\n",
      " [ 0.995  0.601  0.545  0.877  0.389  0.504  0.493  0.471  0.172  0.510\n",
      "   0.493  0.251]\n",
      " [ 0.826  0.491  0.435  0.250  0.613  0.704  0.395  0.849  0.228  0.510\n",
      "   0.509  0.260]\n",
      " [ 0.433  0.876  0.956  0.521  0.350  0.651  0.776  0.560  0.794  0.510\n",
      "   0.477  0.243]\n",
      " [ 0.581  0.576  0.963  0.276  0.852  0.832  0.905  0.453  0.886  0.510\n",
      "   0.514  0.262]\n",
      " [ 0.761  0.577  0.365  0.755  0.905  0.819  0.211  0.030  0.174  0.510\n",
      "   0.515  0.263]]\n",
      "VAR Next:  [ 0.708  0.254  0.380  0.319  0.962  0.952  0.016  0.046  0.989]\n",
      "Added NEG Class:  [ 0.708  0.254  0.380  0.319  0.962  0.952  0.016  0.046  0.989]\n",
      "--------------------------------------------------------------------------------\n",
      "...................... Debug ...................................\n",
      "Max Pred: \n",
      "[ 0.348  0.765  0.746  0.970  0.249  0.742  0.873  0.773  0.143] [ 0.086  0.369] 0.876444796226 0.876444796226 [ 0.343] [ 0.264]\n",
      "Nearest:  (0.2558778882279593, 0) [ 0.401  0.824  0.774  0.848  0.240  0.596  0.902  0.919  0.153] [ 0.098  0.421]\n",
      "................................................................\n",
      "Sample\t\t\t p[head] \t P[disp] \t L_Prop \t R_Prop \t Product\n",
      "[[ 0.639  0.290  0.286  0.304  0.311  0.717  0.654  0.851  0.606  0.010\n",
      "   0.041  0.097  0.097  0.003]\n",
      " [ 0.287  0.407  0.856  0.298  0.760  0.308  0.509  0.230  0.916  0.002\n",
      "   0.007  0.016  0.016  0.000]\n",
      " [ 0.314  0.938  0.457  0.564  0.576  0.480  0.077  0.884  0.856  0.005\n",
      "   0.021  0.049  0.049  0.001]\n",
      " [ 0.775  0.388  0.457  0.810  0.895  0.495  0.585  0.612  0.355  0.011\n",
      "   0.046  0.109  0.109  0.004]\n",
      " [ 0.720  0.967  0.489  0.657  0.535  0.507  0.794  0.381  0.581  0.019\n",
      "   0.082  0.195  0.195  0.013]\n",
      " [ 0.863  0.328  0.671  0.204  0.363  0.864  0.281  0.055  0.554  0.001\n",
      "   0.005  0.011  0.011  0.000]\n",
      " [ 0.994  0.580  0.905  0.285  0.472  0.477  0.606  0.919  0.881  0.006\n",
      "   0.024  0.057  0.057  0.001]\n",
      " [ 0.997  0.787  0.766  0.630  0.558  0.901  0.810  0.038  0.359  0.006\n",
      "   0.024  0.058  0.058  0.001]\n",
      " [ 0.765  0.382  0.769  0.379  0.666  0.949  0.173  0.598  0.380  0.005\n",
      "   0.019  0.046  0.046  0.001]\n",
      " [ 0.351  0.893  0.595  0.761  0.561  0.868  0.556  0.344  0.525  0.019\n",
      "   0.083  0.197  0.197  0.013]]\n",
      "Choosing bin:  5\n",
      "Maximums:  [ 0.000  0.000  0.000  0.000  0.000  0.421  0.000  0.000  0.000  0.000]\n",
      "Pos Samples:  1\n",
      "Neg Samples:  2\n",
      "OPT Next:  [ 0.348  0.765  0.746  0.970  0.249  0.742  0.873  0.773  0.143]\n",
      "Added NEG Class:  [ 0.348  0.765  0.746  0.970  0.249  0.742  0.873  0.773  0.143]\n",
      "--------------------------------------------------------------------------------\n",
      "Sample\t\t\t Prob \t Var \t Product\n",
      "[[ 0.791  0.766  0.580  0.743  0.732  0.754  0.405  0.427  0.275  0.260\n",
      "   0.502  0.130]\n",
      " [ 0.567  0.835  0.729  0.524  0.565  0.809  0.909  0.390  0.789  0.260\n",
      "   0.501  0.130]\n",
      " [ 0.738  0.647  0.527  0.243  0.971  0.772  0.722  0.923  0.749  0.260\n",
      "   0.514  0.134]\n",
      " [ 0.720  0.605  0.559  0.666  0.829  0.986  0.061  0.602  0.361  0.260\n",
      "   0.514  0.134]\n",
      " [ 0.227  0.994  0.811  0.213  0.429  0.547  0.742  0.533  0.685  0.260\n",
      "   0.501  0.130]\n",
      " [ 0.995  0.601  0.545  0.877  0.389  0.504  0.493  0.471  0.172  0.260\n",
      "   0.493  0.128]\n",
      " [ 0.826  0.491  0.435  0.250  0.613  0.704  0.395  0.849  0.228  0.260\n",
      "   0.509  0.132]\n",
      " [ 0.433  0.876  0.956  0.521  0.350  0.651  0.776  0.560  0.794  0.260\n",
      "   0.476  0.124]\n",
      " [ 0.581  0.576  0.963  0.276  0.852  0.832  0.905  0.453  0.886  0.260\n",
      "   0.515  0.134]\n",
      " [ 0.761  0.577  0.365  0.755  0.905  0.819  0.211  0.030  0.174  0.260\n",
      "   0.515  0.134]]\n",
      "VAR Next:  [ 0.245  0.460  0.238  0.260  0.979  0.446  0.002  0.012  0.928]\n",
      "Added NEG Class:  [ 0.245  0.460  0.238  0.260  0.979  0.446  0.002  0.012  0.928]\n",
      "--------------------------------------------------------------------------------\n",
      "...................... Debug ...................................\n",
      "Max Pred: \n",
      "[ 0.334  0.780  0.919  0.894  0.315  0.468  0.890  0.781  0.094] [ 0.085  0.363] 0.861043253521 0.861043253521 [ 0.210] [ 0.156]\n",
      "Nearest:  (0.27264992952869077, 0) [ 0.401  0.824  0.774  0.848  0.240  0.596  0.902  0.919  0.153] [ 0.098  0.421]\n",
      "................................................................\n",
      "Sample\t\t\t p[head] \t P[disp] \t L_Prop \t R_Prop \t Product\n",
      "[[ 0.639  0.290  0.286  0.304  0.311  0.717  0.654  0.851  0.606  0.010\n",
      "   0.041  0.097  0.097  0.002]\n",
      " [ 0.287  0.407  0.856  0.298  0.760  0.308  0.509  0.230  0.916  0.002\n",
      "   0.007  0.016  0.016  0.000]\n",
      " [ 0.314  0.938  0.457  0.564  0.576  0.480  0.077  0.884  0.856  0.005\n",
      "   0.021  0.049  0.049  0.001]\n",
      " [ 0.775  0.388  0.457  0.810  0.895  0.495  0.585  0.612  0.355  0.011\n",
      "   0.046  0.109  0.109  0.003]\n",
      " [ 0.720  0.967  0.489  0.657  0.535  0.507  0.794  0.381  0.581  0.019\n",
      "   0.082  0.195  0.195  0.008]\n",
      " [ 0.863  0.328  0.671  0.204  0.363  0.864  0.281  0.055  0.554  0.001\n",
      "   0.005  0.011  0.011  0.000]\n",
      " [ 0.994  0.580  0.905  0.285  0.472  0.477  0.606  0.919  0.881  0.006\n",
      "   0.024  0.057  0.057  0.001]\n",
      " [ 0.997  0.787  0.766  0.630  0.558  0.901  0.810  0.038  0.359  0.006\n",
      "   0.024  0.058  0.058  0.001]\n",
      " [ 0.765  0.382  0.769  0.379  0.666  0.949  0.173  0.598  0.380  0.005\n",
      "   0.019  0.046  0.046  0.000]\n",
      " [ 0.351  0.893  0.595  0.761  0.561  0.868  0.556  0.344  0.525  0.019\n",
      "   0.083  0.197  0.197  0.008]]\n",
      "Choosing bin:  5\n",
      "Maximums:  [ 0.000  0.000  0.000  0.000  0.000  0.421  0.000  0.000  0.000  0.000]\n",
      "Pos Samples:  1\n",
      "Neg Samples:  4\n",
      "OPT Next:  [ 0.334  0.780  0.919  0.894  0.315  0.468  0.890  0.781  0.094]\n",
      "OPT Kern params:  {'model.kern.lengthscales': array([ 0.500]), 'model.kern.variance': array([ 100.000])}\n",
      "Added POS:  [ 0.334  0.780  0.919  0.894  0.315  0.468  0.890  0.781  0.094] [ 0.989  0.748]\n",
      "Added POS Class:  [ 0.334  0.780  0.919  0.894  0.315  0.468  0.890  0.781  0.094]\n",
      "--------------------------------------------------------------------------------\n",
      "Sample\t\t\t Prob \t Var \t Product\n",
      "[[ 0.791  0.766  0.580  0.743  0.732  0.754  0.405  0.427  0.275  0.343\n",
      "   0.504  0.173]\n",
      " [ 0.567  0.835  0.729  0.524  0.565  0.809  0.909  0.390  0.789  0.343\n",
      "   0.504  0.173]\n",
      " [ 0.738  0.647  0.527  0.243  0.971  0.772  0.722  0.923  0.749  0.343\n",
      "   0.515  0.177]\n",
      " [ 0.720  0.605  0.559  0.666  0.829  0.986  0.061  0.602  0.361  0.343\n",
      "   0.516  0.177]\n",
      " [ 0.227  0.994  0.811  0.213  0.429  0.547  0.742  0.533  0.685  0.343\n",
      "   0.503  0.173]\n",
      " [ 0.995  0.601  0.545  0.877  0.389  0.504  0.493  0.471  0.172  0.343\n",
      "   0.496  0.170]\n",
      " [ 0.826  0.491  0.435  0.250  0.613  0.704  0.395  0.849  0.228  0.343\n",
      "   0.511  0.175]\n",
      " [ 0.433  0.876  0.956  0.521  0.350  0.651  0.776  0.560  0.794  0.343\n",
      "   0.480  0.165]\n",
      " [ 0.581  0.576  0.963  0.276  0.852  0.832  0.905  0.453  0.886  0.343\n",
      "   0.516  0.177]\n",
      " [ 0.761  0.577  0.365  0.755  0.905  0.819  0.211  0.030  0.174  0.343\n",
      "   0.517  0.177]]\n",
      "VAR Next:  [ 0.873  0.256  0.447  0.294  0.825  0.741  0.026  0.008  0.829]\n",
      "OPT Kern params:  {'model.kern.lengthscales': array([ 0.500]), 'model.kern.variance': array([ 100.000])}\n",
      "Added POS:  [ 0.873  0.256  0.447  0.294  0.825  0.741  0.026  0.008  0.829] [ 0.446  0.222]\n",
      "Added POS Class:  [ 0.873  0.256  0.447  0.294  0.825  0.741  0.026  0.008  0.829]\n",
      "--------------------------------------------------------------------------------\n",
      "...................... Debug ...................................\n",
      "Max Pred: \n",
      "[ 0.318  0.636  0.953  0.962  0.273  0.509  0.868  0.598  0.099] [ 1.121  0.731] 0.976586377086 0.976586377086 [ 0.439] [ 0.418]\n",
      "Nearest:  (0.25425748223405337, 1) [ 0.334  0.780  0.919  0.894  0.315  0.468  0.890  0.781  0.094] [ 0.989  0.748]\n",
      "................................................................\n",
      "Sample\t\t\t p[head] \t P[disp] \t L_Prop \t R_Prop \t Product\n",
      "[[ 0.639  0.290  0.286  0.304  0.311  0.717  0.654  0.851  0.606 -0.072\n",
      "   0.007  0.017  0.010  0.000]\n",
      " [ 0.287  0.407  0.856  0.298  0.760  0.308  0.509  0.230  0.916  0.097\n",
      "   0.052  0.233  0.069  0.007]\n",
      " [ 0.314  0.938  0.457  0.564  0.576  0.480  0.077  0.884  0.856 -0.005\n",
      "   0.017  0.041  0.023  0.000]\n",
      " [ 0.775  0.388  0.457  0.810  0.895  0.495  0.585  0.612  0.355  0.107\n",
      "   0.090  0.120  0.120  0.006]\n",
      " [ 0.720  0.967  0.489  0.657  0.535  0.507  0.794  0.381  0.581  0.053\n",
      "   0.098  0.232  0.130  0.013]\n",
      " [ 0.863  0.328  0.671  0.204  0.363  0.864  0.281  0.055  0.554  0.190\n",
      "   0.098  0.443  0.132  0.026]\n",
      " [ 0.994  0.580  0.905  0.285  0.472  0.477  0.606  0.919  0.881 -0.006\n",
      "   0.020  0.048  0.027  0.001]\n",
      " [ 0.997  0.787  0.766  0.630  0.558  0.901  0.810  0.038  0.359  0.065\n",
      "   0.051  0.069  0.069  0.002]\n",
      " [ 0.765  0.382  0.769  0.379  0.666  0.949  0.173  0.598  0.380  0.098\n",
      "   0.066  0.296  0.088  0.011]\n",
      " [ 0.351  0.893  0.595  0.761  0.561  0.868  0.556  0.344  0.525  0.095\n",
      "   0.117  0.277  0.156  0.019]]\n",
      "Choosing bin:  5\n",
      "Maximums:  [ 0.000  0.000  0.000  0.000  0.000  0.748  0.000  0.000  0.000  0.000]\n",
      "Pos Samples:  3\n",
      "Neg Samples:  4\n",
      "OPT Next:  [ 0.318  0.636  0.953  0.962  0.273  0.509  0.868  0.598  0.099]\n",
      "OPT Kern params:  {'model.kern.lengthscales': array([ 0.500]), 'model.kern.variance': array([ 100.000])}\n",
      "Added POS:  [ 0.318  0.636  0.953  0.962  0.273  0.509  0.868  0.598  0.099] [ 0.448  0.909]\n",
      "Added POS Class:  [ 0.318  0.636  0.953  0.962  0.273  0.509  0.868  0.598  0.099]\n",
      "--------------------------------------------------------------------------------\n",
      "Sample\t\t\t Prob \t Var \t Product\n",
      "[[ 0.791  0.766  0.580  0.743  0.732  0.754  0.405  0.427  0.275  0.510\n",
      "   0.506  0.258]\n",
      " [ 0.567  0.835  0.729  0.524  0.565  0.809  0.909  0.390  0.789  0.510\n",
      "   0.513  0.261]\n",
      " [ 0.738  0.647  0.527  0.243  0.971  0.772  0.722  0.923  0.749  0.510\n",
      "   0.525  0.268]\n",
      " [ 0.720  0.605  0.559  0.666  0.829  0.986  0.061  0.602  0.361  0.510\n",
      "   0.513  0.261]\n",
      " [ 0.227  0.994  0.811  0.213  0.429  0.547  0.742  0.533  0.685  0.510\n",
      "   0.515  0.263]\n",
      " [ 0.995  0.601  0.545  0.877  0.389  0.504  0.493  0.471  0.172  0.510\n",
      "   0.498  0.254]\n",
      " [ 0.826  0.491  0.435  0.250  0.613  0.704  0.395  0.849  0.228  0.510\n",
      "   0.519  0.265]\n",
      " [ 0.433  0.876  0.956  0.521  0.350  0.651  0.776  0.560  0.794  0.510\n",
      "   0.492  0.251]\n",
      " [ 0.581  0.576  0.963  0.276  0.852  0.832  0.905  0.453  0.886  0.510\n",
      "   0.525  0.268]\n",
      " [ 0.761  0.577  0.365  0.755  0.905  0.819  0.211  0.030  0.174  0.510\n",
      "   0.505  0.258]]\n",
      "VAR Next:  [ 0.244  0.868  0.212  0.374  0.925  0.224  0.048  0.993  0.543]\n",
      "OPT Kern params:  {'model.kern.lengthscales': array([ 0.500]), 'model.kern.variance': array([ 100.000])}\n",
      "Added POS:  [ 0.244  0.868  0.212  0.374  0.925  0.224  0.048  0.993  0.543] [ 0.903  0.119]\n",
      "Added POS Class:  [ 0.244  0.868  0.212  0.374  0.925  0.224  0.048  0.993  0.543]\n",
      "--------------------------------------------------------------------------------\n",
      "...................... Debug ...................................\n",
      "Max Pred: \n",
      "[ 0.425  0.673  0.882  0.904  0.389  0.529  0.899  0.526  0.001] [ 0.490  0.819] 0.901093226052 0.901093226052 [ 0.566] [ 0.459]\n",
      "Nearest:  (0.22501380562978798, 3) [ 0.318  0.636  0.953  0.962  0.273  0.509  0.868  0.598  0.099] [ 0.448  0.909]\n",
      "................................................................\n",
      "Sample\t\t\t p[head] \t P[disp] \t L_Prop \t R_Prop \t Product\n",
      "[[ 0.639  0.290  0.286  0.304  0.311  0.717  0.654  0.851  0.606 -0.093\n",
      "   0.030  0.070  0.033  0.001]\n",
      " [ 0.287  0.407  0.856  0.298  0.760  0.308  0.509  0.230  0.916  0.102\n",
      "   0.064  0.288  0.070  0.011]\n",
      " [ 0.314  0.938  0.457  0.564  0.576  0.480  0.077  0.884  0.856  0.392\n",
      "   0.067  0.559  0.073  0.023]\n",
      " [ 0.775  0.388  0.457  0.810  0.895  0.495  0.585  0.612  0.355  0.092\n",
      "   0.118  0.130  0.130  0.010]\n",
      " [ 0.720  0.967  0.489  0.657  0.535  0.507  0.794  0.381  0.581  0.023\n",
      "   0.120  0.285  0.132  0.021]\n",
      " [ 0.863  0.328  0.671  0.204  0.363  0.864  0.281  0.055  0.554  0.162\n",
      "   0.106  0.477  0.117  0.031]\n",
      " [ 0.994  0.580  0.905  0.285  0.472  0.477  0.606  0.919  0.881  0.012\n",
      "   0.024  0.057  0.027  0.001]\n",
      " [ 0.997  0.787  0.766  0.630  0.558  0.901  0.810  0.038  0.359 -0.040\n",
      "   0.080  0.088  0.088  0.004]\n",
      " [ 0.765  0.382  0.769  0.379  0.666  0.949  0.173  0.598  0.380  0.083\n",
      "   0.083  0.372  0.091  0.019]\n",
      " [ 0.351  0.893  0.595  0.761  0.561  0.868  0.556  0.344  0.525 -0.053\n",
      "   0.172  0.189  0.189  0.020]]\n",
      "Choosing bin:  5\n",
      "Maximums:  [ 0.000  0.000  0.000  0.000  0.000  0.909  0.000  0.000  0.000  0.000]\n",
      "Pos Samples:  5\n",
      "Neg Samples:  4\n",
      "OPT Next:  [ 0.425  0.673  0.882  0.904  0.389  0.529  0.899  0.526  0.001]\n",
      "Added NEG Class:  [ 0.425  0.673  0.882  0.904  0.389  0.529  0.899  0.526  0.001]\n",
      "--------------------------------------------------------------------------------\n",
      "Sample\t\t\t Prob \t Var \t Product\n",
      "[[ 0.791  0.766  0.580  0.743  0.732  0.754  0.405  0.427  0.275  0.510\n",
      "   0.510  0.260]\n",
      " [ 0.567  0.835  0.729  0.524  0.565  0.809  0.909  0.390  0.789  0.510\n",
      "   0.518  0.264]\n",
      " [ 0.738  0.647  0.527  0.243  0.971  0.772  0.722  0.923  0.749  0.510\n",
      "   0.526  0.268]\n",
      " [ 0.720  0.605  0.559  0.666  0.829  0.986  0.061  0.602  0.361  0.510\n",
      "   0.515  0.262]\n",
      " [ 0.227  0.994  0.811  0.213  0.429  0.547  0.742  0.533  0.685  0.510\n",
      "   0.519  0.265]\n",
      " [ 0.995  0.601  0.545  0.877  0.389  0.504  0.493  0.471  0.172  0.510\n",
      "   0.503  0.256]\n",
      " [ 0.826  0.491  0.435  0.250  0.613  0.704  0.395  0.849  0.228  0.510\n",
      "   0.518  0.264]\n",
      " [ 0.433  0.876  0.956  0.521  0.350  0.651  0.776  0.560  0.794  0.510\n",
      "   0.497  0.253]\n",
      " [ 0.581  0.576  0.963  0.276  0.852  0.832  0.905  0.453  0.886  0.510\n",
      "   0.531  0.271]\n",
      " [ 0.761  0.577  0.365  0.755  0.905  0.819  0.211  0.030  0.174  0.510\n",
      "   0.510  0.260]]\n",
      "VAR Next:  [ 0.992  0.343  0.998  0.206  0.527  0.219  0.999  0.666  0.950]\n",
      "OPT Kern params:  {'model.kern.lengthscales': array([ 0.500]), 'model.kern.variance': array([ 100.000])}\n",
      "Added POS:  [ 0.992  0.343  0.998  0.206  0.527  0.219  0.999  0.666  0.950] [ 0.910  0.299]\n",
      "Added POS Class:  [ 0.992  0.343  0.998  0.206  0.527  0.219  0.999  0.666  0.950]\n"
     ]
    }
   ],
   "source": [
    "# np.random.seed(0)\n",
    "\n",
    "gp = init_gp_model()\n",
    "for idx in range(0,11):\n",
    "    ctrl = select_next_control()\n",
    "    label = np.random.random(2)\n",
    "    cls = np.random.randint(0,2)\n",
    "    if cls == 0:\n",
    "        add_negative(ctrl)\n",
    "    else:\n",
    "        add_optimize(ctrl, label)\n",
    "#     gp.test_class(model.train_data[idx], np.random.randint(0,2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mlengthscales\u001b[0m transform:+ve prior:None\n",
      "[ 18.59493  35.59242  17.04945  1.03225]\n",
      "[False False False False]\n",
      "\u001b[1mlengthscales\u001b[0m transform:+ve prior:None\n",
      "[ 18.59493  35.59242  17.04945  1.03225]\n"
     ]
    }
   ],
   "source": [
    "# gp.model.kern.lengthscales = np.asarray([ 3.81204,  1112.49888,  1.87983,  14.38833])\n",
    "print gp.model.kern.lengthscales\n",
    "gp.model.kern.lengthscales = gp.model.kern.lengthscales.value + ((np.array(gp.model.kern.lengthscales.value)) < 0.1)*1\n",
    "print gp.model.kern.lengthscales\n",
    "\n",
    "# print gp.model.kern.lengthscales.value + (np.array(gp.model.kern.lengthscales.value) < 0.0001)*1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# POS samples to check:\n",
    "#     [0.60412, 0.2395375, 0.90696, 0.9685600000000001] \n",
    "# 30 degrees/second w 0.07 disp\n",
    "# [ 0.40282   0.754825  0.25592   0.37912 ]\n",
    "item = np.array([ 0.40282,   0.754825,  0.25592,   0.37912 ])\n",
    "res = gp.nn_tree.query(item, k=1, distance_upper_bound=6)\n",
    "print res[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.48058    0.1989375  0.54712    0.36696  ]\n",
      " [ 0.90844    0.3214375  0.84656    0.23368  ]\n",
      " [ 0.85822    0.720525   0.27456    0.51936  ]]\n"
     ]
    }
   ],
   "source": [
    "print gp.ctrl_samples[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[ 0.29513445]]), nan)\n",
      "(array([[ 0.75567769]]), nan)\n",
      "(array([[ 0.,  0.]]), array([[ 104.34142856]]))\n",
      "(array([[ 0.,  0.]]), array([[ 104.34142856]]))\n"
     ]
    }
   ],
   "source": [
    "print gp.gp_cls.predict(np.asarray([[ 0.98662 ,  0.945575,  0.54648 ,  0.98688 ]]))\n",
    "print gp.gp_cls.predict(np.asarray([[ 0.4  ,  0.4,  0.4  ,  0.4  ]]))\n",
    "\n",
    "print gp.model.predict(np.asarray([[ 0.98662 ,  0.945575,  0.54648 ,  0.7 ]]))\n",
    "print gp.model.predict(np.asarray([[0.54088,     0.401325,    0.77016,     0.50064 ]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.86434   0.702675  0.7592    0.6832  ] [ 0.51032556]\n",
      "[ 0.60838   0.263775  0.63784   0.5316  ] [ 0.52646589]\n",
      "[ 0.67396    0.4922375  0.5008     0.3548   ] [ 0.65448981]\n",
      "[ 0.75268  0.2349   0.37136  0.57528] [ 0.58994663]\n",
      "[ 0.66808    0.7832625  0.7988     0.61928  ] [ 0.51981089]\n",
      "[ 0.7534     0.5123625  0.33664    0.65136  ] [ 0.58895835]\n",
      "[ 0.50464    0.3329875  0.6252     0.37552  ] [ 0.59338669]\n",
      "[ 0.64228    0.8826625  0.48568    0.56312  ] [ 0.54886105]\n",
      "[ 0.95776    0.4005375  0.22008    0.25016  ] [ 0.59656452]\n",
      "[ 0.80308    0.6478125  0.24112    0.46728  ] [ 0.59544387]\n",
      "[ 0.8647     0.7844875  0.3892     0.34904  ] [ 0.55990568]\n",
      "[ 0.54346    0.5414125  0.34184    0.74848  ] [ 0.59541713]\n",
      "[ 0.87196   0.465725  0.2168    0.51568 ] [ 0.58612111]\n",
      "[ 0.4891     0.3550375  0.55944    0.20832  ] [ 0.59448168]\n",
      "[ 0.46252    0.4455125  0.3464     0.9532   ] [ 0.51102683]\n",
      "[ 0.58846   0.207425  0.65352   0.49248 ] [ 0.50780467]\n",
      "[ 0.60808    0.9349875  0.5844     0.48288  ] [ 0.53402976]\n",
      "[ 0.99784    0.6782625  0.62192    0.59736  ] [ 0.5191299]\n",
      "[ 0.78244    0.8737375  0.52408    0.40448  ] [ 0.54441062]\n",
      "[ 0.4486     0.3034125  0.33056    0.65112  ] [ 0.7299104]\n",
      "[ 0.59116    0.1284125  0.42928    0.55168  ] [ 0.63186954]\n",
      "[ 0.65806    0.8669125  0.37488    0.23984  ] [ 0.53140016]\n",
      "[ 0.96832   0.736275  0.39256   0.26008 ] [ 0.53727069]\n",
      "[ 0.58954    0.5527875  0.31832    0.21392  ] [ 0.66326933]\n",
      "[ 0.9517     0.4196125  0.39408    0.35912  ] [ 0.57754161]\n",
      "[ 0.8497    0.803475  0.28064   0.22376 ] [ 0.54388928]\n",
      "[ 0.40906    0.3539875  0.26872    0.68496  ] [ 0.71216543]\n",
      "[ 0.86458  0.4722   0.37592  0.37208] [ 0.62656225]\n",
      "[ 0.53956   0.629175  0.62176   0.78064 ] [ 0.53709973]\n",
      "[ 0.44446   0.740475  0.3548    0.69384 ] [ 0.51285078]\n",
      "[ 0.526     0.476925  0.46152   0.63304 ] [ 0.7069137]\n",
      "[ 0.42292    0.5386125  0.42864    0.296    ] [ 0.68749248]\n",
      "[ 0.8644    0.893425  0.74136   0.64024 ] [ 0.53258783]\n",
      "[ 0.59404   0.580175  0.23024   0.608   ] [ 0.62080665]\n",
      "[ 0.64426    0.3074375  0.20656    0.64208  ] [ 0.64587721]\n",
      "[ 0.82636    0.7353125  0.606      0.55584  ] [ 0.58331921]\n",
      "[ 0.4      0.25765  0.65472  0.55952] [ 0.57835588]\n",
      "[ 0.85372    0.7158875  0.46496    0.44288  ] [ 0.58799317]\n",
      "[ 0.7399     0.5923375  0.23864    0.47784  ] [ 0.63280337]\n",
      "[ 0.83116  0.6367   0.64352  0.4528 ] [ 0.52797465]\n",
      "[ 0.74782  0.13795  0.27424  0.42408] [ 0.62709161]\n",
      "[ 0.84196    0.9524875  0.48976    0.43152  ] [ 0.5281785]\n",
      "[ 0.93172  0.75605  0.43144  0.42712] [ 0.55970434]\n",
      "[ 0.97024  0.65175  0.47432  0.52008] [ 0.5518922]\n",
      "[ 0.74032  0.69165  0.50784  0.73504] [ 0.53277498]\n",
      "[ 0.44704   0.243125  0.4424    0.73528 ] [ 0.64825491]\n",
      "[ 0.41968    0.4346625  0.62432    0.3824   ] [ 0.62053009]\n",
      "[ 0.77662   0.708625  0.70376   0.46632 ] [ 0.51419631]\n",
      "[ 0.48538  0.47185  0.36184  0.47328] [ 0.76449645]\n",
      "[ 0.42496    0.1588625  0.23472    0.67696  ] [ 0.70005023]\n",
      "[ 0.6982     0.3468125  0.34344    0.60904  ] [ 0.64660233]\n",
      "[ 0.4981     0.5167375  0.33832    0.41056  ] [ 0.74537918]\n",
      "[ 0.58402    0.7627875  0.354      0.30456  ] [ 0.59520505]\n",
      "[ 0.72838    0.2402375  0.28344    0.29624  ] [ 0.67136658]\n",
      "[ 0.58906    0.6404625  0.50464    0.69704  ] [ 0.61112237]\n",
      "[ 0.51136   0.577725  0.53128   0.81032 ] [ 0.54535557]\n",
      "[ 0.47194  0.52295  0.3964   0.74696] [ 0.62833554]\n",
      "[ 0.59596    0.7661125  0.64232    0.50344  ] [ 0.5825156]\n",
      "[ 0.6358   0.55165  0.5696   0.79232] [ 0.53011267]\n",
      "[ 0.88264  0.37665  0.36408  0.35984] [ 0.61603163]\n",
      "[ 0.44374    0.3702625  0.66544    0.63     ] [ 0.57620277]\n",
      "[ 0.59668   0.560225  0.34216   0.51408 ] [ 0.71170302]\n",
      "[ 0.9814     0.8884375  0.6488     0.59944  ] [ 0.52855117]\n",
      "[ 0.90994   0.364225  0.34856   0.35864 ] [ 0.60443318]\n",
      "[ 0.81604   0.825875  0.42936   0.32784 ] [ 0.54688636]\n",
      "[ 0.77152    0.5940875  0.23544    0.65984  ] [ 0.52641459]\n",
      "[ 0.67384  0.3133   0.31848  0.40592] [ 0.71696687]\n",
      "[ 0.56266  0.41235  0.26536  0.88832] [ 0.52132462]\n",
      "[ 0.51088   0.627075  0.56872   0.20112 ] [ 0.52380425]\n",
      "[ 0.733     0.218625  0.43632   0.49808 ] [ 0.60487764]\n",
      "[ 0.4801    0.375075  0.25072   0.95416 ] [ 0.53221688]\n",
      "[ 0.48562    0.7057375  0.44808    0.30928  ] [ 0.61389489]\n",
      "[ 0.44044   0.680275  0.32768   0.396   ] [ 0.65200075]\n",
      "[ 0.85744   0.933675  0.72552   0.5572  ] [ 0.53214282]\n",
      "[ 0.51526    0.4691375  0.3816     0.30984  ] [ 0.72866794]\n",
      "[ 0.98956    0.5485875  0.22608    0.31632  ] [ 0.57663325]\n",
      "[ 0.59884    0.2659625  0.20144    0.26904  ] [ 0.69104173]\n",
      "[ 0.45712    0.4085875  0.34728    0.22848  ] [ 0.70157072]\n",
      "[ 0.77146    0.6327625  0.2348     0.20496  ] [ 0.60470384]\n",
      "[ 0.95182   0.780025  0.65768   0.53184 ] [ 0.5373729]\n",
      "[ 0.7618     0.7526375  0.60536    0.54848  ] [ 0.59711093]\n",
      "[ 0.41146    0.2325375  0.22904    0.21264  ] [ 0.66584835]\n",
      "[ 0.6001     0.4348375  0.59592    0.65264  ] [ 0.60179875]\n",
      "[ 0.5374    0.167525  0.4332    0.41096 ] [ 0.68203515]\n",
      "[ 0.85678   0.615175  0.34352   0.20464 ] [ 0.58389683]\n",
      "[ 0.94354   0.890275  0.374     0.31496 ] [ 0.52225827]\n",
      "[ 0.4693     0.1985875  0.2216     0.28776  ] [ 0.6890988]\n",
      "[ 0.57406  0.51875  0.5324   0.44296] [ 0.69295734]\n",
      "[ 0.6403    0.533275  0.38264   0.40096 ] [ 0.71760144]\n",
      "[ 0.93538   0.960975  0.41904   0.3612  ] [ 0.5137736]\n",
      "[ 0.48694    0.1635875  0.21448    0.34872  ] [ 0.69344946]\n",
      "[ 0.97366    0.4164625  0.4888     0.4724   ] [ 0.51483302]\n",
      "[ 0.73276    0.4491875  0.25008    0.22368  ] [ 0.66614623]\n",
      "[ 0.92182    0.6070375  0.384      0.56192  ] [ 0.55745001]\n",
      "[ 0.46468   0.353375  0.51808   0.7708  ] [ 0.60290703]\n",
      "[ 0.68368    0.5197125  0.62408    0.70712  ] [ 0.54944534]\n",
      "[ 0.61864   0.796825  0.57056   0.31824 ] [ 0.51834419]\n",
      "[ 0.43744    0.6199875  0.22208    0.77344  ] [ 0.51042363]\n",
      "[ 0.99574    0.3559125  0.28144    0.5172   ] [ 0.52252498]\n",
      "[ 0.88054    0.5347625  0.20928    0.27832  ] [ 0.61147815]\n",
      "[ 0.49918    0.6455375  0.21656    0.49648  ] [ 0.63127467]\n",
      "[ 0.60172   0.224225  0.46624   0.61184 ] [ 0.62658205]\n",
      "[ 0.5881     0.6392375  0.66944    0.41184  ] [ 0.54077865]\n",
      "[ 0.40984   0.794375  0.39776   0.2576  ] [ 0.56161631]\n",
      "[ 0.91318   0.786325  0.2492    0.5112  ] [ 0.51360879]\n",
      "[ 0.5308   0.6682   0.76776  0.5288 ] [ 0.51419369]\n",
      "[ 0.67      0.292475  0.44984   0.48576 ] [ 0.66815412]\n",
      "[ 0.81658    0.2645625  0.42264    0.29664  ] [ 0.60564495]\n",
      "[ 0.7663     0.9052375  0.6684     0.57752  ] [ 0.555269]\n",
      "[ 0.57562    0.7486125  0.74056    0.6592   ] [ 0.54105636]\n",
      "[ 0.80146  0.3035   0.44144  0.21944] [ 0.5963418]\n",
      "[ 0.69682    0.8375125  0.41688    0.3572   ] [ 0.56147793]\n",
      "[ 0.4738    0.796475  0.53304   0.50096 ] [ 0.59042029]\n",
      "[ 0.6367     0.1852875  0.25816    0.39128  ] [ 0.6903907]\n",
      "[ 0.43828   0.421625  0.22136   0.55288 ] [ 0.72923187]\n",
      "[ 0.91798    0.3450625  0.44432    0.23824  ] [ 0.55844351]\n",
      "[ 0.97522    0.7883375  0.62752    0.61248  ] [ 0.53417561]\n",
      "[ 0.71764   0.363175  0.60888   0.534   ] [ 0.53500914]\n",
      "[ 0.50974    0.3025375  0.48048    0.87952  ] [ 0.52197887]\n",
      "[ 0.80314    0.5225125  0.39016    0.38768  ] [ 0.65074419]\n",
      "[ 0.57064   0.561275  0.41432   0.26016 ] [ 0.66472928]\n",
      "[ 0.51658   0.598375  0.6428    0.3804  ] [ 0.56751641]\n",
      "[ 0.61702    0.7274375  0.73144    0.69936  ] [ 0.53897463]\n",
      "[ 0.4558    0.442975  0.55144   0.56128 ] [ 0.70103447]\n",
      "[ 0.94312  0.6101   0.4104   0.5944 ] [ 0.53733683]\n",
      "[ 0.77668  0.5268   0.52456  0.32344] [ 0.57834218]\n",
      "[ 0.41974   0.573525  0.54952   0.31016 ] [ 0.62281483]\n",
      "[ 0.45202    0.5841125  0.53288    0.67416  ] [ 0.6468262]\n",
      "[ 0.83416  0.1551   0.26384  0.41008] [ 0.59602669]\n",
      "[ 0.53146  0.6276   0.43736  0.54536] [ 0.69453866]\n",
      "[ 0.73486    0.5590875  0.60464    0.37816  ] [ 0.54664552]\n",
      "[ 0.52078    0.8175625  0.52056    0.3068   ] [ 0.53464815]\n",
      "[ 0.6478     0.8707625  0.53344    0.49064  ] [ 0.56791801]\n",
      "[ 0.83914   0.179075  0.21936   0.23912 ] [ 0.61046685]\n",
      "[ 0.67996    0.7599875  0.4964     0.2492   ] [ 0.53015221]\n",
      "[ 0.51358    0.1452125  0.55472    0.45824  ] [ 0.60598871]\n",
      "[ 0.69052  0.44525  0.38192  0.48888] [ 0.70879972]\n",
      "[ 0.94228  0.5695   0.20384  0.2944 ] [ 0.58617295]\n",
      "[ 0.47386    0.2251875  0.40304    0.70992  ] [ 0.66634783]\n",
      "[ 0.66382  0.6493   0.22448  0.23408] [ 0.61996733]\n",
      "[ 0.80344   0.643875  0.48432   0.36544 ] [ 0.59451342]\n",
      "[ 0.5095     0.9083875  0.41192    0.30304  ] [ 0.52373541]\n",
      "[ 0.47476    0.6166625  0.49024    0.43456  ] [ 0.68974886]\n",
      "[ 0.5341   0.75885  0.2848   0.46288] [ 0.58862397]\n",
      "[ 0.66664  0.7795   0.70064  0.75032] [ 0.51626608]\n",
      "[ 0.9991   0.93315  0.72304  0.50528] [ 0.51015707]\n",
      "[ 0.78316  0.17435  0.2836   0.42168] [ 0.62302529]\n",
      "[ 0.4294     0.5883125  0.36832    0.81136  ] [ 0.54365047]\n",
      "[ 0.44452    0.6850875  0.73152    0.43832  ] [ 0.50884755]\n",
      "[ 0.8575   0.49495  0.57304  0.52144] [ 0.54122457]\n",
      "[ 0.8101   0.5548   0.47376  0.34616] [ 0.60479878]\n",
      "[ 0.9379    0.193425  0.37032   0.49048 ] [ 0.50872669]\n",
      "[ 0.90268  0.61115  0.42896  0.30888] [ 0.57353523]\n",
      "[ 0.65176    0.5100875  0.3744     0.28744  ] [ 0.69023527]\n",
      "[ 0.51862    0.4260875  0.21608    0.314    ] [ 0.71937914]\n",
      "[ 0.93262    0.3788375  0.29752    0.34968  ] [ 0.6033188]\n",
      "[ 0.7801    0.227725  0.53664   0.4852  ] [ 0.51815375]\n",
      "[ 0.49558   0.330275  0.67576   0.41696 ] [ 0.55216217]\n",
      "[ 0.78424   0.530475  0.20808   0.21576 ] [ 0.63044852]\n",
      "[ 0.63952    0.5333625  0.53192    0.39952  ] [ 0.65765086]\n",
      "[ 0.622     0.329225  0.37264   0.56992 ] [ 0.70577072]\n",
      "[ 0.47938  0.7501   0.33904  0.36664] [ 0.61084376]\n",
      "[ 0.5065     0.4001875  0.65864    0.34408  ] [ 0.55243282]\n",
      "[ 0.6988   0.342    0.36544  0.21816] [ 0.66807828]\n",
      "[ 0.57616   0.470275  0.3324    0.71672 ] [ 0.63562966]\n",
      "[ 0.64654    0.4451625  0.2328     0.23936  ] [ 0.68733394]\n",
      "[ 0.52618   0.809775  0.49416   0.50032 ] [ 0.59179693]\n",
      "[ 0.69298  0.84145  0.45184  0.63064] [ 0.52984518]\n",
      "[ 0.81382    0.7571875  0.68712    0.71424  ] [ 0.53345634]\n",
      "[ 0.90034    0.4304625  0.38208    0.6392   ] [ 0.50693474]\n",
      "[ 0.98302  0.3392   0.35864  0.27904] [ 0.5707308]\n",
      "[ 0.54874    0.2439125  0.44232    0.41232  ] [ 0.70757964]\n",
      "[ 0.57982  0.86245  0.2832   0.47432] [ 0.51941207]\n",
      "[ 0.46738  0.29195  0.67736  0.39216] [ 0.54900733]\n",
      "[ 0.54322  0.61395  0.38536  0.38896] [ 0.69873844]\n",
      "[ 0.56458   0.242075  0.37672   0.76144 ] [ 0.60460528]\n",
      "[ 0.83338   0.363525  0.42272   0.2112  ] [ 0.59723099]\n",
      "[ 0.83086    0.3266875  0.29816    0.38192  ] [ 0.64469058]\n",
      "[ 0.88576  0.80155  0.46528  0.29488] [ 0.52799053]\n",
      "[ 0.42952   0.214775  0.43032   0.79576 ] [ 0.61830402]\n",
      "[ 0.41758    0.3263375  0.2036     0.27736  ] [ 0.69899309]\n",
      "[ 0.77968    0.5620625  0.2028     0.47528  ] [ 0.61869818]\n",
      "[ 0.60562  0.37315  0.31656  0.23528] [ 0.70428243]\n",
      "[ 0.5842   0.51315  0.26856  0.29184] [ 0.70331587]\n",
      "[ 0.7297   0.6136   0.53032  0.58224] [ 0.63446051]\n",
      "[ 0.64366   0.510525  0.47712   0.4056  ] [ 0.69548978]\n",
      "[ 0.93478    0.9076875  0.76208    0.5928   ] [ 0.52141735]\n",
      "[ 0.6028   0.21285  0.29672  0.52608] [ 0.70219249]\n",
      "[ 0.72658    0.6847375  0.3896     0.5056   ] [ 0.63134234]\n",
      "[ 0.40366  0.32065  0.41008  0.30976] [ 0.71924837]\n",
      "[ 0.78292    0.6997875  0.66632    0.55488  ] [ 0.57177606]\n",
      "[ 0.4912    0.623575  0.35184   0.28728 ] [ 0.66456007]\n",
      "[ 0.6118    0.676075  0.62104   0.40616 ] [ 0.57054156]\n",
      "[ 0.63994    0.2530125  0.31064    0.81128  ] [ 0.53364188]\n",
      "[ 0.577    0.9181   0.59408  0.63128] [ 0.52250625]\n",
      "[ 0.97888    0.9108375  0.3204     0.47192  ] [ 0.50400335]\n",
      "[ 0.8413     0.6646125  0.6056     0.43768  ] [ 0.54641441]\n",
      "[ 0.79732   0.398875  0.27808   0.45544 ] [ 0.65635211]\n",
      "[ 0.69814    0.7496625  0.52864    0.55008  ] [ 0.61902349]\n",
      "[ 0.6538   0.5947   0.5836   0.37152] [ 0.58764739]\n",
      "[ 0.82546  0.2048   0.21832  0.57664] [ 0.55213506]\n",
      "[ 0.56392   0.575275  0.27792   0.78592 ] [ 0.52218908]\n",
      "[ 0.43756  0.5317   0.66792  0.48776] [ 0.60486422]\n",
      "[ 0.93958   0.906725  0.38416   0.39648 ] [ 0.52392846]\n",
      "[ 0.5389     0.3730625  0.61712    0.79984  ] [ 0.50050655]\n",
      "[ 0.44986    0.2222125  0.31352    0.21304  ] [ 0.67549913]\n",
      "[ 0.748      0.6698625  0.6796     0.49168  ] [ 0.54629784]\n",
      "[ 0.50224   0.808025  0.6436    0.36592 ] [ 0.50193071]\n",
      "[ 0.74056    0.5797375  0.26376    0.71912  ] [ 0.50711821]\n",
      "[ 0.69478  0.4953   0.2384   0.72984] [ 0.54084097]\n",
      "[ 0.86488   0.349175  0.38408   0.2244  ] [ 0.60512688]\n",
      "[ 0.75838  0.3259   0.5988   0.49448] [ 0.51094887]\n",
      "[ 0.4168   0.4316   0.4664   0.56584] [ 0.74049537]\n",
      "[ 0.4708   0.36055  0.33224  0.4856 ] [ 0.772436]\n",
      "[ 0.5707     0.4449875  0.55688    0.67424  ] [ 0.63004338]\n",
      "[ 0.43642   0.714225  0.70592   0.68944 ] [ 0.52956708]\n",
      "[ 0.48652   0.293525  0.29472   0.70016 ] [ 0.69841736]\n",
      "[ 0.93766  0.6339   0.41392  0.45576] [ 0.57529894]\n",
      "[ 0.5299    0.621825  0.38864   0.59232 ] [ 0.67407305]\n",
      "[ 0.5608     0.8928125  0.30296    0.2964   ] [ 0.5324071]\n",
      "[ 0.49396    0.7206125  0.56696    0.55824  ] [ 0.62708593]\n",
      "[ 0.92356   0.591025  0.45816   0.52256 ] [ 0.56861215]\n",
      "[ 0.56446    0.4738625  0.6476     0.27584  ] [ 0.50900561]\n",
      "[ 0.50344    0.3035875  0.33744    0.85112  ] [ 0.59104452]\n",
      "[ 0.96472   0.368775  0.26408   0.3164  ] [ 0.59301664]\n",
      "[ 0.8155    0.500375  0.2796    0.55736 ] [ 0.60383965]\n",
      "[ 0.42034  0.43685  0.51752  0.29048] [ 0.66605811]\n",
      "[ 0.50476   0.630225  0.25784   0.62136 ] [ 0.60630672]\n",
      "[ 0.48178    0.8551875  0.43376    0.25184  ] [ 0.52991542]\n",
      "[ 0.4942    0.829725  0.51552   0.60288 ] [ 0.55602248]\n",
      "[ 0.7261     0.8098625  0.78456    0.67504  ] [ 0.52553835]\n",
      "[ 0.79216   0.764625  0.23392   0.3928  ] [ 0.56269632]\n",
      "[ 0.62176    0.1471375  0.47752    0.40536  ] [ 0.62359085]\n",
      "[ 0.73396    0.8583375  0.63176    0.39384  ] [ 0.51077603]\n",
      "[ 0.5476     0.6479875  0.51336    0.52448  ] [ 0.67991384]\n",
      "[ 0.41782  0.3952   0.7356   0.5496 ] [ 0.53530501]\n",
      "[ 0.48532  0.68115  0.32048  0.2388 ] [ 0.62038938]\n",
      "[ 0.67432   0.771275  0.3828    0.5124  ] [ 0.59357572]\n",
      "[ 0.50368    0.5844625  0.73648    0.7348   ] [ 0.51206864]\n",
      "[ 0.66334    0.1943875  0.4316     0.32072  ] [ 0.64666709]\n",
      "[ 0.66952   0.412525  0.61936   0.62584 ] [ 0.55246461]\n",
      "[ 0.4639     0.7556125  0.44128    0.32576  ] [ 0.59426544]\n",
      "[ 0.73144    0.6105375  0.51544    0.41328  ] [ 0.62776108]\n",
      "[ 0.71962    0.6339875  0.28512    0.2344   ] [ 0.6225839]\n",
      "[ 0.6799     0.8753125  0.35952    0.39856  ] [ 0.54607998]\n",
      "[ 0.56758   0.398525  0.6596    0.46976 ] [ 0.56735237]\n",
      "[ 0.72772    0.2386625  0.54112    0.2304   ] [ 0.54462111]\n",
      "[ 0.81814  0.5632   0.65992  0.66704] [ 0.51532927]\n",
      "[ 0.51616    0.4962625  0.25584    0.67208  ] [ 0.65576961]\n",
      "[ 0.68386    0.8259625  0.24824    0.358    ] [ 0.55186693]\n",
      "[ 0.53986    0.3132125  0.68848    0.54904  ] [ 0.52213826]\n",
      "[ 0.6796     0.5933875  0.56008    0.76496  ] [ 0.54193316]\n",
      "[ 0.52984    0.2580875  0.20976    0.48184  ] [ 0.73004043]\n",
      "[ 0.74308    0.9426875  0.26352    0.35544  ] [ 0.50904589]\n",
      "[ 0.60004   0.333075  0.49352   0.35896 ] [ 0.68010193]\n",
      "[ 0.55576   0.267975  0.29216   0.9196  ] [ 0.52624668]\n",
      "[ 0.49684    0.7097625  0.59944    0.45832  ] [ 0.60573199]\n",
      "[ 0.79246    0.9138125  0.4612     0.35568  ] [ 0.5272999]\n",
      "[ 0.922     0.630925  0.3228    0.28032 ] [ 0.58126833]\n",
      "[ 0.76654  0.27865  0.44496  0.5532 ] [ 0.579982]\n",
      "[ 0.77764    0.3812875  0.35552    0.32696  ] [ 0.67111069]\n",
      "[ 0.57286    0.9775125  0.38984    0.4084   ] [ 0.50410727]\n",
      "[ 0.43534    0.6399375  0.30344    0.38832  ] [ 0.67077867]\n",
      "[ 0.58168   0.483925  0.53424   0.784   ] [ 0.56113794]\n",
      "[ 0.63106   0.826925  0.56944   0.30288 ] [ 0.50174647]\n",
      "[ 0.43978  0.4064   0.25216  0.85096] [ 0.59555419]\n",
      "[ 0.92236   0.722625  0.47344   0.25128 ] [ 0.52032122]\n",
      "[ 0.50848    0.4512875  0.4728     0.89872  ] [ 0.5120863]\n",
      "[ 0.69892  0.5135   0.25808  0.58352] [ 0.63905968]\n",
      "[ 0.63046    0.6072125  0.46904    0.67152  ] [ 0.62960191]\n",
      "[ 0.56914    0.3910875  0.37552    0.40288  ] [ 0.75705499]\n",
      "[ 0.6859     0.3247625  0.52024    0.61328  ] [ 0.58227365]\n",
      "[ 0.81742    0.3658875  0.41064    0.60056  ] [ 0.56196231]\n",
      "[ 0.5236   0.70775  0.36168  0.3188 ] [ 0.62964876]\n",
      "[ 0.4945     0.3749875  0.30576    0.92744  ] [ 0.53815946]\n",
      "[ 0.58696   0.558125  0.5408    0.47712 ] [ 0.68649572]\n",
      "[ 0.43984   0.696025  0.46104   0.28304 ] [ 0.60290547]\n",
      "[ 0.60106    0.6378375  0.45208    0.2936   ] [ 0.6309439]\n",
      "[ 0.7288     0.8196625  0.57968    0.60048  ] [ 0.58464363]\n",
      "[ 0.70384    0.6159625  0.55512    0.66     ] [ 0.60899424]\n",
      "[ 0.475     0.717375  0.42848   0.51208 ] [ 0.64137365]\n",
      "[ 0.4096    0.745725  0.50008   0.31688 ] [ 0.57675855]\n",
      "[ 0.82258    0.6752875  0.45736    0.3372   ] [ 0.5829217]\n",
      "[ 0.55336    0.6803625  0.67848    0.5332   ] [ 0.58722983]\n",
      "[ 0.4441     0.4782375  0.46432    0.31416  ] [ 0.70192705]\n",
      "[ 0.8569     0.3578375  0.42616    0.412    ] [ 0.59977092]\n",
      "[ 0.79192   0.597325  0.22728   0.52168 ] [ 0.59423908]\n",
      "[ 0.74896    0.5533125  0.29552    0.23648  ] [ 0.64411037]\n",
      "[ 0.54946   0.767075  0.48856   0.73736 ] [ 0.50964294]\n",
      "[ 0.72682    0.5911125  0.21056    0.348    ] [ 0.64432827]\n",
      "[ 0.71128   0.309275  0.42672   0.3008  ] [ 0.66014391]\n",
      "[ 0.46366    0.4980125  0.5456     0.62904  ] [ 0.68295134]\n",
      "[ 0.61834  0.5394   0.64616  0.7908 ] [ 0.50912065]\n",
      "[ 0.84706   0.983375  0.47392   0.55856 ] [ 0.50720425]\n",
      "[ 0.84334    0.7403875  0.62376    0.56768  ] [ 0.57506536]\n",
      "[ 0.78976    0.3354375  0.23768    0.26992  ] [ 0.66027826]\n",
      "[ 0.48094   0.466425  0.39904   0.52952 ] [ 0.75984666]\n",
      "[ 0.5755     0.8919375  0.64976    0.70328  ] [ 0.50123754]\n",
      "[ 0.55084    0.2421625  0.26192    0.69928  ] [ 0.66764222]\n",
      "[ 0.68788   0.238575  0.20536   0.59248 ] [ 0.63547047]\n",
      "[ 0.71968  0.5324   0.37376  0.356  ] [ 0.68360106]\n",
      "[ 0.53374  0.40185  0.5604   0.60664] [ 0.66251063]\n",
      "[ 0.68014  0.1852   0.32192  0.42888] [ 0.67159323]\n",
      "[ 0.42076   0.369125  0.29288   0.88288 ] [ 0.59383244]\n",
      "[ 0.73888   0.712125  0.75136   0.5584  ] [ 0.53086274]\n",
      "[ 0.70234    0.5233875  0.57624    0.55328  ] [ 0.62459333]\n",
      "[ 0.84526   0.637575  0.65016   0.452   ] [ 0.51942331]\n",
      "[ 0.65644  0.66855  0.46752  0.20648] [ 0.55965376]\n",
      "[ 0.42694    0.1910625  0.51792    0.88408  ] [ 0.51966407]\n",
      "[ 0.5362     0.2752375  0.57896    0.23448  ] [ 0.57666752]\n",
      "[ 0.50836   0.501425  0.27408   0.848   ] [ 0.53584352]\n",
      "[ 0.55546    0.4966125  0.64752    0.27872  ] [ 0.5105755]\n",
      "[ 0.55936    0.4957375  0.36648    0.57064  ] [ 0.72925805]\n",
      "[ 0.99328  0.13935  0.39616  0.20528] [ 0.53140725]\n",
      "[ 0.6904     0.3613375  0.62328    0.438    ] [ 0.53454997]\n",
      "[ 0.5926     0.1534375  0.58048    0.30552  ] [ 0.55631729]\n",
      "[ 0.59662   0.505275  0.22376   0.30432 ] [ 0.69709653]\n",
      "[ 0.83866    0.7610375  0.59896    0.42064  ] [ 0.54247005]\n",
      "[ 0.54478   0.609575  0.42496   0.79272 ] [ 0.53917663]\n",
      "[ 0.5005    0.414625  0.21096   0.75096 ] [ 0.63152705]\n",
      "[ 0.88516    0.5543625  0.47288    0.33752  ] [ 0.57340374]\n",
      "[ 0.58444   0.743625  0.39808   0.47856 ] [ 0.62683156]\n",
      "[ 0.42778   0.535375  0.4636    0.89848 ] [ 0.51060422]\n",
      "[ 0.96004    0.5734375  0.36104    0.30296  ] [ 0.57693376]\n",
      "[ 0.96502  0.43545  0.21112  0.5636 ] [ 0.52130968]\n",
      "[ 0.54268   0.148975  0.44576   0.31832 ] [ 0.65404621]\n",
      "[ 0.69772    0.1599125  0.27144    0.41544  ] [ 0.65846224]\n",
      "[ 0.73948    0.8163375  0.77672    0.64304  ] [ 0.53472999]\n",
      "[ 0.59692    0.5540125  0.49912    0.49512  ] [ 0.70718934]\n",
      "[ 0.66712    0.5477125  0.26928    0.57024  ] [ 0.65107472]\n",
      "[ 0.4696    0.829025  0.60328   0.52512 ] [ 0.56029019]\n",
      "[ 0.823      0.5421125  0.548      0.41848  ] [ 0.57366726]\n",
      "[ 0.56566   0.586125  0.67904   0.80184 ] [ 0.50072697]\n",
      "[ 0.86446    0.4987125  0.51504    0.67512  ] [ 0.50762394]\n",
      "[ 0.82612  0.44     0.42752  0.61   ] [ 0.56764438]\n",
      "[ 0.7582     0.2734875  0.52648    0.20784  ] [ 0.54541221]\n",
      "[ 0.88852  0.39345  0.26208  0.45208] [ 0.60606908]\n",
      "[ 0.40804  0.3021   0.40872  0.8616 ] [ 0.60022902]\n",
      "[ 0.79912   0.572475  0.59936   0.38576 ] [ 0.53341291]\n",
      "[ 0.65602    0.2831125  0.27824    0.60344  ] [ 0.66527913]\n",
      "[ 0.41572    0.7090625  0.50792    0.28392  ] [ 0.57800119]\n",
      "[ 0.65536    0.6586625  0.7176     0.57808  ] [ 0.56151264]\n",
      "[ 0.71812   0.159475  0.33464   0.73424 ] [ 0.50121461]\n",
      "[ 0.86632    0.9302625  0.26592    0.38168  ] [ 0.50921158]\n",
      "[ 0.73582    0.5562875  0.58       0.61744  ] [ 0.60026266]\n",
      "[ 0.53608   0.491975  0.34232   0.57208 ] [ 0.73095615]\n",
      "[ 0.93994    0.5701125  0.54248    0.51912  ] [ 0.54032557]\n",
      "[ 0.99766    0.3235375  0.2412     0.3772   ] [ 0.56696025]\n",
      "[ 0.92056   0.553925  0.41968   0.46328 ] [ 0.58373491]\n",
      "[ 0.42682    0.1516875  0.54224    0.45616  ] [ 0.63500122]\n",
      "[ 0.94918  0.888    0.81432  0.62304] [ 0.50706234]\n",
      "[ 0.99664    0.7045125  0.23096    0.26688  ] [ 0.54925034]\n",
      "[ 0.61744    0.3483875  0.34608    0.70104  ] [ 0.6377248]\n",
      "[ 0.52408   0.313825  0.3264    0.83672 ] [ 0.59210228]\n",
      "[ 0.59494    0.4236375  0.64112    0.46168  ] [ 0.58162371]\n",
      "[ 0.5083    0.637225  0.40992   0.43112 ] [ 0.69379657]\n",
      "[ 0.89362  0.70845  0.4344   0.39432] [ 0.5750204]\n",
      "[ 0.91168    0.5683625  0.31784    0.454    ] [ 0.5930425]\n",
      "[ 0.59092   0.590325  0.27752   0.35512 ] [ 0.68831413]\n",
      "[ 0.80554    0.4029875  0.43448    0.38152  ] [ 0.63432098]\n",
      "[ 0.74572  0.68045  0.56608  0.28528] [ 0.51365638]\n",
      "[ 0.51214  0.4638   0.51928  0.62784] [ 0.69283281]\n",
      "[ 0.601    0.37245  0.57536  0.22432] [ 0.55957915]\n",
      "[ 0.54694    0.4675625  0.5272     0.48304  ] [ 0.71193932]\n",
      "[ 0.52378   0.663825  0.66496   0.57696 ] [ 0.60361603]\n",
      "[ 0.98122  0.17155  0.26232  0.3712 ] [ 0.5480811]\n",
      "[ 0.5587   0.2748   0.27624  0.92144] [ 0.52554821]\n",
      "[ 0.56878   0.584025  0.48448   0.77816 ] [ 0.56480216]\n",
      "[ 0.58708   0.804525  0.248     0.3312  ] [ 0.56652001]\n",
      "[ 0.7756   0.13445  0.30752  0.59128] [ 0.54759541]\n",
      "[ 0.59698    0.4544375  0.3148     0.57416  ] [ 0.71680021]\n",
      "[ 0.66826    0.8613125  0.59392    0.48488  ] [ 0.56475162]\n",
      "[ 0.6223     0.9173125  0.4552     0.3748   ] [ 0.53132265]\n",
      "[ 0.66856    0.4829625  0.63576    0.51952  ] [ 0.5808245]\n",
      "[ 0.73216    0.9274625  0.34752    0.39512  ] [ 0.52261347]\n",
      "[ 0.72064  0.6241   0.2748   0.54616] [ 0.61313332]\n",
      "[ 0.7333     0.7242875  0.21704    0.23776  ] [ 0.58225674]\n",
      "[ 0.59878   0.231225  0.26368   0.45664 ] [ 0.71798085]\n",
      "[ 0.8974     0.4686125  0.4388     0.3752   ] [ 0.58938023]\n",
      "[ 0.46924  0.3742   0.25104  0.39944] [ 0.75250091]\n",
      "[ 0.5737   0.2188   0.50136  0.53376] [ 0.64406287]\n",
      "[ 0.95986    0.9122375  0.35208    0.31056  ] [ 0.51736239]\n",
      "[ 0.44236  0.50685  0.38968  0.48144] [ 0.75318762]\n",
      "[ 0.5125     0.3660625  0.2712     0.98256  ] [ 0.50466888]\n"
     ]
    }
   ],
   "source": [
    "prob = gp.gp_cls.predict(gp.ctrl_samples)[0]\n",
    "for i,x in enumerate(gp.ctrl_samples):\n",
    "    if prob[i] > 0.5:\n",
    "        print x, prob[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(397, 4)\n",
      "[-2.353  1.092] [-2.009  1.188] [ 95.673] [ 0.344  0.096]\n",
      "[ 4.763  2.304] [ 0.307  2.817] [ 144.744] [-4.456  0.513]\n",
      "[-8.251  3.033] [-1.590  2.536] [ 23.435] [ 6.661 -0.497]\n",
      "[ 1.766  3.381] [-15.723  2.997] [ 532.114] [-17.489 -0.384]\n",
      "[-0.897  4.328] [-27.332  4.403] [ 115.358] [-26.435  0.075]\n",
      "[-22.208  3.274] [-2.963  3.392] [ 166.912] [ 19.245  0.119]\n",
      "[ 0.679  0.663] [-2.845  0.609] [ 60.904] [-3.523 -0.054]\n",
      "[ 2.540  0.237] [ 5.965  0.046] [ 62.248] [ 3.424 -0.191]\n",
      "[ 12.206  2.856] [ 7.389  2.433] [ 30.570] [-4.817 -0.424]\n",
      "[ 2.826  2.787] [-3.955  2.146] [ 23.244] [-6.780 -0.641]\n",
      "[-23.304  3.812] [-16.492  2.381] [ 91.165] [ 6.812 -1.431]\n",
      "[ 1.689  3.043] [-10.735  1.531] [ 153.607] [-12.425 -1.512]\n",
      "[-27.196  2.507] [-25.299  0.553] [ 23.411] [ 1.897 -1.954]\n",
      "[ 27.556  2.092] [ 25.724  1.352] [ 401.418] [-1.832 -0.740]\n",
      "[-0.890  3.939] [-4.913  3.820] [ 29.290] [-4.024 -0.119]\n",
      "[-0.287  1.542] [ 0.139  1.529] [ 19.510] [ 0.427 -0.013]\n",
      "[-1.075  0.192] [-4.080  0.147] [ 67.043] [-3.005 -0.045]\n",
      "[ 9.371  2.010] [ 7.573  2.218] [ 23.137] [-1.798  0.209]\n",
      "[ 1.773  0.201] [ 36.372 -0.153] [ 83.572] [ 34.599 -0.354]\n",
      "[-0.468  0.363] [-16.980 -0.749] [ 93.010] [-16.512 -1.112]\n",
      "[ 5.242  1.311] [-3.283  1.403] [ 49.202] [-8.525  0.091]\n",
      "[ 15.996  2.584] [ 11.970  2.317] [ 33.809] [-4.026 -0.267]\n",
      "[-23.805  3.470] [-26.666  3.028] [ 65.254] [-2.861 -0.442]\n",
      "[ 1.464  0.277] [ 3.254  0.370] [ 19.398] [ 1.790  0.093]\n",
      "[-0.062  0.453] [-12.658 -0.590] [ 67.531] [-12.596 -1.043]\n",
      "[ 13.872  2.723] [ 13.495  2.778] [ 18.512] [-0.377  0.055]\n",
      "[-0.831  0.392] [ 2.661  0.226] [ 28.647] [ 3.492 -0.166]\n",
      "[ 0.684  1.623] [ 19.399  1.028] [ 110.283] [ 18.715 -0.596]\n",
      "[ 0.852  0.772] [ 7.504  1.581] [ 26.380] [ 6.652  0.810]\n",
      "[-8.202  2.189] [-9.723  2.444] [ 36.488] [-1.522  0.255]\n",
      "[ 8.327  2.449] [ 8.936  2.636] [ 17.165] [ 0.609  0.187]\n",
      "[ 0.693  0.171] [-2.622  0.044] [ 37.848] [-3.315 -0.127]\n",
      "[ 6.090  1.648] [ 8.881  1.870] [ 45.244] [ 2.791  0.222]\n",
      "[ 6.407  1.721] [ 10.742  2.063] [ 38.698] [ 4.335  0.342]\n",
      "[-14.520  3.253] [-9.035  3.527] [ 34.760] [ 5.485  0.274]\n",
      "[-3.996  1.748] [-14.340  1.448] [ 46.788] [-10.344 -0.300]\n",
      "[-16.337  3.048] [-8.019  3.311] [ 43.050] [ 8.318  0.264]\n",
      "[ 9.905  1.946] [ 12.858  2.048] [ 57.006] [ 2.953  0.102]\n",
      "[ 7.285  2.901] [ 4.945  2.190] [ 55.981] [-2.340 -0.711]\n",
      "[-2.272  1.743] [-0.592  1.844] [ 24.416] [ 1.680  0.101]\n",
      "[-0.271  0.569] [ 1.257  0.416] [ 32.310] [ 1.528 -0.153]\n",
      "[ 1.085  0.469] [ 2.046  0.565] [ 18.943] [ 0.961  0.095]\n",
      "[ 0.079  3.334] [-3.681  3.088] [ 324.862] [-3.761 -0.246]\n",
      "[-3.042  0.784] [-8.855  0.892] [ 136.033] [-5.813  0.108]\n",
      "[-0.972  0.473] [-1.277  0.358] [ 19.211] [-0.305 -0.115]\n",
      "[-3.701  4.362] [-10.358  3.891] [ 383.560] [-6.657 -0.470]\n",
      "[-9.509  2.528] [-7.779  1.596] [ 46.158] [ 1.730 -0.932]\n",
      "[-3.739  1.924] [-4.716  1.805] [ 15.348] [-0.978 -0.118]\n",
      "[-18.097  3.512] [-18.425  3.459] [ 23.200] [-0.328 -0.052]\n",
      "[-32.339  2.786] [-34.638  0.931] [ 29.498] [-2.298 -1.855]\n",
      "[ 32.964  1.229] [ 28.420  1.723] [ 25.588] [-4.544  0.494]\n",
      "[-5.161  2.025] [-5.721  2.209] [ 25.727] [-0.560  0.184]\n",
      "[-29.750  2.902] [-15.590  1.472] [ 38.893] [ 14.161 -1.430]\n",
      "[ 0.266  0.582] [-3.596  0.448] [ 35.616] [-3.863 -0.134]\n",
      "[-5.223  2.964] [-6.729  2.928] [ 26.709] [-1.506 -0.036]\n",
      "[ 16.302  2.313] [ 13.193  2.934] [ 47.562] [-3.110  0.620]\n",
      "[-1.128  0.344] [ 3.649  0.309] [ 50.898] [ 4.777 -0.034]\n",
      "[ 2.287  1.988] [-0.676  1.662] [ 16.129] [-2.963 -0.326]\n",
      "[-0.744  0.797] [ 1.381  1.171] [ 26.200] [ 2.125  0.374]\n",
      "[-1.250  0.629] [ 28.911  1.605] [ 45.469] [ 30.160  0.976]\n",
      "[-35.637  2.777] [-30.713  0.961] [ 37.316] [ 4.925 -1.817]\n",
      "[-1.530  2.276] [ 3.071  2.389] [ 122.225] [ 4.601  0.112]\n",
      "[ 0.875  0.386] [ 2.315  0.182] [ 31.581] [ 1.440 -0.204]\n",
      "[ 5.255  1.697] [ 5.090  2.037] [ 19.848] [-0.166  0.340]\n",
      "[-5.160  1.122] [ 14.407  1.634] [ 168.591] [ 19.566  0.512]\n",
      "[ 2.739  1.268] [-0.109  0.946] [ 230.040] [-2.849 -0.322]\n",
      "[-0.672  0.331] [ 1.382  0.320] [ 26.896] [ 2.054 -0.011]\n",
      "[ 6.458  1.684] [ 11.342  2.203] [ 30.327] [ 4.884  0.519]\n",
      "[-1.288  0.517] [ 1.076  0.689] [ 33.833] [ 2.364  0.173]\n",
      "[-1.758  1.040] [-0.316  0.806] [ 53.508] [ 1.442 -0.234]\n",
      "[-31.630  2.576] [-12.407  1.369] [ 35.509] [ 19.223 -1.207]\n",
      "[-0.381  0.332] [ 7.343 -1.276] [ 110.401] [ 7.724 -1.608]\n",
      "[-1.016  0.453] [ 0.413  0.488] [ 45.723] [ 1.429  0.035]\n",
      "[-32.992  2.523] [-29.158  1.353] [ 16.061] [ 3.834 -1.170]\n",
      "[ 18.204  2.934] [ 15.491  3.358] [ 31.894] [-2.713  0.425]\n",
      "[ 0.636  0.534] [ 1.137  0.454] [ 27.572] [ 0.501 -0.081]\n",
      "[ 16.450  2.832] [ 8.332  3.316] [ 22.070] [-8.118  0.484]\n",
      "[-20.068  3.647] [-24.193  3.344] [ 25.235] [-4.125 -0.303]\n",
      "[ 0.229  0.608] [-5.126  0.065] [ 144.732] [-5.355 -0.543]\n",
      "[-28.683  3.218] [-29.895  2.010] [ 16.338] [-1.212 -1.207]\n",
      "[-16.580  3.233] [-41.102  3.159] [ 62.819] [-24.522 -0.074]\n",
      "[ 0.975  0.395] [ 7.083  0.488] [ 24.628] [ 6.108  0.092]\n",
      "[-0.666  0.350] [ 3.201  0.469] [ 38.338] [ 3.867  0.119]\n",
      "[-26.401  3.152] [-40.355  2.451] [ 29.801] [-13.954 -0.701]\n",
      "[-0.045  0.731] [-1.038  0.782] [ 77.237] [-0.992  0.051]\n",
      "[ 14.611  2.334] [ 16.580  2.339] [ 41.402] [ 1.969  0.005]\n",
      "[ 1.302  1.044] [-9.001  1.594] [ 46.043] [-10.303  0.550]\n",
      "[ 10.742  2.227] [ 9.316  2.539] [ 21.179] [-1.426  0.313]\n",
      "[-22.433  2.998] [-30.307  2.397] [ 47.159] [-7.874 -0.601]\n",
      "[ 3.956  3.234] [-48.833  0.163] [ 40.967] [-52.789 -3.071]\n",
      "[-14.671  3.595] [-17.724  3.196] [ 30.696] [-3.053 -0.399]\n",
      "[ 22.415  2.558] [ 13.890  2.496] [ 40.146] [-8.525 -0.061]\n",
      "[-31.379  2.538] [-36.518  0.736] [ 79.723] [-5.139 -1.802]\n",
      "[ 9.462  1.913] [ 8.586  1.631] [ 24.691] [-0.875 -0.282]\n",
      "[-0.587  0.992] [ 0.106  1.077] [ 17.124] [ 0.693  0.085]\n",
      "[ 4.187  1.289] [ 6.402  1.875] [ 26.272] [ 2.215  0.586]\n",
      "[-10.193  1.971] [-0.644  1.559] [ 122.228] [ 9.550 -0.413]\n",
      "[-0.409  0.764] [ 9.117  1.260] [ 30.693] [ 9.526  0.496]\n",
      "[ 12.285  2.758] [ 16.255  3.337] [ 45.018] [ 3.970  0.579]\n",
      "[ 26.458  1.980] [ 28.533  1.771] [ 152.553] [ 2.075 -0.209]\n",
      "[ 0.980  0.604] [ 2.276  0.235] [ 24.503] [ 1.296 -0.369]\n",
      "[ 0.214  1.000] [-11.402  0.688] [ 45.150] [-11.616 -0.312]\n",
      "[-1.184  0.439] [-1.550  0.217] [ 43.124] [-0.366 -0.222]\n",
      "[-24.114  3.168] [-29.551  1.518] [ 24.962] [-5.437 -1.650]\n",
      "[ 0.612  0.200] [ 1.512  0.235] [ 23.056] [ 0.900  0.035]\n",
      "[ 1.385  4.595] [ 1.404  3.706] [ 16.840] [ 0.019 -0.889]\n",
      "[-1.369  0.338] [-1.311 -0.138] [ 100.123] [ 0.058 -0.476]\n",
      "[ 16.075  2.729] [ 13.359  2.935] [ 19.812] [-2.716  0.207]\n",
      "[-0.515  0.436] [ 0.272  0.568] [ 69.338] [ 0.788  0.133]\n",
      "[ 2.006  0.263] [ 5.172  0.174] [ 28.317] [ 3.167 -0.089]\n",
      "[-0.092  1.052] [ 0.373  1.175] [ 15.608] [ 0.465  0.123]\n",
      "[ 25.804  1.571] [ 22.466  3.017] [ 116.277] [-3.338  1.446]\n",
      "[-9.865  3.538] [-10.428  2.957] [ 19.099] [-0.563 -0.581]\n",
      "[-17.182  3.372] [-13.488  3.886] [ 34.076] [ 3.693  0.514]\n",
      "[ 1.055  0.893] [ 5.869 -0.151] [ 45.496] [ 4.815 -1.043]\n",
      "[ 0.871  0.482] [-1.537  0.659] [ 17.898] [-2.408  0.177]\n",
      "[ 24.838  2.601] [ 20.712  2.646] [ 21.009] [-4.126  0.045]\n",
      "[ 0.660  1.569] [ 3.760  1.532] [ 21.933] [ 3.099 -0.037]\n",
      "[ 1.362  1.028] [-8.695  0.782] [ 43.575] [-10.057 -0.246]\n",
      "[ 16.409  2.603] [ 17.344  2.757] [ 36.974] [ 0.936  0.155]\n",
      "[-23.431  3.201] [-10.906  2.814] [ 40.046] [ 12.525 -0.387]\n",
      "[ 0.896  0.476] [ 1.844  0.486] [ 44.236] [ 0.949  0.009]\n",
      "[-1.291  1.003] [-3.310  0.660] [ 35.198] [-2.020 -0.343]\n",
      "[ 28.219  2.046] [ 35.342  3.163] [ 54.388] [ 7.122  1.117]\n",
      "[-5.822  2.709] [ 4.549  2.641] [ 31.700] [ 10.370 -0.068]\n",
      "[ 0.825  0.379] [ 1.914  0.181] [ 20.523] [ 1.089 -0.198]\n",
      "[ 2.363  3.207] [ 1.356  3.307] [ 19.331] [-1.007  0.101]\n",
      "[ 4.489  1.461] [ 22.543  1.442] [ 26.852] [ 18.054 -0.018]\n",
      "[ 0.733  0.490] [ 1.623  0.467] [ 18.954] [ 0.889 -0.023]\n",
      "[-14.506  3.383] [-15.486  1.958] [ 29.960] [-0.979 -1.425]\n",
      "[-23.580  3.173] [-19.411  1.914] [ 29.589] [ 4.169 -1.259]\n",
      "[-0.076  0.683] [-15.868  0.837] [ 127.976] [-15.792  0.154]\n",
      "[-0.870  0.688] [ 8.222  0.526] [ 34.157] [ 9.092 -0.162]\n",
      "[-2.404  1.257] [-3.430  0.839] [ 62.474] [-1.027 -0.419]\n",
      "[-1.449  3.326] [-18.441  2.386] [ 37.520] [-16.993 -0.940]\n",
      "[-0.597  0.713] [-1.291  0.799] [ 37.739] [-0.694  0.086]\n",
      "[-35.619  3.751] [-37.058  3.700] [ 75.436] [-1.438 -0.051]\n",
      "[ 1.216  0.299] [-1.134  0.347] [ 17.152] [-2.351  0.048]\n",
      "[-24.350  3.251] [-30.090  3.744] [ 55.303] [-5.739  0.493]\n",
      "[ 17.318  1.756] [ 7.176  1.236] [ 106.293] [-10.142 -0.521]\n",
      "[ 20.465  1.844] [ 24.877  2.349] [ 23.351] [ 4.412  0.505]\n",
      "[-25.898  2.914] [-36.244  2.293] [ 35.660] [-10.347 -0.621]\n",
      "[-27.019  3.454] [-12.170  2.412] [ 134.273] [ 14.849 -1.042]\n",
      "[ 0.918  0.439] [ 2.988  0.397] [ 51.076] [ 2.070 -0.042]\n",
      "[ 0.045  0.463] [ 1.001  0.148] [ 33.218] [ 0.956 -0.316]\n",
      "[-2.019  1.404] [ 0.398  1.703] [ 27.362] [ 2.417  0.299]\n",
      "[ 1.319  0.470] [ 1.838  0.832] [ 24.221] [ 0.519  0.362]\n",
      "[ 2.139  0.416] [ 20.131 -0.239] [ 30.163] [ 17.992 -0.656]\n",
      "[ 23.658  0.340] [ 26.232  1.288] [ 15.913] [ 2.575  0.948]\n",
      "[-0.525  1.230] [-4.769  1.423] [ 108.489] [-4.245  0.193]\n",
      "[-0.463  1.723] [ 1.174  1.856] [ 14.819] [ 1.637  0.132]\n",
      "[-2.502  0.363] [-11.748  1.087] [ 185.512] [-9.246  0.724]\n",
      "[-12.009  4.373] [ 9.677  3.890] [ 21.909] [ 21.686 -0.482]\n",
      "[-7.080  2.802] [-3.229  1.828] [ 25.964] [ 3.851 -0.974]\n",
      "[-0.258  0.420] [-24.802  0.191] [ 90.291] [-24.543 -0.229]\n",
      "[ 1.282  0.528] [ 5.464  0.495] [ 20.521] [ 4.182 -0.034]\n",
      "[ 23.292  2.591] [ 30.754  3.160] [ 73.369] [ 7.462  0.569]\n",
      "[ 1.904  0.384] [ 1.611  0.578] [ 20.535] [-0.293  0.193]\n",
      "[ 0.811  0.825] [-4.422  1.612] [ 25.882] [-5.233  0.787]\n",
      "[ 12.900  2.819] [ 18.698  3.682] [ 20.645] [ 5.798  0.864]\n",
      "[-0.084  0.301] [-4.635 -0.254] [ 52.707] [-4.551 -0.555]\n",
      "[-0.351  0.890] [ 0.693  0.907] [ 54.692] [ 1.044  0.017]\n",
      "[ 0.557  1.777] [ 4.425  0.057] [ 41.381] [ 3.868 -1.719]\n",
      "[-1.132  0.288] [ 0.654  0.151] [ 22.323] [ 1.786 -0.137]\n",
      "[ 2.052  3.470] [ 5.471  3.723] [ 90.510] [ 3.419  0.253]\n",
      "[ 1.719  1.198] [ 1.974  1.031] [ 13.337] [ 0.256 -0.166]\n",
      "[-6.620  4.487] [ 3.798  3.288] [ 29.983] [ 10.418 -1.200]\n",
      "[-2.162  0.899] [ 31.019  0.493] [ 147.485] [ 33.181 -0.406]\n",
      "[ 7.365  2.712] [ 7.207  2.684] [ 13.808] [-0.158 -0.028]\n",
      "[-1.834  1.052] [ 13.782  0.853] [ 44.028] [ 15.616 -0.199]\n",
      "[-25.191  3.116] [-22.011  2.200] [ 21.724] [ 3.180 -0.916]\n",
      "[ 0.948  0.213] [ 11.636 -0.011] [ 71.107] [ 10.688 -0.224]\n",
      "[ 1.146  0.309] [ 4.426  0.142] [ 23.778] [ 3.280 -0.167]\n",
      "[ 0.495  0.760] [-3.981  0.937] [ 42.465] [-4.476  0.176]\n",
      "[-27.171  3.078] [-31.060  2.436] [ 38.817] [-3.889 -0.642]\n",
      "[ 1.452  0.313] [ 0.535  0.337] [ 16.680] [-0.916  0.023]\n",
      "[-0.045  0.601] [-2.925  0.279] [ 159.326] [-2.881 -0.322]\n",
      "[-36.268  3.226] [-37.138  2.428] [ 45.725] [-0.870 -0.798]\n",
      "[ 0.120  0.410] [-3.636  0.892] [ 71.310] [-3.756  0.482]\n",
      "[ 26.232  1.395] [ 9.690  1.434] [ 29.726] [-16.542  0.039]\n",
      "[ 1.024  0.507] [-1.622  0.408] [ 67.926] [-2.646 -0.099]\n",
      "[ 1.103  1.066] [ 2.641  1.221] [ 28.060] [ 1.538  0.155]\n",
      "[ 12.171  1.053] [ 4.699  2.359] [ 32.648] [-7.472  1.306]\n",
      "[-27.882  2.967] [-33.426  2.185] [ 28.902] [-5.545 -0.782]\n",
      "[-1.930  0.565] [ 19.821 -0.271] [ 61.228] [ 21.751 -0.836]\n",
      "[-18.776  3.874] [-12.377  3.238] [ 25.605] [ 6.399 -0.636]\n",
      "[-1.084  0.476] [-5.474 -0.183] [ 32.892] [-4.390 -0.658]\n",
      "[ 0.857  0.431] [ 1.897  0.169] [ 93.296] [ 1.039 -0.262]\n",
      "[-1.117  0.343] [-3.395  0.094] [ 31.822] [-2.278 -0.249]\n",
      "[ 11.196  2.477] [ 13.000  2.891] [ 40.613] [ 1.804  0.414]\n",
      "[ 3.016  0.996] [ 20.743  0.767] [ 155.928] [ 17.727 -0.229]\n",
      "[-25.017  3.141] [-19.794  3.082] [ 47.174] [ 5.223 -0.059]\n",
      "[-14.776  4.047] [-22.843  3.630] [ 26.917] [-8.067 -0.417]\n",
      "[-1.785  1.054] [-0.458  1.316] [ 29.686] [ 1.326  0.262]\n",
      "[ 22.674  2.787] [ 23.935  2.921] [ 31.857] [ 1.261  0.134]\n",
      "[-2.765  1.391] [-3.662  1.714] [ 29.126] [-0.897  0.324]\n",
      "[ 0.933  0.695] [-1.792  1.191] [ 23.715] [-2.725  0.496]\n",
      "[-27.022  2.439] [-12.755  1.251] [ 32.065] [ 14.266 -1.188]\n",
      "[ 28.866  2.234] [ 19.642  2.138] [ 42.124] [-9.224 -0.096]\n",
      "[ 22.926  2.697] [ 26.070  3.252] [ 29.295] [ 3.144  0.555]\n",
      "[-0.118  0.574] [ 1.274  1.297] [ 38.337] [ 1.393  0.723]\n",
      "[ 4.307  1.176] [ 17.794  1.066] [ 126.401] [ 13.487 -0.111]\n",
      "[-12.263  2.581] [-15.165  2.284] [ 29.944] [-2.902 -0.297]\n",
      "[-27.523  3.027] [-26.840  1.337] [ 23.386] [ 0.683 -1.689]\n",
      "[-10.363  3.558] [ 4.423  3.827] [ 38.826] [ 14.786  0.269]\n",
      "[ 2.827  1.571] [ 6.155  1.922] [ 76.424] [ 3.328  0.351]\n",
      "[ 11.954  2.410] [ 11.243  2.331] [ 18.789] [-0.711 -0.079]\n",
      "[ 1.114  0.232] [ 13.034  0.048] [ 65.233] [ 11.920 -0.184]\n",
      "[ 1.359  0.389] [ 1.375  0.146] [ 28.528] [ 0.016 -0.242]\n",
      "[ 0.305  0.532] [ 4.723  0.894] [ 31.301] [ 4.418  0.362]\n",
      "[-15.052  2.878] [-13.584  2.455] [ 46.871] [ 1.468 -0.423]\n",
      "[-26.280  3.482] [-13.895  3.557] [ 21.585] [ 12.385  0.075]\n",
      "[ 26.279  1.833] [ 37.182  2.792] [ 24.802] [ 10.903  0.959]\n",
      "[-27.731  3.400] [-27.685  4.064] [ 101.165] [ 0.046  0.665]\n",
      "[-0.187  1.102] [-6.312  1.287] [ 124.355] [-6.125  0.186]\n",
      "[ 34.355 -2.742] [ 1.862  5.422] [ 219.787] [-32.493  8.163]\n",
      "[ 2.217  0.601] [ 0.545  0.524] [ 29.327] [-1.672 -0.078]\n",
      "[ 24.380  1.907] [ 26.263  2.484] [ 16.077] [ 1.883  0.577]\n",
      "[ 12.293  3.271] [ 0.495  2.958] [ 29.818] [-11.798 -0.313]\n",
      "[ 0.031  1.304] [ 8.403  0.496] [ 48.997] [ 8.372 -0.808]\n",
      "[ 15.418 -2.508] [ 1.575  5.602] [ 330.725] [-13.843  8.110]\n",
      "[ 0.621  1.021] [-0.952  0.885] [ 28.057] [-1.573 -0.137]\n",
      "[-5.722  3.988] [-20.775  3.068] [ 40.040] [-15.053 -0.921]\n",
      "[-7.133  1.989] [-1.535  2.467] [ 28.963] [ 5.598  0.478]\n",
      "[ 2.769  4.420] [ 3.746  3.862] [ 15.807] [ 0.977 -0.558]\n",
      "[-32.704  3.710] [-41.745  3.778] [ 29.453] [-9.041  0.068]\n",
      "[-0.016  3.449] [ 32.437  1.107] [ 252.594] [ 32.454 -2.343]\n",
      "[ 0.435  0.420] [ 5.916  0.733] [ 25.921] [ 5.482  0.313]\n",
      "[-14.100  3.959] [-14.666  3.892] [ 19.695] [-0.566 -0.067]\n",
      "[-9.153  2.115] [ 4.143  1.992] [ 41.890] [ 13.296 -0.123]\n",
      "[ 10.245  3.487] [-1.597  3.668] [ 32.169] [-11.842  0.181]\n",
      "[ 1.304  0.376] [-0.999  0.529] [ 16.424] [-2.303  0.153]\n",
      "[-2.138  0.244] [-14.725  1.037] [ 69.260] [-12.586  0.794]\n",
      "[ 1.310  0.516] [ 2.259  0.855] [ 29.551] [ 0.949  0.339]\n",
      "[-32.285  2.932] [-41.135  2.023] [ 44.907] [-8.850 -0.908]\n",
      "[ 1.288  1.135] [-0.350  1.171] [ 22.677] [-1.638  0.035]\n",
      "[-19.538  3.182] [-11.139  1.692] [ 28.542] [ 8.399 -1.489]\n",
      "[-27.366  2.932] [ 4.273  2.027] [ 15.183] [ 31.639 -0.905]\n",
      "[ 26.796  2.369] [ 13.419  2.421] [ 106.406] [-13.376  0.052]\n",
      "[ 4.494  1.452] [ 7.024  1.977] [ 31.445] [ 2.530  0.525]\n",
      "[-0.305  0.226] [-1.986  0.113] [ 25.162] [-1.681 -0.113]\n",
      "[-0.661  0.510] [-2.769  1.063] [ 40.871] [-2.108  0.553]\n",
      "[ 17.860  2.837] [ 12.073  3.325] [ 47.376] [-5.786  0.488]\n",
      "[-3.908  4.055] [-0.199  3.332] [ 54.211] [ 3.709 -0.722]\n",
      "[-30.952  2.921] [-27.996  1.698] [ 23.945] [ 2.956 -1.224]\n",
      "[-24.736  3.460] [-13.955  3.433] [ 74.535] [ 10.781 -0.027]\n",
      "[ 0.806  0.794] [-6.500  0.643] [ 33.407] [-7.306 -0.151]\n",
      "[-0.455  0.562] [-2.930  0.764] [ 48.082] [-2.475  0.202]\n",
      "[ 0.750  0.808] [ 3.213  1.172] [ 20.746] [ 2.464  0.364]\n",
      "[ 6.238  3.390] [ 2.483  3.116] [ 17.406] [-3.754 -0.274]\n",
      "[-0.633  0.749] [-0.189  0.684] [ 92.387] [ 0.443 -0.065]\n",
      "[ 0.670  0.628] [ 0.558  0.385] [ 26.488] [-0.113 -0.244]\n",
      "[ 1.332  1.816] [ 0.232  2.197] [ 22.856] [-1.100  0.381]\n",
      "[ 7.786  1.814] [ 8.292  1.691] [ 47.744] [ 0.505 -0.123]\n",
      "[ 0.369  0.578] [ 6.503  0.651] [ 26.024] [ 6.134  0.074]\n",
      "[-25.803  3.133] [-52.284  2.462] [ 39.306] [-26.481 -0.671]\n",
      "[ 2.605  1.114] [ 14.097  1.557] [ 62.339] [ 11.492  0.443]\n",
      "[-33.986  2.720] [-80.228  0.750] [ 75.669] [-46.242 -1.969]\n",
      "[-28.245  2.533] [-22.468  0.890] [ 42.247] [ 5.776 -1.643]\n",
      "[ 0.167  0.485] [ 6.819  1.044] [ 47.385] [ 6.653  0.559]\n",
      "[ 0.916  0.145] [ 8.731  0.012] [ 51.083] [ 7.815 -0.133]\n",
      "[-29.446  3.343] [-30.214  2.416] [ 31.378] [-0.768 -0.927]\n",
      "[ 29.985  0.293] [ 13.277  0.241] [ 54.726] [-16.708 -0.053]\n",
      "[-0.582  0.436] [ 3.403  0.251] [ 26.836] [ 3.985 -0.185]\n",
      "[ 3.616  1.345] [ 10.136  1.619] [ 28.655] [ 6.520  0.273]\n",
      "[ 29.166  1.152] [ 34.864  1.887] [ 33.192] [ 5.698  0.735]\n",
      "[ 0.548  0.719] [-16.922  0.386] [ 76.816] [-17.470 -0.334]\n",
      "[-30.787  2.962] [-12.669  2.973] [ 53.959] [ 18.119  0.011]\n",
      "[ 45.271 -1.799] [ 24.781  1.674] [ 162.129] [-20.490  3.472]\n",
      "[ 10.566  2.026] [ 9.715  1.827] [ 33.093] [-0.851 -0.198]\n",
      "[-0.633  0.841] [ 0.162  0.882] [ 25.688] [ 0.794  0.041]\n",
      "[ 0.931  0.407] [-0.672  0.631] [ 44.055] [-1.603  0.223]\n",
      "[ 1.610  0.376] [ 3.901  0.231] [ 27.015] [ 2.292 -0.145]\n",
      "[-0.102  1.513] [ 0.110  1.535] [ 22.435] [ 0.212  0.022]\n",
      "[ 0.192  0.260] [ 6.269  0.422] [ 40.708] [ 6.077  0.162]\n",
      "[-26.294  3.124] [ 4.313  2.096] [ 19.996] [ 30.606 -1.028]\n",
      "[ 1.839  4.205] [-1.442  3.900] [ 75.658] [-3.282 -0.305]\n",
      "[-29.816  2.743] [-5.023  1.940] [ 38.739] [ 24.793 -0.803]\n",
      "[ 13.960  2.433] [ 10.293  2.376] [ 56.103] [-3.666 -0.057]\n",
      "[ 2.811  3.264] [ 6.778  4.257] [ 83.447] [ 3.968  0.993]\n",
      "[-19.076  3.148] [-8.357  1.829] [ 26.191] [ 10.719 -1.318]\n",
      "[-21.219  3.576] [-23.247  2.805] [ 18.231] [-2.028 -0.771]\n",
      "[-12.681  2.820] [-25.172  2.616] [ 56.238] [-12.491 -0.205]\n",
      "[ 0.211  0.321] [ 0.611  0.322] [ 39.380] [ 0.400  0.000]\n",
      "[-0.372  0.837] [ 0.955  1.301] [ 30.949] [ 1.327  0.464]\n",
      "[ 10.661  2.050] [ 9.047  2.278] [ 40.074] [-1.614  0.228]\n",
      "[-9.052  4.094] [ 1.868  4.841] [ 23.222] [ 10.919  0.746]\n",
      "[ 28.420  1.691] [ 45.401  2.366] [ 19.980] [ 16.981  0.674]\n",
      "[-1.179  4.177] [-6.964  4.730] [ 25.051] [-5.785  0.553]\n",
      "[ 0.786  0.799] [ 1.381  1.076] [ 26.420] [ 0.595  0.277]\n",
      "[-13.320  4.065] [ 2.831  4.792] [ 24.763] [ 16.151  0.727]\n",
      "[ 0.445  0.560] [ 2.626  0.413] [ 23.796] [ 2.181 -0.147]\n",
      "[ 1.364  0.559] [-10.565  0.325] [ 74.249] [-11.929 -0.234]\n",
      "[-32.581  3.241] [-29.680  1.874] [ 24.054] [ 2.901 -1.368]\n",
      "[ 0.024  0.372] [-9.563 -0.309] [ 65.028] [-9.587 -0.681]\n",
      "[ 27.382  1.998] [ 26.025  1.901] [ 152.006] [-1.358 -0.097]\n",
      "[-5.507  3.400] [-13.667  2.967] [ 27.080] [-8.160 -0.433]\n",
      "[-26.015  3.264] [-1.190  2.248] [ 28.949] [ 24.825 -1.016]\n",
      "[-1.103  0.861] [ 10.875  1.213] [ 54.291] [ 11.978  0.353]\n",
      "[-6.048  2.466] [-2.757  2.513] [ 69.053] [ 3.290  0.047]\n",
      "[ 1.162  0.421] [ 5.355  0.283] [ 27.084] [ 4.193 -0.138]\n",
      "[ 4.353  0.621] [ 13.231  0.782] [ 326.334] [ 8.879  0.161]\n",
      "[ 9.337  2.131] [ 5.420  1.822] [ 43.309] [-3.917 -0.309]\n",
      "[-1.958  1.066] [-2.653  1.373] [ 49.458] [-0.695  0.306]\n",
      "[-26.509  3.249] [-37.779  2.619] [ 17.274] [-11.270 -0.630]\n",
      "[ 24.539  2.290] [ 19.047  2.796] [ 28.405] [-5.491  0.506]\n",
      "[ 17.338  0.461] [ 12.088  1.622] [ 15.801] [-5.249  1.162]\n",
      "[ 30.735  0.631] [ 48.898  1.609] [ 37.904] [ 18.163  0.979]\n",
      "[ 0.072  0.664] [ 7.110  1.067] [ 48.916] [ 7.038  0.403]\n",
      "[-0.360  0.772] [-3.071  0.970] [ 39.323] [-2.712  0.198]\n",
      "[ 0.469  0.627] [-3.133  0.283] [ 25.402] [-3.602 -0.344]\n",
      "[-20.487  2.987] [-14.389  0.735] [ 33.268] [ 6.097 -2.252]\n",
      "[-4.711  1.367] [ 9.498  0.980] [ 389.711] [ 14.209 -0.387]\n",
      "[-0.201  0.201] [-4.438  0.300] [ 112.788] [-4.236  0.099]\n",
      "[-0.831  3.503] [-7.663  3.272] [ 21.035] [-6.832 -0.231]\n",
      "[ 13.709  2.855] [ 13.155  2.943] [ 16.867] [-0.554  0.088]\n",
      "[-1.795  2.403] [-1.038  2.531] [ 25.894] [ 0.757  0.128]\n",
      "[ 4.191  2.799] [ 3.599  2.670] [ 14.339] [-0.592 -0.129]\n",
      "[ 5.567  1.605] [ 5.970  1.579] [ 98.991] [ 0.403 -0.026]\n",
      "[ 0.439  0.956] [ 0.501  1.102] [ 16.792] [ 0.062  0.146]\n",
      "[ 5.654  2.110] [ 5.231  2.155] [ 24.200] [-0.423  0.045]\n",
      "[-22.869  3.535] [-9.626  3.244] [ 37.049] [ 13.243 -0.291]\n",
      "[-3.131  0.672] [-4.593  0.481] [ 230.866] [-1.461 -0.192]\n",
      "[-0.231  0.604] [ 4.044  1.332] [ 28.983] [ 4.275  0.728]\n",
      "[ 0.348  0.322] [-2.429  0.144] [ 28.748] [-2.777 -0.178]\n",
      "[ 2.674  4.007] [ 0.091  3.140] [ 120.313] [-2.583 -0.866]\n",
      "[-21.755  2.880] [-15.487  0.070] [ 53.376] [ 6.268 -2.810]\n",
      "[-1.306  0.440] [-4.289  0.705] [ 25.408] [-2.983  0.265]\n",
      "[ 1.349  0.268] [ 0.537  0.620] [ 32.882] [-0.812  0.352]\n",
      "[-19.420  3.165] [-31.269  1.662] [ 88.932] [-11.849 -1.503]\n",
      "[-1.126  0.805] [ 0.841  0.937] [ 18.919] [ 1.967  0.132]\n",
      "[ 1.038  0.353] [-0.375  0.098] [ 65.617] [-1.413 -0.255]\n",
      "[ 22.333 -2.625] [ 32.742  0.948] [ 78.911] [ 10.408  3.573]\n",
      "[ 11.833  2.816] [-1.016  3.190] [ 29.630] [-12.849  0.375]\n",
      "[-0.491  0.650] [ 10.430  0.995] [ 75.962] [ 10.921  0.345]\n",
      "[ 30.091  0.627] [ 39.299  1.320] [ 17.947] [ 9.208  0.692]\n",
      "[-32.036  3.802] [-35.871  1.955] [ 146.605] [-3.835 -1.847]\n",
      "[-1.544  3.658] [ 0.383  2.353] [ 49.075] [ 1.927 -1.305]\n",
      "[ 1.554  0.169] [ 3.129  0.297] [ 56.901] [ 1.575  0.128]\n",
      "[-1.181  0.534] [ 1.864  1.534] [ 90.694] [ 3.045  1.000]\n",
      "[-4.721  2.319] [-10.960  1.932] [ 45.728] [-6.239 -0.388]\n",
      "[-1.164  1.084] [ 2.996  1.371] [ 20.118] [ 4.161  0.287]\n",
      "[-23.465  2.700] [-21.753  0.540] [ 23.735] [ 1.712 -2.160]\n",
      "[ 2.830  2.088] [ 3.646  1.982] [ 17.182] [ 0.816 -0.106]\n",
      "[-8.173  4.501] [-2.849  4.518] [ 20.015] [ 5.325  0.017]\n",
      "[-14.787  3.344] [-14.336  2.418] [ 25.735] [ 0.451 -0.926]\n",
      "[-11.159  2.672] [-6.414  3.386] [ 63.228] [ 4.744  0.714]\n",
      "[-1.206  2.047] [ 12.103  3.872] [ 45.425] [ 13.309  1.825]\n",
      "[ 1.380  0.387] [-0.507  0.454] [ 16.723] [-1.887  0.067]\n",
      "[-0.647  0.448] [-1.123  0.154] [ 52.852] [-0.476 -0.294]\n",
      "[-15.261  2.983] [-13.780  2.851] [ 40.565] [ 1.481 -0.132]\n",
      "[ 0.722  0.494] [ 2.544  0.821] [ 105.733] [ 1.822  0.327]\n",
      "[-6.469  3.229] [ 5.760  2.875] [ 58.110] [ 12.229 -0.354]\n",
      "[-28.950  3.569] [ 6.158  1.994] [ 301.630] [ 35.108 -1.575]\n",
      "[-1.300  0.541] [-6.493  0.425] [ 32.646] [-5.193 -0.116]\n",
      "[ 0.417  2.907] [ 0.651  0.248] [ 236.371] [ 0.234 -2.659]\n",
      "[-1.979  1.508] [ 2.008  1.950] [ 51.299] [ 3.987  0.443]\n",
      "[ 1.867  0.574] [ 9.160  1.078] [ 28.459] [ 7.293  0.504]\n",
      "[-22.006  3.736] [-26.072  3.229] [ 16.734] [-4.066 -0.507]\n",
      "[-0.268  0.522] [ 9.257  2.154] [ 87.711] [ 9.525  1.631]\n",
      "[-0.983  0.346] [-2.137  0.169] [ 84.822] [-1.154 -0.177]\n",
      "[-1.257  1.069] [-2.796  0.941] [ 20.564] [-1.539 -0.128]\n",
      "[-1.084  0.419] [-12.123  1.338] [ 187.554] [-11.039  0.919]\n",
      "[ 1.056  0.407] [ 2.598  0.415] [ 16.354] [ 1.543  0.008]\n",
      "[-29.660  2.884] [-12.266  2.922] [ 57.825] [ 17.394  0.038]\n",
      "[-26.522  3.733] [ 6.133  2.044] [ 242.996] [ 32.655 -1.689]\n",
      "[ 0.321  0.511] [-0.513  0.195] [ 21.717] [-0.833 -0.316]\n",
      "[-26.717  3.208] [-41.444  2.934] [ 36.467] [-14.727 -0.274]\n",
      "[-11.877  2.934] [-7.989  3.183] [ 23.738] [ 3.888  0.249]\n",
      "[-29.233  3.525] [-14.404  2.486] [ 72.185] [ 14.829 -1.038]\n",
      "[-24.596  2.609] [-21.394  1.056] [ 29.166] [ 3.202 -1.554]\n",
      "[ 1.499  0.842] [ 4.970  0.944] [ 16.949] [ 3.471  0.103]\n",
      "[ 0.016  1.627] [ 1.265  1.633] [ 16.377] [ 1.249  0.006]\n",
      "[ 1.110  0.482] [ 4.223  0.562] [ 29.532] [ 3.112  0.080]\n",
      "[-1.059  1.057] [ 0.732  1.312] [ 27.106] [ 1.790  0.256]\n",
      "[-17.451  3.483] [-15.971  3.053] [ 20.793] [ 1.480 -0.430]\n",
      "[-10.208  2.637] [ 0.493  2.264] [ 35.278] [ 10.701 -0.373]\n",
      "[ 1.198  1.393] [ 8.890  2.712] [ 96.676] [ 7.692  1.318]\n",
      "[ 20.772  2.329] [ 16.671  2.684] [ 33.900] [-4.101  0.356]\n",
      "[ 0.887  3.439] [-5.927  3.150] [ 98.552] [-6.814 -0.289]\n",
      "[-34.926  3.272] [-35.995  1.853] [ 60.710] [-1.070 -1.419]\n",
      "[-32.104  2.478] [-27.577  0.764] [ 23.074] [ 4.527 -1.714]\n",
      "[-0.808  3.950] [ 11.211  4.109] [ 23.940] [ 12.019  0.160]\n",
      "[ 0.781  1.158] [-0.126  1.029] [ 19.042] [-0.907 -0.129]\n",
      "[-3.995  1.528] [-5.562  1.740] [ 15.807] [-1.567  0.212]\n",
      "[-0.217  0.625] [ 4.034  1.305] [ 26.622] [ 4.251  0.680]\n",
      "[-28.657  2.694] [ 7.335  1.303] [ 25.086] [ 35.993 -1.391]\n",
      "[ 0.828  1.157] [-2.131  1.078] [ 28.425] [-2.959 -0.079]\n",
      "[-20.157  2.272] [-17.592  1.352] [ 22.046] [ 2.565 -0.920]\n",
      "[ 21.621  0.457] [ 31.980  2.266] [ 64.419] [ 10.358  1.809]\n",
      "[ 0.033  3.225] [-0.543  2.698] [ 22.809] [-0.576 -0.527]\n",
      "[ 0.413  0.651] [ 1.315  0.519] [ 24.388] [ 0.902 -0.132]\n",
      "[-1.075  0.560] [-4.930  0.409] [ 30.865] [-3.855 -0.151]\n",
      "[ 1.004  0.323] [ 1.450  0.054] [ 49.777] [ 0.446 -0.269]\n",
      "[ 1.061  1.780] [-0.135  1.369] [ 16.477] [-1.196 -0.412]\n",
      "[-1.024  0.634] [-3.633  0.603] [ 39.347] [-2.610 -0.031]\n",
      "[-1.306  0.590] [-4.891  0.512] [ 19.312] [-3.585 -0.078]\n",
      "[ 22.836  2.619] [ 28.821  3.033] [ 51.144] [ 5.986  0.414]\n",
      "[-0.396  0.774] [-1.576  1.004] [ 97.975] [-1.180  0.231]\n",
      "[ 0.685  3.545] [-0.988  2.306] [ 37.375] [-1.673 -1.239]\n",
      "[-0.389  1.449] [-3.147  2.202] [ 52.205] [-2.758  0.754]\n",
      "[ 25.960  2.029] [ 34.730  2.747] [ 24.449] [ 8.771  0.718]\n",
      "[-0.694  0.324] [-8.093  0.930] [ 159.007] [-7.399  0.607]\n",
      "[-17.538  4.103] [-9.091  3.599] [ 24.208] [ 8.447 -0.504]\n",
      "[ 1.038  0.722] [-2.660  0.744] [ 53.738] [-3.698  0.022]\n",
      "[ 0.167  0.825] [ 7.240  1.076] [ 22.159] [ 7.072  0.251]\n",
      "[ 14.222  3.293] [ 10.865  3.307] [ 28.506] [-3.358  0.014]\n",
      "[ 16.094  2.846] [ 15.294  2.943] [ 15.162] [-0.800  0.097]\n",
      "[-0.734  0.205] [-4.525  0.167] [ 43.994] [-3.790 -0.037]\n",
      "[ 0.705  0.729] [-0.289  0.421] [ 31.193] [-0.994 -0.307]\n",
      "[-35.654  3.720] [-8.911  3.193] [ 79.739] [ 26.743 -0.527]\n",
      "[-28.485  3.087] [-19.149  1.891] [ 33.183] [ 9.336 -1.196]\n",
      "[ 25.669  2.538] [ 20.117  2.644] [ 26.220] [-5.552  0.107]\n",
      "[ 2.089  3.020] [-7.178  2.192] [ 203.192] [-9.267 -0.829]\n",
      "[ 8.231  2.368] [ 8.442  2.714] [ 38.793] [ 0.211  0.346]\n",
      "[-0.707  0.813] [-0.447  2.019] [ 28.206] [ 0.259  1.206]\n",
      "[-6.300  1.875] [-10.943  2.285] [ 29.940] [-4.643  0.411]\n",
      "[ 3.881  4.122] [ 1.800  3.150] [ 104.622] [-2.081 -0.973]\n",
      "[ 29.479  1.200] [ 23.137  1.450] [ 32.701] [-6.342  0.251]\n",
      "[ 0.049  0.528] [ 2.397  0.607] [ 19.533] [ 2.348  0.079]\n",
      "[-9.222  3.032] [ 4.229  2.454] [ 243.674] [ 13.451 -0.578]\n",
      "[-2.078  4.079] [ 3.788  4.179] [ 19.336] [ 5.866  0.100]\n",
      "[-23.833  2.493] [-27.426  0.760] [ 51.190] [-3.592 -1.733]\n",
      "[-3.248  4.857] [-2.013  4.648] [ 20.164] [ 1.235 -0.209]\n",
      "[-24.831  3.547] [-26.928  3.331] [ 15.685] [-2.097 -0.216]\n",
      "[ 19.434  2.258] [ 13.537  2.371] [ 90.921] [-5.896  0.113]\n",
      "[ 0.988  0.272] [ 0.562  0.212] [ 25.309] [-0.426 -0.060]\n",
      "[ 0.653  0.408] [ 0.642  0.132] [ 17.813] [-0.011 -0.276]\n",
      "[-29.840  3.122] [-22.403  2.480] [ 37.473] [ 7.437 -0.641]\n",
      "[-15.158  3.188] [-18.060  2.631] [ 21.568] [-2.902 -0.557]\n",
      "[-25.359  3.547] [-36.543  2.797] [ 38.293] [-11.183 -0.750]\n",
      "[-0.217  0.725] [ 6.762  0.735] [ 40.856] [ 6.979  0.011]\n",
      "[ 10.421  2.168] [ 11.735  2.379] [ 17.043] [ 1.314  0.211]\n",
      "[ 3.977  1.241] [ 2.781  1.488] [ 20.911] [-1.197  0.247]\n",
      "[-10.948  2.178] [ 14.601  2.088] [ 82.965] [ 25.549 -0.090]\n",
      "[-0.821  0.576] [-7.121  0.282] [ 38.433] [-6.300 -0.295]\n",
      "[-22.524  3.199] [-48.559  2.218] [ 27.705] [-26.036 -0.981]\n",
      "[-22.576  3.317] [-13.270  3.711] [ 88.926] [ 9.306  0.393]\n",
      "[-0.797  0.182] [-10.155 -0.460] [ 186.461] [-9.358 -0.642]\n",
      "[ 0.328  0.367] [-5.386  0.054] [ 61.170] [-5.714 -0.313]\n",
      "[-1.264  0.828] [-4.408  1.155] [ 147.076] [-3.144  0.326]\n",
      "[-19.110  3.420] [-32.528  1.996] [ 187.495] [-13.418 -1.425]\n",
      "[-0.218  0.329] [-4.764 -0.055] [ 56.542] [-4.546 -0.384]\n",
      "[-2.123  0.860] [-3.765  1.111] [ 19.508] [-1.642  0.251]\n",
      "[-1.658  1.027] [-3.616  1.493] [ 19.981] [-1.958  0.467]\n",
      "[ 0.428  0.410] [ 3.816  0.495] [ 27.314] [ 3.387  0.085]\n",
      "[ 0.085  0.688] [-0.195  0.827] [ 34.537] [-0.280  0.140]\n",
      "[-17.901  3.419] [-18.724  2.999] [ 23.544] [-0.823 -0.420]\n",
      "[-2.635  1.327] [-10.533  1.029] [ 147.442] [-7.898 -0.297]\n",
      "[-0.556  1.189] [-9.027  1.391] [ 67.391] [-8.471  0.202]\n",
      "[-0.574  0.768] [ 11.754  1.292] [ 62.889] [ 12.328  0.523]\n",
      "[ 1.395  0.244] [ 0.981  0.570] [ 87.912] [-0.414  0.326]\n",
      "[ 17.209  2.481] [ 17.042  3.491] [ 13.944] [-0.167  1.010]\n",
      "[ 3.532  3.204] [-2.847  1.561] [ 30.810] [-6.378 -1.644]\n",
      "[-1.591  1.164] [-5.922  1.150] [ 40.350] [-4.331 -0.014]\n",
      "[ 24.154  1.530] [-1.949  2.396] [ 47.353] [-26.103  0.866]\n",
      "[ 14.357  3.033] [ 13.355  3.311] [ 19.137] [-1.003  0.278]\n",
      "[-0.255  0.774] [-11.194  0.511] [ 110.822] [-10.939 -0.263]\n",
      "[-1.483  3.828] [-6.445  3.573] [ 19.436] [-4.962 -0.256]\n",
      "[ 17.119  2.924] [ 15.542  3.071] [ 21.883] [-1.577  0.147]\n",
      "[ 0.430  1.387] [-1.549  1.644] [ 68.019] [-1.980  0.257]\n",
      "[-0.144  2.096] [-6.981  1.909] [ 73.421] [-6.837 -0.186]\n",
      "[-0.949  0.318] [-5.555 -0.598] [ 86.825] [-4.606 -0.916]\n",
      "[ 22.090  1.248] [ 31.052  1.480] [ 89.572] [ 8.963  0.232]\n",
      "[-0.927  1.140] [-0.896  0.383] [ 35.647] [ 0.031 -0.757]\n",
      "[-11.957  2.097] [ 10.200  1.715] [ 181.690] [ 22.156 -0.382]\n",
      "[ 28.013 -2.589] [-4.978  1.072] [ 950.612] [-32.991  3.661]\n",
      "[-19.741  3.649] [-13.312  2.930] [ 21.677] [ 6.429 -0.719]\n",
      "[ 6.232  3.869] [ 4.273  3.344] [ 43.683] [-1.959 -0.525]\n",
      "[ 1.098  1.441] [-0.829  1.277] [ 15.061] [-1.927 -0.164]\n",
      "[ 20.599  2.815] [ 23.393  3.304] [ 18.886] [ 2.795  0.489]\n",
      "[-0.407  0.782] [-0.825  0.635] [ 16.416] [-0.418 -0.147]\n",
      "[-1.759  1.317] [-2.703  2.035] [ 33.269] [-0.944  0.719]\n",
      "[-37.344  2.857] [-38.660  2.216] [ 159.555] [-1.316 -0.641]\n",
      "[-6.156  1.649] [ 7.215  0.914] [ 233.040] [ 13.371 -0.735]\n",
      "[-3.563  4.371] [-8.261  4.365] [ 23.890] [-4.698 -0.006]\n",
      "[-8.555  2.330] [-8.366  1.521] [ 57.002] [ 0.188 -0.809]\n",
      "[-29.945  3.623] [-33.970  2.691] [ 38.463] [-4.025 -0.932]\n",
      "[ 5.526  1.482] [ 10.199  1.882] [ 32.539] [ 4.673  0.400]\n",
      "[ 12.543  2.936] [ 14.377  3.412] [ 14.747] [ 1.834  0.476]\n",
      "[-29.634  3.619] [-41.306  3.534] [ 297.182] [-11.672 -0.085]\n",
      "[-6.889  1.743] [-4.055  2.448] [ 40.894] [ 2.834  0.705]\n",
      "[ 2.763  3.138] [-3.863  2.139] [ 34.678] [-6.626 -0.999]\n",
      "[-3.043  0.329] [ 59.176 -0.849] [ 518.568] [ 62.219 -1.178]\n",
      "[ 17.785  1.476] [ 18.321  2.633] [ 16.233] [ 0.536  1.157]\n",
      "[-0.507  0.675] [-0.093  0.503] [ 76.765] [ 0.413 -0.173]\n",
      "[ 1.169  0.546] [ 4.075  0.531] [ 19.278] [ 2.906 -0.015]\n",
      "[-24.060  3.595] [-28.025  2.902] [ 25.415] [-3.965 -0.694]\n",
      "[ 0.069  1.013] [ 0.242  1.121] [ 19.076] [ 0.173  0.107]\n",
      "[-0.768  2.423] [-20.723  1.777] [ 57.936] [-19.955 -0.646]\n",
      "[ 0.227  0.592] [-17.453 -0.291] [ 64.928] [-17.680 -0.884]\n",
      "[-0.914  0.636] [-2.007  0.409] [ 16.325] [-1.092 -0.228]\n",
      "[ 1.150  0.284] [ 15.080  0.694] [ 30.100] [ 13.930  0.410]\n",
      "[-2.576  1.119] [ 0.500  1.575] [ 33.205] [ 3.076  0.456]\n",
      "[-0.752  1.329] [-0.149  0.429] [ 32.606] [ 0.603 -0.900]\n",
      "[-0.486  0.527] [ 2.879  0.392] [ 102.026] [ 3.365 -0.134]\n",
      "[-1.376  1.085] [-17.181  0.881] [ 109.226] [-15.804 -0.204]\n",
      "[ 1.204  0.861] [ 3.130  0.885] [ 69.037] [ 1.926  0.024]\n",
      "[ 1.133  0.709] [-2.191  1.077] [ 24.675] [-3.325  0.368]\n",
      "[ 17.800  1.954] [ 11.384  1.597] [ 57.999] [-6.417 -0.357]\n",
      "[-28.700  3.229] [-29.061  2.261] [ 23.518] [-0.361 -0.968]\n",
      "[ 0.760  3.417] [-4.422  3.076] [ 329.023] [-5.182 -0.341]\n",
      "[ 4.852  3.398] [ 4.368  3.339] [ 65.877] [-0.484 -0.058]\n",
      "[-32.043  2.689] [-6.048  2.253] [ 64.964] [ 25.995 -0.436]\n",
      "[ 1.930  3.117] [-3.425  2.825] [ 39.196] [-5.354 -0.293]\n",
      "[-0.801  0.500] [-1.322  0.492] [ 22.866] [-0.521 -0.008]\n",
      "[ 11.139  2.776] [ 9.825  3.049] [ 22.246] [-1.314  0.274]\n",
      "[-0.157  0.425] [ 0.813  0.365] [ 25.399] [ 0.970 -0.061]\n",
      "[ 1.005  0.289] [ 5.197 -0.047] [ 32.106] [ 4.192 -0.336]\n",
      "[-0.625  3.782] [ 1.846  3.880] [ 29.389] [ 2.471  0.099]\n",
      "[ 8.779  3.226] [-18.194  1.905] [ 93.067] [-26.973 -1.321]\n",
      "[-14.307  3.235] [-4.044  2.765] [ 27.379] [ 10.263 -0.470]\n",
      "[-1.628  0.513] [-8.435  0.855] [ 38.820] [-6.806  0.343]\n",
      "[-1.067  0.338] [-0.263  0.563] [ 194.963] [ 0.804  0.225]\n",
      "[-0.774  0.403] [ 3.365  0.251] [ 38.184] [ 4.139 -0.152]\n",
      "[-0.091  0.816] [ 29.055  0.320] [ 60.173] [ 29.146 -0.497]\n",
      "[-1.490  2.096] [ 4.427  2.218] [ 27.019] [ 5.917  0.121]\n",
      "[-0.151  0.794] [-3.584  1.162] [ 59.004] [-3.433  0.368]\n",
      "6.56340123213\n"
     ]
    }
   ],
   "source": [
    "X = np.load('/home/colin/.ros/gp_opt_train_data.npy')\n",
    "Y = np.load('/home/colin/.ros/gp_opt_train_labels.npy')\n",
    "\n",
    "print X.shape\n",
    "\n",
    "m_load = GPy.models.GPRegression(X, Y)\n",
    "m_load.update_model(False) # do not call the underlying expensive algebra on load\n",
    "# m_load.initialize_parameter() # Initialize the parameters (connect the parameters up)\n",
    "# m_load[:] = np.load('/home/colin/.ros/gp_opt_model.npy') # Load the parameters\n",
    "m_load.kern.variance = 1615.832\n",
    "m_load.kern.lengthscale = 0.171\n",
    "m_load.update_model(True) # Call the algebra only once\n",
    "m_load.optimize('tnc', messages=0, max_iters=1000)\n",
    "\n",
    "# print np.concatenate((X,Y),axis=1)\n",
    "# test_pts = np.array([[0.493,  0.855,  0.541,  0.828]])\n",
    "\n",
    "# pred, pred_var = m_load.predict(test_pts)\n",
    "# for idx,item in enumerate(test_pts):\n",
    "#     print pred[idx]\n",
    "    \n",
    "pred, pred_var = m_load.predict(model.train_data)\n",
    "pred_diff = []\n",
    "for idx,item in enumerate(model.train_data):\n",
    "    pred_diff.append(pred[idx]-model.train_labels[idx])\n",
    "    print model.train_labels[idx], pred[idx], pred_var[idx], pred_diff[idx]\n",
    "# print np.asarray(pred_diff)[:,0]\n",
    "print np.mean(np.abs(np.asarray(pred_diff)[:,0]))\n",
    "\n",
    "# print np.histogram(Y[:,0],bins=10,range=[-45,45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.77368    0.227375   0.24368    0.86984    0.       ]\n",
      " [ 0.44884    0.4785875  0.54408    0.28568    1.       ]\n",
      " [ 0.98458    0.9008625  0.36088    0.9832     0.       ]\n",
      " [ 0.7024     0.531      0.658      0.58312    0.       ]\n",
      " [ 0.83014    0.944      0.90952    0.98224    0.       ]\n",
      " [ 0.66496    0.7974375  0.41504    0.23608    1.       ]\n",
      " [ 0.93736    0.317675   0.9976     0.94616    1.       ]\n",
      " [ 0.4399     0.8914125  0.20328    0.53296    1.       ]\n",
      " [ 0.8704     0.1319125  0.22       0.85008    0.       ]\n",
      " [ 0.4111     0.9862625  0.59728    0.59544    1.       ]\n",
      " [ 0.8815     0.135325   0.37656    0.21424    0.       ]\n",
      " [ 0.56956    0.9299125  0.70304    0.95952    0.       ]\n",
      " [ 0.41032    0.241375   0.98256    0.9652     0.       ]\n",
      " [ 0.45556    0.8490625  0.5328     0.98312    0.       ]\n",
      " [ 0.85534    0.987925   0.99752    0.28952    0.       ]\n",
      " [ 0.65332    0.9906375  0.96632    0.71184    0.       ]\n",
      " [ 0.4255     0.9827625  0.22992    0.23344    0.       ]\n",
      " [ 0.48928    0.8324375  0.52496    0.97128    1.       ]\n",
      " [ 0.84958    0.132175   0.95256    0.37464    0.       ]\n",
      " [ 0.4279     0.890975   0.81016    0.41216    0.       ]\n",
      " [ 0.91696    0.1607     0.2592     0.80152    1.       ]\n",
      " [ 0.55216    0.9846875  0.68336    0.34736    1.       ]\n",
      " [ 0.99028    0.362125   0.84424    0.27768    0.       ]\n",
      " [ 0.52654    0.9685875  0.94088    0.60896    1.       ]\n",
      " [ 0.97408    0.2918625  0.8064     0.31424    0.       ]\n",
      " [ 0.60142    0.943825   0.45728    0.40896    1.       ]\n",
      " [ 0.87202    0.2776     0.92016    0.29344    0.       ]\n",
      " [ 0.79564    0.902875   0.26712    0.61104    0.       ]\n",
      " [ 0.89296    0.2302625  0.78744    0.22208    0.       ]\n",
      " [ 0.65686    0.8215     0.37064    0.5472     1.       ]\n",
      " [ 0.70162    0.1324375  0.88936    0.2332     1.       ]\n",
      " [ 0.90004    0.978825   0.27656    0.5224     0.       ]\n",
      " [ 0.4201     0.2216     0.91888    0.98384    0.       ]\n",
      " [ 0.81292    0.9825     0.22528    0.48232    1.       ]]\n"
     ]
    }
   ],
   "source": [
    "X_class = np.load('/home/colin/.ros/gp_class_train_data.npy')\n",
    "Y_class = np.load('/home/colin/.ros/gp_class_train_labels.npy')\n",
    "\n",
    "m_class = GPy.models.GPClassification(X_class, Y_class)\n",
    "m_class.update_model(False) # do not call the underlying expensive algebra on load\n",
    "# m_load.initialize_parameter() # Initialize the parameters (connect the parameters up)\n",
    "m_class[:] = np.load('/home/colin/.ros/gp_class_model.npy') # Load the parameters\n",
    "m_class.update_model(True) # Call the algebra only once\n",
    "\n",
    "# pred, pred_var = m_class.predict(model.train_data)\n",
    "# for idx,item in enumerate(model.train_data):\n",
    "#     print item, pred[idx]\n",
    "    \n",
    "print np.concatenate((X_class,Y_class),axis=1)\n",
    "    \n",
    "# ind = np.asarray([Y_class == 1])[0][:,0]\n",
    "# negs = X_class[ind]\n",
    "# pred, pred_var = m_class.predict(negs)\n",
    "# for idx,item in enumerate(negs):\n",
    "#     print item, pred[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[309 349 495 474 250]\n",
      "[[ 0.61946726  0.9872148   0.29663098  0.32971275]\n",
      " [ 0.61021441  0.90795588  0.35371792  0.2206621 ]\n",
      " [ 0.76074773  0.9192006   0.32449138  0.23732111]\n",
      " [ 0.73407465  0.96475381  0.41141945  0.20768024]\n",
      " [ 0.79433519  0.94886321  0.31798884  0.27431446]]\n",
      "[[-0.35957173  0.77172178]\n",
      " [-0.64699584  0.44813341]\n",
      " [-0.48614153  0.52656025]\n",
      " [-6.15595818  1.64907765]\n",
      " [-0.63259095  0.74891335]]\n"
     ]
    }
   ],
   "source": [
    "item = [0.6502, 0.983375, 0.32280000000000003, 0.26424000000000003] \n",
    "near_tree = scipy.spatial.cKDTree(model.train_data, leafsize=100)\n",
    "result = near_tree.query(item, k=5, distance_upper_bound=6)\n",
    "print result[1]\n",
    "print model.train_data[result[1]]\n",
    "print model.train_labels[result[1]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
